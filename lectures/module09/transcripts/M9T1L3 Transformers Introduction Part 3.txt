>> Hi class. In this lecture, we will dive into the attention layer and understand why they are needed in the transformer models. Attention was introduced by Bahdanau to improve the performance of encoder-decoder models for machine translation. The main job of this mechanism is by paying attention to some parts of the input sequence for the task of predictions. The attention mechanism helps with dealing with long-range dependencies between words in a long sentence. But the main concept is explained in the LSTM lecture with the attention mechanism, we have a decoder and encoder in sequence-to-sequence modeling using LSTM. We use an attention mechanism to look back at the whole sentence and selectively extract information it requires during decoding. In transformers, after applying embedding and positional encoding, we use attention to connect to distinct word. In particular, the attention mechanism is called self-attention transformer models. Let's look at the example of the cat drank the milk because it was hungry, or the cat drank the milk because it was sweet. Self-attention, extract information about the meaning so it can associate it with the correct word. In the self-attention layer, the input is passed through three parameters, key, query, and value. Key, query, and value matrices are parameters whose initial weights are small, randomly selected numbers. These parameters change as the model is trained on the dataset. The key query and value matrices size depend on the length of embeddings for each word and the size of the sentence or the sequence. Each sequence or sentence, for simplicity, contains several words and the attention score must be computed for all of them. Initially, all the inputs needs to be passed through embeddings and positional encoding, and we need to randomly generate key, query, and value matrices. As we train in the model, the values or parameters of these matrices will be optimized too. The size of all matrices are the same and depends on the number of words in a sequence and the length of embedding. Let's say if our embeddings produces a vector of length four for each word, and we have three words in our sequence. The size of key, query, and value matrix can be defined as four by three. The next step is to create key, query, and value representation vector for each word. To do this, we need to multiply the vectorized world by each matrix, for example, if our word vector is one by four and key matrix is four by three, the multiplication of word vector by key matrix will produce a vector of length one by three. Now we can calculate the key query and value representation vectors for each word in our sequence. We need to calculate the attention score for each word. And by doing this, we in fact consider the contribution of all the neighboring words in the attention mechanism. I provided the equation here and let's understand what it means by this equation. Let's say again, we have all three words in the sequence, and in order to obtain the attention scores, we start with taking the dot product between the first word query representation with all three words. Keys representations. Since there are three key representations, because we have three words, we obtain three attention scores. Therefore, word one will have three scores, and we need to take the softmax across these three scores. Finally, we multiply each attention scalar score, with corresponding values representation. This step will produce three vectors having a length of three. If we have three words in our sequence, the weighted sum of these vectors will produce the output for the first word input. We need to do the same for the second and third word. In this lecture, we'll learn about transformer models, and particularly we went over the encoder and decoder blocks. I'll also explain about the attention mechanism in transformer models and how to actually pay attention to other words in a sequence for a task of prediction. [MUSIC]
