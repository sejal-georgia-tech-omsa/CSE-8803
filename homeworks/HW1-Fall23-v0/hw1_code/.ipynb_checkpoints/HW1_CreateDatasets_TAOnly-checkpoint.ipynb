{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA NOTE\n",
    "The data for this file may have been moved from data/ to data/TA_DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XM3Tz32Bxn5X"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F-RA4NJLLqW3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/rutomo/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('popular')\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "import gzip\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ev-RvvkcxqOe"
   },
   "source": [
    "# Create Dataset and Remove Profanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Clickbait Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.1 ms, sys: 4.81 ms, total: 83.9 ms\n",
      "Wall time: 86.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load clickbait titles\n",
    "with gzip.open('./data/clickbait_data.gz') as fin:\n",
    "    txt_clickbait = [line.decode('utf-8') for line in fin if line != bytes('\\n', 'utf-8')]\n",
    "    \n",
    "# Load non-clickbait titles\n",
    "with gzip.open('./data/non_clickbait_data.gz') as fin:\n",
    "    txt_non_clickbait = [line.decode('utf-8') for line in fin if line != bytes('\\n', 'utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# open profanity text list\n",
    "with open('./data/profanity_list.txt') as fin:\n",
    "    plist = [l.strip() for l in fin]\n",
    "\n",
    "def remove_profanity(dataset, plist):\n",
    "    count, word_list, data = 0, set(), []\n",
    "    for line in dataset:\n",
    "        flag = 0\n",
    "        for word in plist:\n",
    "            if word in line.lower():\n",
    "                count += 1\n",
    "                flag = 1\n",
    "                word_list.add(word)\n",
    "                break\n",
    "        if not flag:\n",
    "            data.append(line)\n",
    "    return data, count, word_list\n",
    "\n",
    "# remove titles with profanity from clickbait and nonclickbait titles\n",
    "data_c, count_c, word_list_c = remove_profanity(txt_clickbait, plist)\n",
    "data_nc, count_nc, word_list_nc = remove_profanity(txt_non_clickbait, plist)\n",
    "\n",
    "print(count_c, count_nc)\n",
    "print(word_list_c.union(word_list_nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clickbait length: 13043  | non_clickbait length: 12183\n"
     ]
    }
   ],
   "source": [
    "# create list of dictionaries with label 1 for clickbait and 0 for nonclickbait\n",
    "dl_c = np.array([{'headline':line, 'label':1} for line in data_c])\n",
    "dl_nc = np.array([{'headline':line, 'label':0} for line in data_nc])\n",
    "print('clickbait length:', len(dl_c), ' | non_clickbait length:', len(dl_nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dataset_size = 12000\n",
    "\n",
    "# Randomly sample equal data size between clickbait and non-clickbait titles\n",
    "idx_c = np.random.choice(len(dl_c), size=dataset_size, replace=False)\n",
    "idx_nc = np.random.choice(len(dl_nc), size=dataset_size, replace=False)\n",
    "\n",
    "# Split clickbait and non clickbait titles into train and test set\n",
    "split = int(len(idx_c)*0.8)\n",
    "train_idx_c, test_idx_c = idx_c[:split], idx_c[split:]\n",
    "train_idx_nc, test_idx_nc = idx_nc[:split], idx_nc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10021,  6480, 12773, ...,   115,  1863,  3119])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine clickbait and nonclickbait data for train and test dataset\n",
    "train_data = np.concatenate((dl_c[train_idx_c], dl_nc[train_idx_nc]))\n",
    "test_data = np.concatenate((dl_c[test_idx_c], dl_nc[test_idx_nc]))\n",
    "\n",
    "# Shuffle clickbait and nonclickbait headlines\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(len(train_data), len(train_data), replace=False)\n",
    "test_idx = np.random.choice(len(test_data), len(test_data), replace=False)\n",
    "train_data = train_data[train_idx]\n",
    "test_data = test_data[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train dataframes\n",
    "df_train = pd.DataFrame(list(train_data))\n",
    "df_test = pd.DataFrame(list(test_data))\n",
    "\n",
    "# Save test and train as csv\n",
    "# df_train.to_csv('./data/train.csv')\n",
    "# df_test.to_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"A 65-Year-Old Man's Typewriter Was Destroyed By An Angry Cop, And The Internet Got Him A New One\\n\",\n",
       "  'Can You Identify These United States Leaders\\n',\n",
       "  'Index of Economic Activity Declined in March\\n',\n",
       "  \"2015's Best News Bloopers Are Here And They're Out Of Control\\n\",\n",
       "  '18 Pictures Everyone Who Loves Spilling The Tea Will Understand\\n'],\n",
       " [1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"19 Things Anyone Who's Best Friends With Their Mum As An Adult Will Understand\\n\",\n",
       "  '6.2 magnitude earthquake hits northern Chile\\n',\n",
       "  'Which Of The Great Lakes Are You\\n',\n",
       "  'In Loneliness, Immigrants Tend the Flock\\n',\n",
       "  '19 Things That Happen When You Have The Sunday Scaries\\n'],\n",
       " [1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WOS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wos_path = './data/WOS5736/X.txt'\n",
    "wos_path = './data/WOS46985/'\n",
    "wos_label = {0:'CS', 1:'ECE', 4:'Civil', 5:'Medical'}\n",
    "\n",
    "with open(wos_path + 'YL1.txt') as fin:\n",
    "    y_wos = [int(line.strip()) for line in fin]\n",
    "\n",
    "with open(wos_path +'X.txt') as fin:\n",
    "    txt_wos = [line for line in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open profanity text list\n",
    "with open('./data/avoid_list.txt') as fin:\n",
    "    alist = [l.strip() for l in fin]\n",
    "    \n",
    "def detect_profanity(text, alist):\n",
    "    text = text.lower().split()\n",
    "    for word in alist:\n",
    "        if word in text:\n",
    "            print('found')\n",
    "            return True, word\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "profanity detected at i: 21 word: jerk label: CS\n",
      "found\n",
      "profanity detected at i: 25 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 31 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 50 word: woody label: CS\n",
      "found\n",
      "profanity detected at i: 52 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 64 word: scrotum label: Medical\n",
      "found\n",
      "profanity detected at i: 65 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 66 word: ovary label: Medical\n",
      "found\n",
      "profanity detected at i: 67 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 68 word: gonads label: Medical\n",
      "found\n",
      "profanity detected at i: 93 word: penetration label: Civil\n",
      "found\n",
      "profanity detected at i: 96 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 101 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 116 word: strip label: ECE\n",
      "found\n",
      "profanity detected at i: 143 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 217 word: slave label: ECE\n",
      "found\n",
      "profanity detected at i: 246 word: strip label: ECE\n",
      "found\n",
      "profanity detected at i: 290 word: tit label: ECE\n",
      "found\n",
      "profanity detected at i: 294 word: penetration label: ECE\n",
      "found\n",
      "profanity detected at i: 337 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 353 word: penetrate label: Medical\n",
      "found\n",
      "profanity detected at i: 361 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 371 word: heroin label: Medical\n",
      "found\n",
      "profanity detected at i: 384 word: dyke label: Civil\n",
      "found\n",
      "profanity detected at i: 401 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 453 word: slope label: Civil\n",
      "found\n",
      "profanity detected at i: 464 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 514 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 522 word: heroin label: Medical\n",
      "found\n",
      "profanity detected at i: 524 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 542 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 546 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 563 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 600 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 610 word: hemp label: Civil\n",
      "found\n",
      "profanity detected at i: 612 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 622 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 644 word: weed label: Civil\n",
      "found\n",
      "profanity detected at i: 656 word: facial label: ECE\n",
      "found\n",
      "profanity detected at i: 658 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 668 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 684 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 692 word: penetration label: CS\n",
      "found\n",
      "profanity detected at i: 712 word: fat label: CS\n",
      "found\n",
      "profanity detected at i: 715 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 837 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 863 word: penetration label: Medical\n",
      "found\n",
      "profanity detected at i: 869 word: stroke label: CS\n",
      "found\n",
      "profanity detected at i: 1003 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 1005 word: tit label: Civil\n",
      "found\n",
      "profanity detected at i: 1058 word: facial label: CS\n",
      "found\n",
      "profanity detected at i: 1142 word: facial label: CS\n",
      "found\n",
      "profanity detected at i: 1149 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 1158 word: dummy label: ECE\n",
      "found\n",
      "profanity detected at i: 1188 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 1228 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 1283 word: asses label: CS\n",
      "found\n",
      "profanity detected at i: 1287 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 1307 word: strip label: Civil\n",
      "found\n",
      "profanity detected at i: 1346 word: thrust label: ECE\n",
      "found\n",
      "profanity detected at i: 1402 word: thrust label: Civil\n",
      "found\n",
      "profanity detected at i: 1465 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 1491 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 1520 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 1523 word: penetration label: Civil\n",
      "found\n",
      "profanity detected at i: 1533 word: erection label: Civil\n",
      "found\n",
      "profanity detected at i: 1545 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 1571 word: thrust label: ECE\n",
      "found\n",
      "profanity detected at i: 1574 word: slope label: Civil\n",
      "found\n",
      "profanity detected at i: 1576 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 1592 word: fat label: Medical\n",
      "found\n",
      "profanity detected at i: 1616 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 1629 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 1631 word: stroke label: CS\n",
      "found\n",
      "profanity detected at i: 1675 word: slope label: ECE\n",
      "found\n",
      "profanity detected at i: 1766 word: sex label: CS\n",
      "found\n",
      "profanity detected at i: 1771 word: sperm label: Medical\n",
      "found\n",
      "profanity detected at i: 1775 word: fat label: Medical\n",
      "found\n",
      "profanity detected at i: 1779 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 1805 word: organ label: CS\n",
      "found\n",
      "profanity detected at i: 1812 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 1823 word: enlargement label: Medical\n",
      "found\n",
      "profanity detected at i: 1832 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 1836 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 1844 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 1902 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 1990 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 1992 word: sexual label: Medical\n",
      "found\n",
      "profanity detected at i: 1993 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 1996 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 2012 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2045 word: stroke label: CS\n",
      "found\n",
      "profanity detected at i: 2106 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 2108 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 2137 word: thrust label: Medical\n",
      "found\n",
      "profanity detected at i: 2144 word: facial label: CS\n",
      "found\n",
      "profanity detected at i: 2185 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 2187 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 2196 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 2198 word: fat label: Medical\n",
      "found\n",
      "profanity detected at i: 2207 word: paddy label: Civil\n",
      "found\n",
      "profanity detected at i: 2208 word: oral label: Civil\n",
      "found\n",
      "profanity detected at i: 2218 word: hiv label: Medical\n",
      "found\n",
      "profanity detected at i: 2240 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2243 word: anal label: Medical\n",
      "found\n",
      "profanity detected at i: 2253 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2259 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2268 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 2271 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2273 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 2275 word: facial label: Medical\n",
      "found\n",
      "profanity detected at i: 2288 word: fat label: Medical\n",
      "found\n",
      "profanity detected at i: 2289 word: stroke label: Medical\n",
      "found\n",
      "profanity detected at i: 2313 word: testes label: Medical\n",
      "found\n",
      "profanity detected at i: 2318 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2324 word: fat label: Medical\n",
      "found\n",
      "profanity detected at i: 2326 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 2356 word: urine label: Medical\n",
      "found\n",
      "profanity detected at i: 2365 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2380 word: slope label: Medical\n",
      "found\n",
      "profanity detected at i: 2381 word: orally label: Medical\n",
      "found\n",
      "profanity detected at i: 2385 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2386 word: prick label: Medical\n",
      "found\n",
      "profanity detected at i: 2404 word: stroke label: Medical\n",
      "found\n",
      "profanity detected at i: 2419 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2429 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 2430 word: urine label: Medical\n",
      "found\n",
      "profanity detected at i: 2438 word: sex label: Medical\n",
      "found\n",
      "profanity detected at i: 2441 word: stroke label: Medical\n",
      "found\n",
      "profanity detected at i: 2449 word: penetration label: Medical\n",
      "found\n",
      "profanity detected at i: 2458 word: oral label: Medical\n",
      "found\n",
      "profanity detected at i: 2481 word: organ label: Medical\n",
      "found\n",
      "profanity detected at i: 2584 word: oral label: CS\n",
      "found\n",
      "profanity detected at i: 2848 word: retard label: Civil\n",
      "found\n",
      "profanity detected at i: 3030 word: strip label: Civil\n",
      "found\n",
      "profanity detected at i: 3079 word: slope label: CS\n",
      "found\n",
      "profanity detected at i: 3139 word: retard label: Civil\n",
      "found\n",
      "profanity detected at i: 3164 word: pms label: Civil\n",
      "found\n",
      "profanity detected at i: 3437 word: strip label: CS\n",
      "found\n",
      "profanity detected at i: 3450 word: urine label: CS\n",
      "found\n",
      "profanity detected at i: 3495 word: slope label: Civil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "profanity detected at i: 3550 word: strip label: Civil\n",
      "found\n",
      "profanity detected at i: 3667 word: strip label: Civil\n",
      "found\n",
      "profanity detected at i: 4074 word: wang label: Civil\n",
      "found\n",
      "profanity detected at i: 4285 word: slope label: Civil\n",
      "found\n",
      "profanity detected at i: 9471 word: slope label: Civil\n",
      "CPU times: user 3 s, sys: 77.1 ms, total: 3.08 s\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data2_wos = {0:[], 1:[], 4:[], 5:[]}\n",
    "data2_wos = {i:[] for i in wos_label.keys()}\n",
    "idx2_wos = {i:[] for i in wos_label.keys()}\n",
    "wos2_count = {i:0 for i in wos_label.keys()}\n",
    "\n",
    "for i in range(len(y_wos)):\n",
    "    currlabel = y_wos[i]\n",
    "#     print(i)\n",
    "    if currlabel in wos2_count.keys() and wos2_count[currlabel] < 500:\n",
    "        p_found, word = detect_profanity(txt_wos[i], plist)\n",
    "        if not p_found:\n",
    "            data2_wos[currlabel].append(txt_wos[i])\n",
    "            idx2_wos[currlabel].append(i + 1)\n",
    "            data2_wos[currlabel]\n",
    "            label2_wos.append(currlabel)\n",
    "            wos2_count[currlabel] += 1\n",
    "        else:\n",
    "            print('profanity detected at i:', i, 'word:', word, 'label:', wos_label[currlabel] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 500, 1: 500, 4: 500, 5: 500}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS 1\n",
      "(2 + 1)-dimensional non-linear optical waves through the coherently excited resonant medium doped with the erbium atoms can be described by a (2 + 1)-dimensional non-linear Schrodinger equation coupled with the self-induced transparency equations. For such a system, via the Hirota method and symbolic computation, linear forms, one-, two-and N-soliton solutions are obtained. Asymptotic analysis is conducted and suggests that the interaction between the two solitons is elastic. Bright solitons are obtained for the fields E and P, while the dark ones for the field N, with E as the electric field, P as the polarization in the resonant medium induced by the electric field, and N as the population inversion profile of the dopant atoms. Head-on interaction between the bidirectional two solitons and overtaking interaction between the unidirectional two solitons are seen. Influence of the averaged natural frequency. on the solitons are studied: (1). can affect the velocities of all the solitons; (2) Amplitudes of the solitons for the fields P and N increase with. decreasing, and decrease with. increasing; (3) With. decreasing, for the fields P and N, one-peak one soliton turns into the two-peak one, as well as interaction type changes from the interaction between two one-peak ones to that between a one-peak one and a two-peak one; (4) For the field E, influence of. on the solitons cannot be found. The results of this paper might be of potential applications in the design of optical communication systems which can produce the bright and dark solitons simultaneously.\n",
      "\n",
      "CS 6\n",
      "(Objective) In order to increase classification accuracy of tea-category identification (TCI) system, this paper proposed a novel approach. (Method) The proposed methods first extracted 64 color histogram to obtain color information, and 16 wavelet packet entropy to obtain the texture information. With the aim of reducing the 80 features, principal component analysis was harnessed. The reduced features were used as input to generalized eigenvalue proximal support vector machine (GEPSVM). Winner-takes-all (WTA) was used to handle the multiclass problem. Two kernels were tested, linear kernel and Radial basis function (RBF) kernel. Ten repetitions of 10-fold stratified cross validation technique were used to estimate the out-of-sample errors. We named our method as GEPSVM + RBF + WTA and GEPSVM + WTA. (Result) The results showed that PCA reduced the 80 features to merely five with explaining 99.90% of total variance. The recall rate of GEPSVM + RBF + WTA achieved the highest overall recall rate of 97.9%. (Conclusion) This was higher than the result of GEPSVM + WTA and other five state-of-the-art algorithms: back propagation neural network, RBF support vector machine, genetic neural-network, linear discriminant analysis, and fitness-scaling chaotic artificial bee colony artificial neural network.\n",
      "\n",
      "CS 31\n",
      "1. Camera trapping is a widely applied method to study mammalian biodiversity and is still gaining popularity. It can quickly generate large amounts of data which need to be managed in an efficient and transparent way that links data acquisition with analytical tools. 2. We describe the free and open-source R package camtrapR, a new toolbox for flexible and efficient management of data generated in camera trap-based wildlife studies. The package implements a complete workflow for processing camera trapping data. It assists in image organization, species and individual identification, data extraction from images, tabulation and visualization of results and export of data for subsequent analyses. There is no limitation to the number of images stored in this data management system; the system is portable and compatible across operating systems. 3. The functions provide extensive automation to minimize data entry mistakes and, apart from species and individual identification, require minimal manual user input. Species and individual identification are performed outside the R environment, either via tags assigned in dedicated image management software or by moving images into species directories. 4. Input for occupancy and (spatial) capture-recapture analyses for density and abundance estimation, for example in the R packages unmarked or secr, is computed in a flexible and reproducible manner. In addition, survey summary reports can be generated, spatial distributions of records can be plotted and exported to GIS software, and single-and two-species activity patterns can be visualized. 5. camtrapR allows for streamlined and flexible camera trap data management and should be most useful to researchers and practitioners who regularly handle large amounts of camera trapping data.\n",
      "\n",
      "ECE 4\n",
      "(Hybrid) electric vehicles are assumed to play a major role in future mobility concepts. Although sales numbers are increasing, little emphasis has been laid on the recycling of some key components such as power electronics or electric motors. Permanent magnet synchronous motors contain considerable amounts of rare earth elements that cannot be recovered in conventional recycling routes. Although their recycling could have large economic, environmental, and strategic advantages, no industrial recycling for permanent magnets is available in western countries at the moment. Regarding the essential steps, dismantling of electric vehicles as well as the extraction of magnets from the rotors, little has been published before. This paper therefore presents and discusses different recycling approaches for the recycling of NdFeB magnets from (hybrid) electric vehicles. Many results stem from the German research project \"Recycling of components and strategic metals of electric drive motors.\".\n",
      "\n",
      "ECE 8\n",
      "(T)his paper presents the concept of a software-defined radio with a flexible RF front end. The design and architecture of this system, as well as possible application examples will be explained. One specific scenario is the operation in maritime frequency bands. A well-known service is the Automatic Identification System (AIS), which has been captured by the DLR mission AISat, and will be chosen as a maritime application example. The results of an embedded solution for AIS on the SDR platform are presented in this paper. Since there is an increasing request for more performance on maritime radio bands, services like AIS will be enhanced by the International Association of Marine Aids to Navigation and Lighthouse Authorities (IALA). The new VHF Data Exchange Service (VDES) shall implement a dedicated satellite link. This paper describes that the SDR with a flexible RF front end can be used as a technology demonstration platform for this upcoming data exchange service.\n",
      "\n",
      "ECE 15\n",
      "[1] First results are reported on statistical tomography of kilometer-scale irregularities in the F layer high-latitude ionosphere from amplitude data of satellite radio probing. Basic formulae for statistical tomography of three-dimensionally (3-D) anisotropic small-scale irregularities are presented. It is shown that 3-D anisotropy disguises spatial distribution of irregularities but is not an insuperable difficulty for tomographic reconstruction. An example is shown of imaging the spatial distribution of the variance of electron density fluctuations over the Kola peninsula in February 1996. Iterative procedure of tomographic inversion was used in the reconstruction. Further steps of applying statistical tomographic approach are outlined.\n",
      "\n",
      "Civil 3\n",
      "(D)ecreasing of energy consumption and environmentally friendly energy resources are the issues in the foreground nowadays. As the electric energy consumed for the illumination is high, long-lasting and low-consumption LED (light-emitting diode) technology gets prominent. There have been made much reseacrh regarding the use of photovoltaic sytems in meeting the energy demand in housing and industry. However, there is need for more research with regards to photovoltaic sytems' integration with energy efficiency sytems. In this study, for the environments which have different lighting levels due to daylight factor, there has been proposed a low-cost PV (photovoltaics) based and distributed sensor smart LED illuminating system and there has been acquired 72.075% more energy saving in comparison with conventional LED illuminating system. (C) 2017 Elsevier Inc. All rights reserved.\n",
      "\n",
      "Civil 41\n",
      "1. INTRODUCTION Sustainability has been defined as the need to preserve existing natural resources so that the earth is able to continue to provide these resources for future generations. Put more simply, a sustainable system is one that survives or persists (Costanza and Patten, 1995). In order to ensure the sustainability of architectural and building activity, it is essential that work in this field is conducted in accordance with the canons of basic ecology and, in addition, that its members seek to address certain cultural and relational characteristics that typify the way we live today. Architecture as a discipline combines technology and art; however, with the advent of \"sustainable architecture\" additional concepts from the fields of ecology, sociology, and philosophy have been incorporated. Yet, the fundamental problem is that the meanings of both the classical and the new concepts remain ambiguous, their significance shifting with our cultural evolution. Hence, the traditional Vitruvian values of architecture (beauty, structure and utility) are no longer so obvious, especially when we are required to think in terms of sustainability. Although the question as to why architecture matters has been answered in a variety of ways (Glaeser, 2011), it is our contention that in the 21st century architecture will matter more than ever, because by 2050 most of the world's population will be concentrated in cities. As a result, the sustainability of dwellings and cities has acquired undeniable importance. Two interacting forces influence all populations. One is the Malthusian dynamic of exponential growth until environmental limits are reached (Figure 1). The second is the Darwinian dynamics of innovation and adaptation that circumvent these limits through biological or cultural evolution. Nekola et al., in 2013 reported that the specific manifestation of these two forces in our current society provide the context that establishes how humans may develop sustainable relationships within our finite planet (Figure 2). Consequently, a permanent and indefinite growth is impossible due to the physical and biological imperatives of our finite world. Biologists and architects and constructors usually inhabit different worlds. The latter innovate, deploy, and apply their techno-science based designs; the first, study the finite nature, propose hypotheses, and gather their evidence. And, to date, there is little to suggest that copying nature purports any advantages to architects, primarily because fully autonomous buildings or towns have yet to be built. According to the described Malthusian-Darwinian dynamic, the two critical questions that we seek to address in this paper are: i) What is the essence of a sustainable dwelling? and ii) What principles should be adhered to in making a dwelling sustainable? In other words, this study aims to elucidate the essence of sustainability in green building design implementation.\n",
      "\n",
      "Civil 42\n",
      "1. INTRODUCTION The emergence of environmental problems as major social issues throughout the world has prompted sustainable development efforts in a wide range of areas, including industry, construction, and transportation, followed by the execution of numerous studies and policies. The concept of sustainable development has been dealt with in earnest in the construction field since the Declaration of Interdependence for a Sustainable Future at the 18th Chicago Convention of UIA in 1993. This Declaration included tasks to be implemented with respect to green buildings, such as the recycling of resources, application of energy-efficient designs, and utilization of natural energy in addition to the application of sustainable designs. As part of green building practices, countries around the world have been implementing various green building certification standards, such as LEED, GBCC, CASBEE, and BREEAM. These certification standards prescribe the criteria relating to the external environment, energy conservation, materials and resources, and the indoor environment, with energy conservation being the top priority for each of these issues. This is due to energy consumption in building operation accounting for more than half of the building life cycle cost. Accordingly, although many studies are undertaken for the purpose of developing the means for conserving energy in relation to green buildings, the majority of these studies are concentrated on the development of technologies for environmental facilities through the application of active designs. study the finite nature, propose hypotheses, and gather their evidence. And, to date, there is little to suggest that copying nature purports any advantages to architects, primarily because fully autonomous buildings or towns have yet to be built. According to the described Malthusian-Darwinian dynamic, the two critical questions that we seek to address in this paper are: i) What is the essence of a sustainable dwelling? and ii) What principles should be adhered to in making a dwelling sustainable? In other words, this study aims to elucidate the essence of sustainability in green building design implementation.\n",
      "\n",
      "Medical 2\n",
      "(beta-amyloid (A beta) and tau pathology become increasingly prevalent with age, however, the spatial relationship between the two pathologies remains unknown. We examined local (same region) and non-local (different region) associations between these 2 aggregated proteins in 46 normal older adults using [F-18]AV-1451 (for tau) and [C-11]PiB (for A beta) positron emission tomography (PET) and 1.5 T magnetic resonance imaging (MRI) images. While local voxelwise analyses showed associations between PiB and AV-1451 tracer largely in the temporal lobes, k-means clustering revealed that some of these associations were driven by regions with low tracer retention. We followed this up with a whole-brain region-by-region (local and non-local) partial correlational analysis. We calculated each participant's mean AV-1451 and PiB uptake values within 87 regions of interest (ROI). Pairwise ROI analysis demonstrated many positive PiB AV-1451 associations. Importantly, strong positive partial correlations (controlling for age, sex, and global gray matter fraction, p <.01) were identified between PiB in multiple regions of association cortex and AV-1451 in temporal cortical ROIs. There were also less frequent and weaker positive associations of regional PiB with frontoparietal AV-1451 uptake. Particularly in temporal lobe ROIs, AV-1451 uptake was strongly predicted by NB across multiple ROI locations. These data indicate that A beta and tau pathology show significant local and non-local regional associations among cognitively normal elderly, with increased PiB uptake throughout the cortex correlating with increased temporal lobe AV-1451 uptake. The spatial relationship between A beta and tau accumulation does not appear to be specific to A beta location, suggesting a regional vulnerability of temporal brain regions to tau accumulation regardless of where AP accumulates.\n",
      "\n",
      "Medical 5\n",
      "(L)-3,4-Dihydroxyphenylalanine ((L)-DOPA) remains the primary pharmacological agent for the symptomatic treatment of Parkinson's disease (PD). However, the development of (L)-DOPA-induced dyskinesia (LID) limits the long-term use of (L)-DOPA for PD patients. Some data have reported that adenosine A(2A) receptor (A(2A)R) antagonists prevented LID in animal model of PD. However, the mechanism in which adenosine A(2A)R blockade alleviates the symptoms of LID has not been fully clarified. Here, we determined to knock out (KO) the gene of A(2A)R and explored the possible underlying mechanisms implicated in development of LID in a mouse model of PD. A(2A)R gene KO mice were unilaterally injected into the striatum with 6-hydroxydopamine (6-OHDA) in order to damage dopamine neurons on one side of the brain. 6-OHDA-lesioned mice were then injected once daily for 21 days with (L)-DOPA. Abnormal involuntary movements (AIMs) were evaluated on days 3, 8, 13, and 18 after (L)-DOPA administration, and real-time polymerase chain reaction and immunohistochemistry for glutamic acid decarboxylase (GAD) 65 and GAD67 were performed. We found that A(2A)R gene KO was effective in reducing AIM scores and accompanied with decrease of striatal GAD67, rather than GAD65. These results demonstrated that the possible mechanism involved in alleviation of AIM symptoms by A(2A)R gene KO might be through reducing the expression of striatal GAD67.\n",
      "\n",
      "Medical 11\n",
      ",Background: The objective was to describe the patterns and mechanisms of water tubing related injuries treated in U.S. emergency departments. Methods: The National Electronic Injury Surveillance System was used to examine cases of water tubing related injuries. Sample weights were used to calculate national estimates of water tubing related injuries. Analyses were conducted in 2010. Results: From 1991-2009 an estimated 69,471 injuries were treated in US emergency departments for water tubing related injuries. The annual number of cases increased 250% over the 19-year study period (P<.001). Sprains and strains accounted for the largest portion of injuries (27.2%). The head was the most frequently injured body part (27.5%). Children and adolescents= 20 years, were more likely than individuals 19 years to sustain sprains and strains (OR: 2.11; 95% CI = 1.64-2.71) and were most commonly injured by impact with the water (54.6%). Conclusions: Patterns of water tubing related injuries differ for children and adults. Research is needed to determine how best to reduce these injuries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lbl in wos2_count.keys():\n",
    "    for i in range(3):\n",
    "        print(wos_label[lbl], idx2_wos[lbl][i])\n",
    "        print(data2_wos[lbl][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(500*0.8)\n",
    "x_wos_train = np.concatenate([data2_wos[i][:split] for i in wos_label.keys()])\n",
    "y_wos_train = np.concatenate([np.ones(500, dtype=int)[:split]*i for i in wos_label.keys()])\n",
    "x_wos_test = np.concatenate([data2_wos[i][split:] for i in wos_label.keys()])\n",
    "y_wos_test = np.concatenate([np.ones(500,dtype=int)[split:]*i for i in wos_label.keys()])\n",
    "\n",
    "wos_train = np.vstack((x_wos_train, y_wos_train)).T\n",
    "wos_test = np.vstack((x_wos_test, y_wos_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 2), (400, 2))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos_train.shape, wos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wos = np.array([{'article':wos_train[i][0], 'label':wos_train[i][1], 'domain':wos_label[int(wos_train[i][1])]} \\\n",
    "             for i in range(wos_train.shape[0])])\n",
    "\n",
    "test_wos = np.array([{'article':wos_test[i][0], 'label':wos_test[i][1], 'domain':wos_label[int(wos_test[i][1])]} \\\n",
    "             for i in range(wos_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': '(Objective) In order to increase classification accuracy of tea-category identification (TCI) system, this paper proposed a novel approach. (Method) The proposed methods first extracted 64 color histogram to obtain color information, and 16 wavelet packet entropy to obtain the texture information. With the aim of reducing the 80 features, principal component analysis was harnessed. The reduced features were used as input to generalized eigenvalue proximal support vector machine (GEPSVM). Winner-takes-all (WTA) was used to handle the multiclass problem. Two kernels were tested, linear kernel and Radial basis function (RBF) kernel. Ten repetitions of 10-fold stratified cross validation technique were used to estimate the out-of-sample errors. We named our method as GEPSVM + RBF + WTA and GEPSVM + WTA. (Result) The results showed that PCA reduced the 80 features to merely five with explaining 99.90% of total variance. The recall rate of GEPSVM + RBF + WTA achieved the highest overall recall rate of 97.9%. (Conclusion) This was higher than the result of GEPSVM + WTA and other five state-of-the-art algorithms: back propagation neural network, RBF support vector machine, genetic neural-network, linear discriminant analysis, and fitness-scaling chaotic artificial bee colony artificial neural network.\\n',\n",
       " 'domain': 'CS',\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle clickbait and nonclickbait headlines\n",
    "np.random.seed(42)\n",
    "train_idx_wos = np.random.choice(len(train_wos), len(train_wos), replace=False)\n",
    "test_idx_wos = np.random.choice(len(test_wos), len(test_wos), replace=False)\n",
    "train_wos = train_wos[train_idx_wos]\n",
    "test_wos = test_wos[test_idx_wos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'An automatized procedure for the parameterization of fundamental equations of state (EOS) that are explicit in terms of the Helmholtz energy and are based on molecular simulation data is presented. The simulation runs are carried out via a cloud-based framework that combines multiple, distributed computing resources. A user-friendly graphical user interface ensures that minimal knowledge about the background operations is required. In order to exemplify the capabilities of this approach an EOS for ethylene oxide is created and compared to data from the literature. (C) 2016 Elsevier B.V. All rights reserved.\\n',\n",
       " 'domain': 'CS',\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train dataframes\n",
    "df_train_wos = pd.DataFrame(list(train_wos))\n",
    "df_test_wos = pd.DataFrame(list(test_wos))\n",
    "\n",
    "# Save test and train as csv\n",
    "# df_train_wos.to_csv('./data/train_wos.csv')\n",
    "# df_test_wos.to_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Save test and train as csv\n",
    "df_train_wos = pd.read_csv('./data/train_wos.csv')\n",
    "df_test_wos = pd.read_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
