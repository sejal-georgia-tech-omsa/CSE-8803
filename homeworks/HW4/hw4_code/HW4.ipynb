{"cells":[{"cell_type":"markdown","id":"b32ba0fd","metadata":{"id":"b32ba0fd"},"source":["# Fall 2023 Applied NLP Homework 4\n","\n","## Instructors: Dr. Mahdi Roozbahani, Wafa Louhichi, Dr. Nimisha Roy\n","\n","## Deadline: December 1st, 11:59PM AoE"]},{"cell_type":"markdown","id":"eb689246","metadata":{"id":"eb689246"},"source":["## Honor Code and Assignment Deadline\n","<!-- No changes needed on the below section -->\n","* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit.\n","\n","* Discussion is encouraged on Ed as part of the Q/A. However, all assignments should be done individually.\n","\n","* <font color='darkred'>Plagiarism is a **serious offense**. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.</font>\n","\n","* <font color='darkred'>All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the instituteâ€™s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, **WE WILL DIRECTLY REPORT ALL CASES TO OSI**, which may, unfortunately, lead to a very harsh outcome. **Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class.**\n","</font>\n"]},{"cell_type":"markdown","id":"18717a84","metadata":{"id":"18717a84"},"source":["## Instructions for the assignment\n","\n","<!-- No changes needed on the below section -->\n","- This entire assignment will be autograded through Gradescope. There is only one Gradescope submissions for this assignment:\n","    - **Homework 4**: Submit all files to this section\n","\n","- We provided you different .py files and we added libraries in those files please DO NOT remove those lines and add your code after those lines. Note that these are the only allowed libraries that you can use for the homework.\n","\n","- You will submit your implemented .py files to the corresponding homework section on Gradescope.\n","\n","- You are allowed to make as many submissions until the deadline as you like. Additionally, note that the autograder tests each function separately, therefore it can serve as a useful tool to help you debug your code if you are not sure of what part of your implementation might have an issue.\n"]},{"cell_type":"markdown","id":"68d5b6db","metadata":{"id":"68d5b6db"},"source":["## Using the local tests <a id='using_local_tests'></a>\n","- For some of the programming questions we have included a local test using a small toy dataset to aid in debugging. The local test sample data and outputs are stored in .py files in the **local_tests** folder\n","- There are no points associated with passing or failing the local tests, you must still pass the autograder to get points.\n","- **It is possible to fail the local test and pass the autograder** since the autograder has a certain allowed error tolerance while the local test allowed error may be smaller. Likewise, passing the local tests does not guarantee passing the autograder.\n","- **You do not need to pass both local and autograder tests to get points, passing the Gradescope autograder is what is required for credit.**\n","- It might be helpful to comment out the tests for functions that have not been completed yet.\n","- It is recommended to test the functions as it gets completed instead of completing the whole class and then testing. This may help in isolating errors. Do not solely rely on the local tests, continue to test on the autograder regularly as well."]},{"cell_type":"markdown","id":"f3559faf","metadata":{"id":"f3559faf"},"source":["# Google Colab Setup (Optional for running on Colab)\n","If you choose to work on the assignment on Google Colab, the following cell may help get you set up. You may need to right click on the Applied NLP folder and `Add shortcut to Drive`. You do not have to run this cell if you are working on the notebook locally."]},{"cell_type":"code","execution_count":3,"id":"0066960d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0066960d","outputId":"79637122-7506-4a42-f68c-8b47bf2da83f","executionInfo":{"status":"ok","timestamp":1701045306860,"user_tz":300,"elapsed":858,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/HW4/hw4_code\n","Mon Nov 27 00:35:06 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# # Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# You may need to create an Applied_NLP/HW#/hw#_code/ folder\n","%cd '/content/drive/MyDrive/HW4/hw4_code/'\n","\n","## If no GPU selected it will ask for GPU to be selected\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","\n","## This wraps output text according to the window size\n","from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"markdown","id":"05409a58","metadata":{"id":"05409a58"},"source":["# Assignment Overview"]},{"cell_type":"markdown","id":"89d96973","metadata":{"id":"89d96973"},"source":["In this homework we will explore non-linear text classification algorithms using deep neural networks.\n","\n","We will reuse the datasets from HW3 and a new dataset for this exploration:\n","* The first dataset is a subset of a [Clickbait Dataset](https://github.com/bhargaviparanjape/clickbait/tree/master/dataset) that has article headlines and a binary label on whether the headline is considered clickbait.\n","* The second dataset is a subset of [Web of Science Dataset](https://data.mendeley.com/datasets/9rw3vkcfy4/6) that has articles and a corresponding label on the domain of the articles.\n","* The third dataset is the [CoNLL-2003](https://huggingface.co/datasets/conll2003) that has text corresponding with Part of Speech and Name Entity Recognition labels.\n","\n","We will first explore LSTM and LSTM with Attention. Then we will be looking into attention based architectures : Transformers and we will apply it to sequence labeling task : Part of Speech Tagging (POS) and Named Entity Recognition (NER). We will also look into Topic Modeling."]},{"cell_type":"markdown","id":"e51f68d8","metadata":{"id":"e51f68d8"},"source":["## Deliverables and Points Distribution\n","\n","### Q1: LSTM [15pts]\n","- **1.1 Implementing the LSTM Model** [10pts] Deliverables: <font color = 'green'>lstm.py</font>\n","\n","    - [4pts] \\_\\_init__\n","\n","    - [6pts] forward\n","- **1.2 Classifying Clickbait Dataset using LSTM** [5pts] Deliverables: <font color = 'green'>lstm.py, best_lstm.model.pt</font>\n","\n","### Q2: LSTM with Attention [15pts]\n","- **2.1 Implementing the LSTM + Attention Model** [10pts] Deliverables: <font color = 'green'>attention.py</font>\n","\n","    - [2pts] \\_\\_init__\n","\n","    - [2pts] forward_lstm\n","\n","    - [2pts] forward_attention\n","\n","    - [2pts] forward_context\n","\n","    - [2pts] forward\n","    \n","    \n","- **2.2 Classifying Web of Science Dataset using LSTM + Attention** [5pts] Deliverables: <font color = 'green'>attention.py, best_attention.model.pt</font>\n","\n","### Q3: Transformers [15pts]\n","- **3.1 Implementing the BERT Classifier** [5pts] Deliverables: <font color = 'green'>bert.py</font>\n","\n","    - [2pts] \\_\\_init__\n","\n","    - [3pts] forward\n","\n","- **3.4 Classifying Web of Science Dataset using BERT Classifier** [5pts] Deliverables: <font color = 'green'>bert_clickbait.pkl</font>\n","\n","- **3.5 Classifying Web of Science Dataset using BERT Classifier** [5pts] Deliverables: <font color = 'green'>bert_wos.pkl</font>\n","\n","\n","### Q4: Sequence Labeling [15pts]\n","- **4.1 Implementing Sequence Labeling** [5pts] Deliverables: <font color = 'green'>sequenceLabeling.py</font>\n","\n","    - [2pts] \\_\\_init__\n","\n","    - [3pts] forward\n","\n","- **4.5 POS Tagging and NER using CoNLL-2003 Dataset** [10pts] Deliverables: <font color = 'green'>bert_pos.pkl, bert_ner.pkl</font>\n","\n","\n","### Q5: Topic Modeling [20pts]\n","- **Topic modeling with Latent Dirichlet Allocation (LDA)** [20pts] Deliverables: <font color = 'green'>lda.py</font>\n","\n","    - [5pts] tokenize_words\n","\n","    - [5pts] remove_stopwords\n","\n","    - [5pts] create_dictionary\n","    \n","    - [5pts] build_LDAModel\n","\n"]},{"cell_type":"markdown","id":"f462ddb9","metadata":{"id":"f462ddb9"},"source":["# Setup\n","**Please checkout the environment_setup.md file to create the environment for this homework.** This notebook is tested under the package versions noted in the Library Imports cell output below, and the corresponding packages can be downloaded from [miniconda](https://docs.conda.io/en/latest/miniconda.html). You may also want to get yourself familiar with several packages:\n","\n","- [jupyter notebook](https://jupyter-notebook.readthedocs.io/en/stable/)\n","- [numpy](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n","- [sklearn](https://matplotlib.org/users/pyplot_tutorial.html)\n","- [pytorch](https://pytorch.org/)\n","\n","In the .py files please implement the functions that have `raise NotImplementedError`, and after you finish the coding, please delete or comment out `raise NotImplementedError`."]},{"cell_type":"markdown","id":"f056b4ff","metadata":{"id":"f056b4ff"},"source":["## Library imports"]},{"cell_type":"code","execution_count":11,"id":"rW_t4sONlu_U","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rW_t4sONlu_U","outputId":"53cd1790-ecd5-402c-a65a-e6657a3f38a4","executionInfo":{"status":"ok","timestamp":1701045189610,"user_tz":300,"elapsed":35783,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.2)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.3)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.1.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.7)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.2.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n","Collecting numpy==1.24\n","  Downloading numpy-1.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.2\n","    Uninstalling numpy-1.26.2:\n","      Successfully uninstalled numpy-1.26.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.24.0 which is incompatible.\n","seaborn 0.12.2 requires numpy!=1.24.0,>=1.17, but you have numpy 1.24.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["## This cell only needs to be run once after the environment is created and then it can be commented out\n","!pip install transformers\n","!pip install datasets\n","!pip install pyLDAvis\n","!pip install numpy==1.24 # may be necessary if running on colab only"]},{"cell_type":"code","execution_count":1,"id":"73b47510","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73b47510","outputId":"9faa96b0-1691-4774-83bd-f971b5fe6047","executionInfo":{"status":"ok","timestamp":1701045259906,"user_tz":300,"elapsed":13069,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Version information\n","python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","numpy: 1.24.0\n","pd: 2.1.3\n","torch: 2.1.0+cu118\n","transformers: 4.35.2\n","gensim: 4.3.2\n","pyLDAvis: 3.4.0\n","torchtext: 0.16.0+cpu\n","datasets: 2.15.0\n"]}],"source":["#Import the necessary libraries\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import scipy as sp\n","import sys\n","import re\n","from copy import deepcopy\n","import random\n","from sklearn.metrics import accuracy_score\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","torch.manual_seed(10)\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import transformers\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import gensim\n","import sklearn\n","\n","\n","import pyLDAvis.gensim_models\n","import pickle\n","import pyLDAvis\n","\n","import torchtext\n","import datasets\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","%load_ext autoreload\n","%autoreload 2\n","%reload_ext autoreload\n","\n","# If set to True then all N_EPOCHS will be set to run for one epoch only\n","# Some compute intensive training loop will break after the first batch\n","SHORT = False\n","\n","print('Version information')\n","\n","print('python: {}'.format(sys.version))\n","print('numpy: {}'.format(np.__version__))\n","print('pd: {}'.format(pd.__version__))\n","print('torch: {}'.format(torch.__version__))\n","print('transformers: {}'.format(transformers.__version__))\n","print('gensim: {}'.format(gensim.__version__))\n","print('pyLDAvis: {}'.format(pyLDAvis.__version__))\n","print('torchtext: {}'.format(torchtext.__version__))\n","print('datasets: {}'.format(datasets.__version__))"]},{"cell_type":"markdown","id":"eff26cb3","metadata":{"id":"eff26cb3"},"source":["# Load Dataset"]},{"cell_type":"markdown","id":"837cc1e5","metadata":{"id":"837cc1e5"},"source":["We start by loading both data sets already split into an 80/20 train and test set."]},{"cell_type":"code","execution_count":4,"id":"e2b97025","metadata":{"id":"e2b97025","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701045312390,"user_tz":300,"elapsed":1162,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"8c0def6f-9e03-4950-dae7-5e7eab962231"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","df_train = pd.read_csv('./data/train.csv')\n","df_test = pd.read_csv('./data/test.csv')\n","\n","# Separate dataframes into train and test lists\n","x_train, y_train = list(df_train['headline']), list(df_train['label'])\n","x_test, y_test = list(df_test['headline']), list(df_test['label'])"]},{"cell_type":"markdown","id":"15f2a21c","metadata":{"id":"15f2a21c"},"source":["Below is the number of headlines in the train and test set as well as a sample of the article headlines and its binary label, where 0 is considered not clickbait and 1 is clickbait."]},{"cell_type":"code","execution_count":5,"id":"11e3ebf5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":499},"id":"11e3ebf5","outputId":"57ccb685-8328-4481-f84a-1e95a321d622","executionInfo":{"status":"ok","timestamp":1701045316414,"user_tz":300,"elapsed":125,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of Train Headlines: 19200\n","Number of Test Headlines: 4800\n","\n","\n","Sample Label and Headlines:\n","1: 27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\n","\n","1: 22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\n","\n","0: PepsiCo Profit Falls 43 Percent\n","\n","0: Website of Bill O'Reilly, FOX News commentator, hacked in retribution\n","\n","1: The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\n","\n","\n","Output of Sample Headlines without Print Statement:\n"]},{"output_type":"execute_result","data":{"text/plain":["['27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\\n',\n"," \"22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\\n\",\n"," 'PepsiCo Profit Falls 43 Percent\\n',\n"," \"Website of Bill O'Reilly, FOX News commentator, hacked in retribution\\n\",\n"," 'The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\\n']"]},"metadata":{},"execution_count":5}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","print(f'Number of Train Headlines: {len(x_train)}')\n","print(f'Number of Test Headlines: {len(x_test)}')\n","\n","print('\\n\\nSample Label and Headlines:')\n","x = 105\n","for label, line in zip(y_train[x:x+5], x_train[x:x+5]):\n","    print(f'{label}: {line}')\n","\n","print('\\nOutput of Sample Headlines without Print Statement:')\n","x_train[x:x+5]"]},{"cell_type":"code","execution_count":6,"id":"20a8debc","metadata":{"id":"20a8debc","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701045318822,"user_tz":300,"elapsed":1335,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"f9965f9e-e2f7-4295-d381-49fcc96e0735"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Save test and train as csv\n","df_train_wos = pd.read_csv('./data/train_wos.csv')\n","df_test_wos = pd.read_csv('./data/test_wos.csv')\n","\n","# Separate dataframes into train and test lists\n","x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n","x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])\n","\n","# Numerical label to domain mapping\n","wos_label = {0:'CS', 1:'ECE', 2:'Civil', 3:'Medical'}\n","# Numerical label to Numerical mapping\n","label_mapping = {0:0, 1:1, 4:2, 5:3}\n","\n","for i, label in enumerate(y_train_wos):\n","    y_train_wos[i] = label_mapping[label]\n","for i, label in enumerate(y_test_wos):\n","    y_test_wos[i] = label_mapping[label]"]},{"cell_type":"code","execution_count":7,"id":"d24ac5b6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":874},"id":"d24ac5b6","outputId":"5f2bf731-89ed-45fc-b4f4-ded77bb6a2ed","executionInfo":{"status":"ok","timestamp":1701045319138,"user_tz":300,"elapsed":167,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of Train Articles: 1600\n","Number of Test Articles: 400\n","\n","Label Key: {0: 'CS', 1: 'ECE', 2: 'Civil', 3: 'Medical'}\n","\n","Sample Label and Articles:\n","\n","0 - CS: An efficient procedure for calculating the electromagnetic fields in multilayered cylindrical structures is reported in this paper. Using symbolic computation, spectral Green's functions, suitable for numerical implementations are determined in compact and closed forms. Applications are presented for structures with two dielectric layers.\n","\n","1 - ECE: A multifunctional platform based on the microhotplate was developed for applications including a Pirani vacuum gauge, temperature, and gas sensor. It consisted of a tungsten microhotplate and an on-chip operational amplifier. The platform was fabricated in a standard complementary metal oxide semiconductor (CMOS) process. A tungsten plug in standard CMOS process was specially designed as the serpentine resistor for the microhotplate, acting as both heater and thermister. With the sacrificial layer technology, the microhotplate was suspended over the silicon substrate with a 340 nm gap. The on-chip operational amplifier provided a bias current for the microhotplate. This platform has been used to develop different kinds of sensors. The first one was a Pirani vacuum gauge ranging from 10(-1) to 10(5) Pa. The second one was a temperature sensor ranging from -20 to 70 degrees C. The third one was a thermal-conductivity gas sensor, which could distinguish gases with different thermal conductivities in constant gas pressure and environment temperature. In the fourth application, with extra fabrication processes including the deposition of gas-sensitive film, the platform was used as a metal-oxide gas sensor for the detection of gas concentration.\n","\n","2 - Civil: Artificial neural networks have been effectively used in various civil engineering fields, including construction management and labour productivity. In this study, the performance of the feed forward neural network (FFNN) was compared with radial basis neural network (RBNN) in modelling the productivity of masonry crews. A variety of input factors were incorporated and analysed. Mean absolute percentage error (MAPE) and correlation coefficient (R) were used to evaluate model performance. Research results indicated that the neural computing techniques could be successfully employed in modelling crew productivity. It was also found that successful models could be developed with different combinations of input factors, and several of the models which excluded one or more input factors turned out to be better than the baseline models. Based on the MAPE values obtained for the models, the RBNN technique was found to be better than the FFNN technique, although both slightly overestimated the masons' productivity.\n","\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","print(f'Number of Train Articles: {len(x_train_wos)}')\n","print(f'Number of Test Articles: {len(x_test_wos)}')\n","\n","print('\\nLabel Key:', wos_label)\n","\n","print('\\nSample Label and Articles:\\n')\n","x = 107\n","for label, line in zip(y_train_wos[x:x+3], x_train_wos[x:x+3]):\n","    print(f'{label} - {wos_label[label]}: {line}')"]},{"cell_type":"markdown","id":"p7tZwLxqeexZ","metadata":{"id":"p7tZwLxqeexZ"},"source":["# Q1: Classification with LSTM [15pts]\n","\n","We will be using an LSTM (Long Short-Term Memory Network) for classification. The architecture of our model looks like :\n","\n","<p align=\"center\"><img src=\"https://www.tensorflow.org/static/text/tutorials/images/bidirectional.png\" width=\"75%\" align=\"center\"></p>\n","\n","For more details on LSTM, please refer to class lectures.\n","\n","Use an Embedding layer, followed by a LSTM layer, and a linear layer.\n","\n","We will then classify the Clickbait and Web of science dataset for this task."]},{"cell_type":"markdown","id":"afb9f399","metadata":{"id":"afb9f399"},"source":["## 1.1 : Implementing the LSTM Model [10 pts]\n","\n","In the **lstm.py** file complete the following functions:\n","\n","* **\\_\\_init__**\n","* **forward**\n","\n","We have included local tests in 1.2.2 for you to test your implementation\n"]},{"cell_type":"markdown","id":"0u3kMUGkfKQJ","metadata":{"id":"0u3kMUGkfKQJ"},"source":["### 1.1.1 : Pre-Processing Data [No Points]\n","\n","Run the cell below to load functions for building vocabulary and tokenizing the sentences."]},{"cell_type":"code","execution_count":8,"id":"V9nm3tqws5uX","metadata":{"id":"V9nm3tqws5uX","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701045321427,"user_tz":300,"elapsed":722,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"04a06837-ff68-4917-e967-9947993a107d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from torchtext.data import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","import torchtext\n","\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","def build_vocabulary(datasets):\n","    for dataset in datasets:\n","        for text in dataset:\n","            yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(build_vocabulary([x_train]), min_freq=1, specials=[\"<UNK>\"])\n","vocab.set_default_index(vocab[\"<UNK>\"])\n","\n","vocab_wos = build_vocab_from_iterator(build_vocabulary([x_train_wos]), min_freq=1, specials=[\"<UNK>\"])\n","vocab_wos.set_default_index(vocab[\"<UNK>\"])"]},{"cell_type":"markdown","id":"d49eab4c","metadata":{"id":"d49eab4c"},"source":["## 1.2 : Classifying Clickbait Dataset using LSTM [5 Pts]\n","\n","Run the cells below to classify the Clickbait train and test datasets using the LSTM functions that you have implemented.\n","\n","**An accuracy of more than 85% is acceptable.**"]},{"cell_type":"markdown","id":"63bd7b32","metadata":{"id":"63bd7b32"},"source":["### 1.2.1 : Create the Dataloaders [No Points]"]},{"cell_type":"code","execution_count":9,"id":"lF9923wLtu8i","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"lF9923wLtu8i","outputId":"fd165157-3d51-411c-a40d-a4bda5b1794d","executionInfo":{"status":"ok","timestamp":1701045324583,"user_tz":300,"elapsed":130,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from torch.utils.data import DataLoader\n","\n","max_words = max(map(len, x_train))\n","\n","def vectorize_batch(batch):\n","    Y, X = list(zip(*batch))\n","    X = [vocab(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n","    X_len = [len(text) for text in X]\n","    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n","    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)\n"]},{"cell_type":"code","execution_count":10,"id":"d5BVAxqdw93-","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"d5BVAxqdw93-","outputId":"b196502f-66d0-49b7-d4b1-a0381ba5d680","executionInfo":{"status":"ok","timestamp":1701045325146,"user_tz":300,"elapsed":155,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n","test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n","\n","train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"]},{"cell_type":"markdown","id":"a1409989","metadata":{"id":"a1409989"},"source":["### 1.2.2: Local Tests for LSTM Functions [No Points]\n","You may test your implementation of the LSTM functions contained in **lstm.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."]},{"cell_type":"code","execution_count":12,"id":"be3ba295","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"be3ba295","executionInfo":{"status":"ok","timestamp":1701045333863,"user_tz":300,"elapsed":333,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"cca9af3e-7cd7-46db-87bf-48925e6d37f0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Local Tests for LSTM Implementation \n","\n","Your forward works as expected: True\n"]}],"source":["# ###############################\n","# ### DO NOT CHANGE THIS CELL ###\n","# ###############################\n","\n","from lstm import LSTM\n","from local_tests.lstm_test import LSTM_Test\n","torch.manual_seed(10)\n","\n","local_test = LSTM_Test()\n","lstm_model = LSTM(vocab, num_classes=2)\n","lstm_model.load_state_dict(torch.load('./local_tests/basic_lstm_model.pt'))    # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n","lstm_model.eval()\n","\n","# creating a vectorized batch from the sample datapoints\n","local_test_dataset = list(map(lambda y, x: (y, x), local_test.output_labels, local_test.input_sequences))\n","X_localtest, X_len_localtest, _ = vectorize_batch(local_test_dataset)\n","\n","print('Local Tests for LSTM Implementation \\n')\n","# Local test for forward\n","output = lstm_model.forward(X_localtest, X_len_localtest)\n","forward_test = (output.shape == local_test.output.shape) and (torch.allclose(output, local_test.output, rtol=0.0001, atol=0.0001))\n","print('Your forward works as expected:', forward_test)"]},{"cell_type":"markdown","id":"T26p33LjgADU","metadata":{"id":"T26p33LjgADU"},"source":["### 1.2.3 : Train and Evaluate on the Clickbait dataset [5 Pts]\n","\n","**You must reach an accuracy of >= 85% to receive credit for this section..**\n"]},{"cell_type":"code","execution_count":13,"id":"eeACJO1IgVgD","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eeACJO1IgVgD","outputId":"e2689adc-c505-4e1b-d0f8-5a2c9bcc3c59","executionInfo":{"status":"ok","timestamp":1701045335116,"user_tz":300,"elapsed":327,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":14,"id":"fHm7mfxWgdYx","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"fHm7mfxWgdYx","outputId":"eda54616-dccf-46ff-95c3-69750eeed560","executionInfo":{"status":"ok","timestamp":1701045352450,"user_tz":300,"elapsed":16921,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 6.547718\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 1.798304\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 14.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 0.710906\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 3: 0.245476\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.79it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 4: 0.103765\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from lstm import LSTM\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 2\n","\n","model = LSTM(vocab, num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","N_EPOCHS = 5 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_len, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_len)\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":15,"id":"5keiILuVyVj6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"5keiILuVyVj6","outputId":"8564398d-ae00-4d98-9757-7d7c3c04f3ae","executionInfo":{"status":"ok","timestamp":1701045352742,"user_tz":300,"elapsed":294,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on Clickbait Dataset using LSTM  : 0.967\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_len, Y in test_loader:\n","        X = X.to(device)\n","        outputs = model(X, X_len)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on Clickbait Dataset using LSTM  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"eFkZ4M2dTaPd","metadata":{"id":"eFkZ4M2dTaPd"},"source":["### ðŸ¦¥ <font color='darkred'>Submit these files to Gradescope</font>\n","**Run the cell below to save the state of your model. You will be required to upload the `best_lstm_model.pt` file that is saved in the `outputs folder` and the `lstm.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 85% on the above test dataset to receive credit for this section.**"]},{"cell_type":"code","execution_count":16,"id":"yuEqLNN3S6NA","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"yuEqLNN3S6NA","outputId":"7906dea7-54fc-42ec-8c8d-0319536d9e35","executionInfo":{"status":"ok","timestamp":1701045353408,"user_tz":300,"elapsed":671,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","torch.save(model.state_dict(), './outputs/best_lstm_model.pt')"]},{"cell_type":"markdown","id":"KUlYQ1qc7q23","metadata":{"id":"KUlYQ1qc7q23"},"source":["## 1.3 : Classifying Web of Science Dataset using LSTM [No Points]\n","\n","Run the cells below to classify the Web of Science train and test datasets using the lstm functions that you have implemented. You should observe an accuracy of more than 40%"]},{"cell_type":"markdown","id":"08506346","metadata":{"id":"08506346"},"source":["### 1.3.1 : Create the Dataloaders [No Points]"]},{"cell_type":"code","execution_count":17,"id":"hio3CfOl7uPz","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"hio3CfOl7uPz","outputId":"f10e9844-e6db-47d7-a4f1-60e622fdd32f","executionInfo":{"status":"ok","timestamp":1701045353408,"user_tz":300,"elapsed":4,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","max_words = max(map(len, x_train_wos))\n","\n","def vectorize_batch(batch):\n","    Y, X = list(zip(*batch))\n","    X = [vocab_wos(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n","    X_len = [len(text) for text in X]\n","    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n","    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"]},{"cell_type":"code","execution_count":18,"id":"vjwukuZr9zoG","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"vjwukuZr9zoG","outputId":"baf524f8-977a-4d20-f33a-542f924a8034","executionInfo":{"status":"ok","timestamp":1701045353558,"user_tz":300,"elapsed":153,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n","test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n","\n","train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=vectorize_batch)"]},{"cell_type":"markdown","id":"c42f5f93","metadata":{"id":"c42f5f93"},"source":["### 1.3.2 Train and Evaluate on the Web of Science Dataset [No Points]"]},{"cell_type":"code","execution_count":19,"id":"taYXndEp-K4f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731},"id":"taYXndEp-K4f","outputId":"26af546b-06d9-4b6b-e8aa-c805afe9f24e","executionInfo":{"status":"ok","timestamp":1701045385055,"user_tz":300,"elapsed":31501,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  7.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 17.730795\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  9.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 17.067045\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  9.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 16.460056\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  9.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 3: 15.760631\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 4: 15.091935\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 5: 14.114826\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 6: 13.049757\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  9.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 7: 11.780611\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 8: 10.286781\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 9: 9.146650\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 10: 8.352035\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 11: 7.511066\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  9.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 12: 6.068389\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 13: 5.045795\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 14: 4.757475\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 15: 4.005289\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 16: 3.193915\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 17: 2.588529\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 18: 2.277907\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  8.20it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 19: 1.821465\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from lstm import LSTM\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 4\n","\n","model = LSTM(vocab_wos, num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","N_EPOCHS = 20 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_len, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_len)\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if SHORT:\n","            break\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":20,"id":"BhJDy8Q6_eAO","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"BhJDy8Q6_eAO","outputId":"28a2295a-fc98-41a9-8ff1-45f3751ed640","executionInfo":{"status":"ok","timestamp":1701045385569,"user_tz":300,"elapsed":517,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on WoS Dataset using LSTM  : 0.562\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_len, Y in test_loader:\n","        X = X.to(device)\n","        outputs = model(X, X_len)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","        if SHORT:\n","            break\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on WoS Dataset using LSTM  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"BcricBIjPfl9","metadata":{"id":"BcricBIjPfl9"},"source":["**NOTE** : LSTM alone is not able to perform good on the WoS dataset and that can be attributed to the very limited data with large vocabulary and lack of embedding structure."]},{"cell_type":"markdown","id":"2wguPmjyAuv1","metadata":{"id":"2wguPmjyAuv1"},"source":["# Q2: Classification with LSTM + Attention [15pts]\n","\n","\n","A potential issue with a vanilla LSTM approach is that a neural network needs to be able to compress all of the necessary information of a source sentence into a fixed-length vector. This may make it difficult for the neural network to cope with long sentences, especially those that are longer than the sentences in the training corpus. The Attention mechanism helps to look at all of the hidden states from the sequence for making predictions unlike the vanilla approach.\n","\n","In this task, we will be implementing LSTM with Attention.\n","\n","<p align=\"center\"><img src=\"./data/images/q2_attention.png\" width=\"75%\" align=\"center\"></p>\n","\n","Please refer to lecture for more details.\n","\n","You will be extending the LSTM model and incorporating attention on top of it.\n","\n","We will then classify the Clickbait and Web of science dataset for this task."]},{"cell_type":"markdown","id":"9ec7cc40","metadata":{"id":"9ec7cc40"},"source":["## 2.1 : Implementing the LSTM + Attention Model [10 Points]\n","\n","In the **attention.py** file complete the following functions:\n","\n","* **\\_\\_init__**\n","* **forward_lstm**\n","* **forward_attention**\n","* **forward_context**\n","* **forward**\n","\n","We have included local tests in 2.2.2 for you to test your implementation"]},{"cell_type":"markdown","id":"-aXMEJ5bEzUn","metadata":{"id":"-aXMEJ5bEzUn"},"source":["## 2.2 : Classifying Clickbait Dataset using LSTM with Attention [No Points]\n","\n","Run the cells below to classify the Clickbait train and test datasets using the attention functions that you have implemented. You should observe an accuracy of more than 88%."]},{"cell_type":"markdown","id":"7d142f27","metadata":{"id":"7d142f27"},"source":["### 2.2.1 : Create the Dataloaders [No Points]"]},{"cell_type":"code","execution_count":38,"id":"em2IUtRXB8NR","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"em2IUtRXB8NR","outputId":"6628ecc1-9e74-4f03-cc2f-981c79a82d78","executionInfo":{"status":"ok","timestamp":1701045893189,"user_tz":300,"elapsed":143,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","max_words = max(map(len, x_train))\n","\n","def vectorize_batch(batch):\n","    Y, X = list(zip(*batch))\n","    X = [vocab(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n","    X_len = [len(text) for text in X]\n","    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n","    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"]},{"cell_type":"code","execution_count":39,"id":"VKsw-S0QFrWj","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"VKsw-S0QFrWj","outputId":"0de66897-d483-4cca-acef-3e1bcf5507af","executionInfo":{"status":"ok","timestamp":1701045894211,"user_tz":300,"elapsed":293,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n","test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n","\n","train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"]},{"cell_type":"markdown","id":"c76cc2fd","metadata":{"id":"c76cc2fd"},"source":["### 2.2.2 : Local Tests for LSTM with Attention Functions [No Points]\n","You may test your implementation of the LSTM with Attention functions contained in **attention.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."]},{"cell_type":"code","execution_count":40,"id":"06ea5962","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"06ea5962","executionInfo":{"status":"ok","timestamp":1701045895800,"user_tz":300,"elapsed":328,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"30fda88e-5171-4f0f-d57e-647efe4419a7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Local Tests for LSTM + Attention Implementation \n","\n","Your forward_lstm works as expected:  True\n","Your forward_attention works as expected:  True\n","Your forward_context works as expected:  True\n","Your forward works as expected:  True\n"]}],"source":["# ###############################\n","# ### DO NOT CHANGE THIS CELL ###\n","# ###############################\n","\n","from attention import Attention\n","from local_tests.attention_test import Attention_Test\n","torch.manual_seed(10)\n","\n","local_test = Attention_Test()\n","attention_model = Attention(vocab, num_classes=2)\n","attention_model.load_state_dict(torch.load('./local_tests/basic_attention_model.pt'))   # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n","attention_model.eval()\n","\n","# creating a vectorized batch from the sample datapoints\n","local_test_dataset = list(map(lambda y, x: (y, x), local_test.output_labels, local_test.input_sequences))\n","X_localtest, X_len_localtest, _ = vectorize_batch(local_test_dataset)\n","# print(X_localtest.shape, X_len_localtest)\n","\n","print('Local Tests for LSTM + Attention Implementation \\n')\n","\n","# Local test for forward_lstm\n","output, hidden = attention_model.forward_lstm(X_localtest, X_len_localtest)\n","forward_lstm_shape_test = (output.shape == local_test.lstm_output.shape) and (hidden.shape == local_test.lstm_hidden.shape)\n","forward_lstm_value_test = (torch.allclose(output, local_test.lstm_output, rtol=0.001, atol=0.001)) and (torch.allclose(hidden, local_test.lstm_hidden, rtol=0.0001, atol=0.0001))\n","print('Your forward_lstm works as expected: ', (forward_lstm_shape_test and forward_lstm_value_test))\n","\n","# Local test for forward_attention\n","attn_weights = attention_model.forward_attention(local_test.lstm_output, local_test.lstm_hidden)\n","forward_attention_test = (attn_weights.shape == local_test.attention_weights.shape) and (torch.allclose(attn_weights, local_test.attention_weights, rtol=0.0001, atol=0.0001))\n","print('Your forward_attention works as expected: ', forward_attention_test)\n","\n","# Local test for forward_context\n","context_output = attention_model.forward_context(local_test.lstm_output, local_test.attention_weights, local_test.lstm_hidden)\n","forward_context_test = (context_output.shape == local_test.context_output.shape) and (torch.allclose(context_output, local_test.context_output, rtol=0.0001, atol=0.0001))\n","print('Your forward_context works as expected: ', forward_context_test)\n","\n","# Local test for forward\n","output = attention_model.forward(X_localtest, X_len_localtest)\n","forward_test = (output.shape == local_test.output.shape) and (torch.allclose(output, local_test.output, rtol=0.0001, atol=0.0001))\n","print('Your forward works as expected: ', forward_test)"]},{"cell_type":"markdown","id":"3f5acf73","metadata":{"id":"3f5acf73"},"source":["### 2.2.3: Train and Evaluate on the Clickbait Dataset [No Points]\n"]},{"cell_type":"code","execution_count":41,"id":"de701556","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"de701556","executionInfo":{"status":"ok","timestamp":1701045899000,"user_tz":300,"elapsed":302,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"6c7ad82d-1cbc-4b2c-fea4-3a2046ba6b47"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":42,"id":"NlCGM3xIFM7V","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"NlCGM3xIFM7V","outputId":"6d2b5bec-a294-49c6-afb2-e98a3ccc7c8d","executionInfo":{"status":"ok","timestamp":1701045908038,"user_tz":300,"elapsed":8352,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  6.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 5.614263\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 1.547896\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 14.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 0.502205\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 3: 0.155966\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.96it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 4: 0.059580\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from attention import Attention\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 2\n","\n","model = Attention(vocab, num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","N_EPOCHS = 5 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_len, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_len)\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":43,"id":"bZ_DZGV8vH6J","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bZ_DZGV8vH6J","outputId":"ce94abcb-c49b-4834-afe3-1551fc882383","executionInfo":{"status":"ok","timestamp":1701045908185,"user_tz":300,"elapsed":150,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on Clickbait Dataset using LSTM with Attention  : 0.960\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_len, Y in test_loader:\n","        X = X.to(device)\n","        outputs = model(X, X_len)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on Clickbait Dataset using LSTM with Attention  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"DUjkG5eOvYkS","metadata":{"id":"DUjkG5eOvYkS"},"source":["## 2.3 : Classifying Web of Science Dataset using LSTM with Attention [5 Pts]\n","\n","Run the cells below to classify the Web of Science train and test datasets using the attention functions that you have implemented.\n","\n","**You must reach an accuracy of >=50% to receive credit for this section.**\n"]},{"cell_type":"markdown","id":"9e258e7f","metadata":{"id":"9e258e7f"},"source":["### 2.3.1 : Create the Dataloaders [No Points]"]},{"cell_type":"code","execution_count":44,"id":"BjLqVQ7Tva-J","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"BjLqVQ7Tva-J","outputId":"4c76ea08-b3f5-48e5-da97-72bfdd0694ba","executionInfo":{"status":"ok","timestamp":1701045908186,"user_tz":300,"elapsed":4,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","max_words = max(map(len, x_train_wos))\n","\n","def vectorize_batch(batch):\n","    Y, X = list(zip(*batch))\n","    X = [vocab_wos(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n","    X_len = [len(text) for text in X]\n","    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n","    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"]},{"cell_type":"code","execution_count":45,"id":"h7sDWvJ4vext","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"h7sDWvJ4vext","outputId":"3292e747-59ff-4b91-ba4f-497de8f37dab","executionInfo":{"status":"ok","timestamp":1701045908186,"user_tz":300,"elapsed":4,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n","test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n","\n","train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=vectorize_batch)"]},{"cell_type":"markdown","id":"0e4c8433","metadata":{"id":"0e4c8433"},"source":["### 2.3.2 : Train and Evaluate on the Web of Science dataset [5 Pts]"]},{"cell_type":"code","execution_count":46,"id":"d936c32e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"d936c32e","executionInfo":{"status":"ok","timestamp":1701045910036,"user_tz":300,"elapsed":119,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"bfa9d90f-962e-4245-8923-4911f52540b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":47,"id":"CpBf0WXrvkXs","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":910},"id":"CpBf0WXrvkXs","outputId":"1aecf9a0-adb9-4a16-8f28-9b2ce148fc94","executionInfo":{"status":"ok","timestamp":1701045969729,"user_tz":300,"elapsed":58883,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 17.733009\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 16.586543\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 14.939132\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 3: 13.468132\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 4: 11.825914\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 5: 10.476588\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 6: 8.932832\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 7: 7.476078\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 8: 6.792090\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 9: 5.581758\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 10: 4.341088\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 11: 3.535834\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 12: 2.372961\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 13: 1.712926\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  6.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 14: 1.193936\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 15: 0.771641\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 16: 0.493638\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 17: 0.266424\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 18: 0.150452\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 19: 0.100295\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 20: 0.079579\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 21: 0.056026\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 22: 0.966269\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 23: 1.458524\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.34it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 24: 0.734346\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from attention import Attention\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 4\n","\n","model = Attention(vocab_wos, num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","N_EPOCHS = 25 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_len, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_len)\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if SHORT:\n","            break\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":48,"id":"ZtFRZKs2vs72","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ZtFRZKs2vs72","outputId":"b5a07b47-81aa-4edc-d96d-9aca3d6b14d0","executionInfo":{"status":"ok","timestamp":1701045969900,"user_tz":300,"elapsed":176,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on WoS Dataset using LSTM with Attention : 0.540\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_len, Y in test_loader:\n","        X = X.to(device)\n","        outputs = model(X, X_len)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","        if SHORT:\n","            break\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on WoS Dataset using LSTM with Attention : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"GzlR7g_Ad7sc","metadata":{"id":"GzlR7g_Ad7sc"},"source":["### ðŸ¦¦ <font color='darkred'>Submit these files to Gradescope</font>\n","**Run the cell below to save the state of your model. You will be required to upload the `best_attention_model.pt` file that is saved in the `outputs folder` and the `attention.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 50% on the above test dataset to receive credit for this section.**"]},{"cell_type":"code","execution_count":49,"id":"inleyjcpd8SA","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"inleyjcpd8SA","outputId":"aaae239c-dee7-4476-9793-0e7f40ce8022","executionInfo":{"status":"ok","timestamp":1701045992067,"user_tz":300,"elapsed":798,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","torch.save(model.state_dict(), './outputs/best_attention_model.pt')"]},{"cell_type":"markdown","id":"Xb_WxXtZ58E_","metadata":{"id":"Xb_WxXtZ58E_"},"source":["# Q3: Classification with BERT [15pts]\n","\n","The transformer neural network is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. In a transformer, we can pass all the words of a sentence and determine the word embedding simultaneously.\n","\n","<p align=\"center\"><img src=\"https://d2l.ai/_images/bert-one-seq.svg\" width=\"75%\" align=\"center\"></p>\n","\n","We will be using BERT (Bidirectional Encoder Representations from Transformers) pre-trained models for embeddings. BERT architecture consists of several Transformer encoders stacked together. Each Transformer encoder encapsulates two sub-layers: a self-attention layer and a feed-forward layer.\n","\n","The details on BERT can be referred from the paper : [BERT: Pre-training of Deep Bidirectional Transformers for\n","Language Understanding](https://arxiv.org/pdf/1810.04805.pdf).\n","\n","We will be using the BERT embeddings and a fully connected linear layer to perform classification.\n","\n","We will then classify the Clickbait and Web of science dataset for this task.\n"]},{"cell_type":"markdown","id":"c90b4711","metadata":{"id":"c90b4711"},"source":["## 3.1 : Implementing the BERT Classifier [10pts]\n","\n","In the **bert.py** file complete the following functions:\n","\n","* **\\_\\_init__**\n","* **forward**"]},{"cell_type":"markdown","id":"c9ff5182","metadata":{"id":"c9ff5182"},"source":["## 3.2: Local Tests for BERT Functions [No Points]\n","You may test your implementation of the BERT functions contained in **bert.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."]},{"cell_type":"code","execution_count":50,"id":"893d9e55","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["9211e2182dbc48c08aa93bac6d3206c3","a671306612a14b6cb0c9528e6fb9cddf","77975ff29d2f4a6ab6aab030aa19efac","ea2cf3910d9448ea93a65e80edff3b47","4160b43446f94b3ca6cb917fd2e1d510","fa28abca94164a6e9e15ad9fab7075af","2b0051b414cb416792a34a33f4f6f055","4c7e925499104388b209b68b4d46a8d8","29d830aa304b4c0e962e4b412ba66d26","49bdaca2324b4764b38742577f3aa23c","e0fad9fffae44f7394628bd0aa9f3a46","c8f0bfedcd114928a95ed3d56aa4fda3","2ddec7bd60944e259cdf807360b3c5b2","f988bcaa2d134768a9ec0a9b1d1b4a89","ec809a3cac544f5fb7249f9a28a073ef","e32c7a4cf7e5446180dbdae08c351dce","d86e694153f04c2f9ec745746e3009de","61b23b7cb4644ce38126f6c807c96b0e","05f3f577ee774f828ecef966ad318f98","c8c23177ce074d0aaa706d8effdbc96a","300ed7ffdfda4492b98e1e6daca5fc47","9a141c8603a548e5b179b4fa4fffb8e2"]},"id":"893d9e55","executionInfo":{"status":"ok","timestamp":1701046007539,"user_tz":300,"elapsed":11303,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"53009bf7-ca09-48d1-fa97-0e082e997493"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Local Tests for BERT Functions \n","\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9211e2182dbc48c08aa93bac6d3206c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f0bfedcd114928a95ed3d56aa4fda3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Your forward works as expected: True\n"]}],"source":["# ###############################\n","# ### DO NOT CHANGE THIS CELL ###\n","# ###############################\n","\n","from bert import BERTClassifier\n","from local_tests.bert_test import BERT_Test\n","\n","local_test = BERT_Test()\n","\n","print('Local Tests for BERT Functions \\n')\n","\n","# Instantiate BERTClassifier and load linear weights for local tests\n","torch.manual_seed(10)\n","student_bert = BERTClassifier(2)\n","basic_bert_linear = torch.load('./local_tests/basic_bert_linear.pt')\n","\n","# If loading the state dict causes an error, then there may be an issue with your layer name or shape\n","student_bert.linear.load_state_dict(basic_bert_linear)\n","\n","# Local test for forward\n","student_bert.eval()\n","outputs = student_bert(local_test.inputs, local_test.masks)\n","forward_test = (torch.allclose(outputs, local_test.outputs, rtol=0.0001, atol=0.0001) and (outputs.shape == local_test.outputs.shape))\n","print('Your forward works as expected:', forward_test)"]},{"cell_type":"markdown","id":"_4TIp-LNEYUd","metadata":{"id":"_4TIp-LNEYUd"},"source":["## 3.3 : Initialize Tokenizer [No Points]\n","\n","Run the below cells to initalizer tokenizer for the pretrained BERT model."]},{"cell_type":"code","execution_count":51,"id":"u2tFeYZ96BAn","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169,"referenced_widgets":["af84ab783df2417e8861ef689d0052ef","526217380908426fb0fa13af44f2465f","41d23513e6784fccadfbffd52188ef2d","58255d47fa334bca81e68467b811c779","534db700d0964f8f8f5266ec6df57e9f","9b75b4e5e5a24f5e8352a5e15b7a6b26","1f81054c2a784fcc9de6449b763e4cc1","31292cae39f440509eaf538015618192","2db73d6aef3f46f8aebe2b74c029f5ff","5c23c5b166e6492eb28779468b94b293","e6d0a80dae284549b2b2603bc75442cb","83cef0fc947841098ca793536fde2663","385ebf6471c54900b379a4512d302ed9","69b44c70d4f54bdb8b297be21a85567c","9d3f686e7d004741b4d10e5d00109ee0","ab8554dda7264b269d36db63c8647ef3","c10c0c7037364edba1998937ded292f7","a38a5767d09f41d6be9115fb87c4763c","c4c6cc572790472896e77672d0ed7eeb","b75d6815f11e416694e94146ab92491c","9c66c38013f34a1b8e9a0e5719922693","402a4f745ec346c39fa57a60302f149d","307a5b70deae460cbee27e1b436bfe17","d5eb23fbe51a461f8599201ea318cde0","025b5cac04ad4ebaba20af904c39f6df","2fdad60efa3f4b8c9385d22e7df787c2","40af967212ad462da7060eec18fbd769","76a3130810414083af6045b973466d95","725f3424b0f849cfa590bfc9447f9f61","1c67987bc25c476bb3c4a009925397bc","3cc2afecbbe4432b9c5dc18679e1a795","761432352b7643199e3c568565c7cf1c","651812e83a87494b84de4d587f927aed"]},"id":"u2tFeYZ96BAn","outputId":"8bdf2a75-c7ab-460c-8777-326166afba0e","executionInfo":{"status":"ok","timestamp":1701046008831,"user_tz":300,"elapsed":1297,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af84ab783df2417e8861ef689d0052ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83cef0fc947841098ca793536fde2663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"307a5b70deae460cbee27e1b436bfe17"}},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":52,"id":"C0CbKHDy6snl","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"C0CbKHDy6snl","outputId":"20ec04e7-38c2-4ab2-e009-ade32cae7bc0","executionInfo":{"status":"ok","timestamp":1701046008832,"user_tz":300,"elapsed":9,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","def vectorize_batch(batch):\n","    Y, X = list(zip(*batch))\n","    X = tokenizer(X, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\")\n","    input_ids, attention_mask = X['input_ids'], X['attention_mask']\n","    return input_ids, attention_mask, torch.tensor(Y)"]},{"cell_type":"markdown","id":"cmCcF-5gEp9y","metadata":{"id":"cmCcF-5gEp9y"},"source":["## 3.4 : Classifying Clickbait Dataset using BERT [5pts]\n","\n","Run the below cell to classify the Clickbait train and test dataset using the bert functions that you have already implemented in 3.\n","\n","**You must reach an accuracy of >= 90% to receive credit for this section.**"]},{"cell_type":"code","execution_count":53,"id":"yWvwUFsa8eix","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"yWvwUFsa8eix","outputId":"8f7b2264-9e3f-490a-fab0-0317f9f11fd8","executionInfo":{"status":"ok","timestamp":1701046009001,"user_tz":300,"elapsed":175,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n","test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=32, collate_fn=vectorize_batch)"]},{"cell_type":"code","execution_count":54,"id":"7c75f738","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7c75f738","executionInfo":{"status":"ok","timestamp":1701046009002,"user_tz":300,"elapsed":6,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"66da35a2-3cea-40bc-f230-f0587566b8c3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":55,"id":"S8mw5EEV8sfX","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"S8mw5EEV8sfX","outputId":"4e9a2924-705f-4ff8-cf78-fe58ffdb38cd","executionInfo":{"status":"ok","timestamp":1701047205809,"user_tz":300,"elapsed":1196812,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [06:38<00:00,  1.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 46.016946\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [06:37<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 14.448872\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [06:37<00:00,  1.51it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 15.247208\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from bert import BERTClassifier\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 2\n","\n","model = BERTClassifier(num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","N_EPOCHS = 3 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_mask, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        X_mask = X_mask.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_mask)\n","\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if SHORT:\n","            break\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":56,"id":"9wPLenolvCIF","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9wPLenolvCIF","outputId":"0124eb58-ea4d-4380-83ce-1ec04d20b463","executionInfo":{"status":"ok","timestamp":1701047242261,"user_tz":300,"elapsed":36485,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on Clickbait Dataset using BERT : 0.983\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_mask, Y in test_loader:\n","        X = X.to(device)\n","        X_mask = X_mask.to(device)\n","        outputs = model(X, X_mask)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","        if SHORT:\n","            break\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on Clickbait Dataset using BERT : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"EdT8WwfLFjbK","metadata":{"id":"EdT8WwfLFjbK"},"source":["### ðŸ¨ <font color='darkred'>Submit this file to Gradescope</font><a id='find_chicken'></a>\n","**Run the cell below to save the results of your model. You will be required to upload the `bert_clickbait.pkl` file that is saved in the `outputs folder` to Gradescope for accuracy evaluation. You must reach an accuracy of >= 90% on the above test dataset to receive credit for this section.**"]},{"cell_type":"code","execution_count":57,"id":"c1NFgLw4FdnP","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"c1NFgLw4FdnP","outputId":"e03a8de5-8747-4459-90e8-46ebfbbaa68f","executionInfo":{"status":"ok","timestamp":1701047242263,"user_tz":300,"elapsed":35,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","preds = F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy()\n","\n","with open('./outputs/bert_clickbait.pkl', 'wb') as fp:\n","    pickle.dump(preds, fp)"]},{"cell_type":"markdown","id":"51PQ7bseI4FE","metadata":{"id":"51PQ7bseI4FE"},"source":["## 3.5 : Classifying Web of Science Dataset using BERT [5pts]\n","\n","Run the below cell to classify the Web of Science train and test dataset using the bert functions that you have already implemented in 3.\n","\n","**You must reach an accuracy of >= 70% to receive credit for this section.**"]},{"cell_type":"code","execution_count":58,"id":"PUEj2GiJI5ug","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"PUEj2GiJI5ug","outputId":"6149e21b-6f70-4b42-e41f-0de5a77c9be0","executionInfo":{"status":"ok","timestamp":1701047242263,"user_tz":300,"elapsed":27,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n","test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size=32, collate_fn=vectorize_batch)"]},{"cell_type":"code","execution_count":59,"id":"57cb878a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"57cb878a","executionInfo":{"status":"ok","timestamp":1701047242500,"user_tz":300,"elapsed":4,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"e510ce42-fa6a-45ea-c602-7456da2c93b3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":60,"id":"uAxgmvlfJGgH","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"uAxgmvlfJGgH","outputId":"80cc4a86-6fbb-4c49-8301-b9fd57df4147","executionInfo":{"status":"ok","timestamp":1701047431632,"user_tz":300,"elapsed":189135,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 0: 37.354610\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:44<00:00,  1.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 1: 16.997236\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:43<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["loss on epoch 2: 8.165334\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from bert import BERTClassifier\n","from tqdm import tqdm\n","\n","NUM_CLASSES = 4\n","\n","model = BERTClassifier(num_classes=NUM_CLASSES)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","N_EPOCHS = 3 if not SHORT else 1\n","\n","model.train()\n","for epoch in range(N_EPOCHS):\n","    total_loss = 0.0\n","    for X, X_mask, Y in tqdm(train_loader):\n","        X = X.to(device)\n","        X_mask = X_mask.to(device)\n","        Y = Y.to(device)\n","        outputs = model(X, X_mask)\n","\n","        loss = criterion(outputs, Y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if SHORT:\n","            break\n","\n","    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"]},{"cell_type":"code","execution_count":61,"id":"J1CLOYP_JJca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J1CLOYP_JJca","outputId":"a4299ccd-001d-4d7d-ff9d-b60250678dfa","executionInfo":{"status":"ok","timestamp":1701047431632,"user_tz":300,"elapsed":41,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Accuracy on Web of Science Dataset using BERT : 0.833\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sklearn.metrics import accuracy_score\n","\n","with torch.no_grad():\n","    Y_truth, Y_preds = [],[]\n","    for X, X_mask, Y in test_loader:\n","        X = X.to(device)\n","        X_mask = X_mask.to(device)\n","        outputs = model(X, X_mask)\n","\n","        Y_truth.append(Y)\n","        Y_preds.append(outputs)\n","\n","        if SHORT:\n","            break\n","\n","    Y_truth = torch.cat(Y_truth)\n","    Y_preds = torch.cat(Y_preds)\n","\n","print(\"Test Accuracy on Web of Science Dataset using BERT : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"]},{"cell_type":"markdown","id":"eFM_ZryfFSQi","metadata":{"id":"eFM_ZryfFSQi"},"source":["### ðŸ¥ <font color='darkred'>Submit this file to Gradescope</font><a id='find_chicken'></a>\n","**Run the cell below to save the results of your model. You will be required to upload the `bert_wos.pkl` file that is saved in the `outputs folder` to Gradescope for accuracy evaluation. You must reach an accuracy of >= 70% on the above test dataset to receive credit for this section.**"]},{"cell_type":"code","execution_count":62,"id":"qis5XQyTFS43","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"qis5XQyTFS43","outputId":"661d017d-c85c-43ed-89d7-a4244a42f655","executionInfo":{"status":"ok","timestamp":1701047431632,"user_tz":300,"elapsed":35,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","preds = F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy()\n","\n","with open('./outputs/bert_wos.pkl', 'wb') as fp:\n","    pickle.dump(preds, fp)"]},{"cell_type":"markdown","id":"exut2n-_8ZxY","metadata":{"id":"exut2n-_8ZxY"},"source":["# Q4: Sequence Labeling [15pts]\n","\n","Part-of-speech (POS) tagging is a popular Natural Language Processing process which refers to categorizing words in a text (corpus) in correspondence with a particular part of speech, depending on the definition of the word and its context.\n","\n","Named entity recognition (NER) seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n","\n","We will be using BERT (Bidirectional Encoder Representations from Transformers) for sequence labeling. The architecture of the model is shown above in the diagram.\n","\n","We will be using the BERT embeddings and a fully connected linear layer to perform classification.\n","\n","We will then classify using the conll2003 dataset for this task."]},{"cell_type":"markdown","id":"0bc635b5","metadata":{"id":"0bc635b5"},"source":["## 4.1 : Implementing Sequence Labeling [5pts]\n","In the **sequenceLabeling.py** file complete the following functions:\n","\n","* **\\_\\_init__**\n","* **forward**"]},{"cell_type":"markdown","id":"fdceef92","metadata":{"id":"fdceef92"},"source":["## 4.2 : Local Tests for Sequence Labeling Functions [No Points]\n","You may test your implementation of the Sequence Labeling functions contained in **sequenceLabeling.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."]},{"cell_type":"code","execution_count":64,"id":"5c8ccf24","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"5c8ccf24","executionInfo":{"status":"ok","timestamp":1701048064940,"user_tz":300,"elapsed":2947,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"b6e54e71-e125-4104-9165-dd62f376a787"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Local Tests for Sequence Labeling Functions \n","\n","Your forward outputs the expected shape: True\n","Your forward outputs the expected values: True\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sequenceLabeling import SequenceLabeling\n","from local_tests.sequenceLabeling_test import SequenceLabeling_Test\n","\n","local_test = SequenceLabeling_Test()\n","\n","print('Local Tests for Sequence Labeling Functions \\n')\n","\n","# Instantiate SequenceLabeling and load linear weights for local tests\n","torch.manual_seed(10)\n","student_seq = SequenceLabeling(9)\n","basic_seq_linear = torch.load('./local_tests/basic_seq_linear.pt')\n","\n","# If loading the state dict causes an error, then there may be an issue with your layer name or shape\n","student_seq.linear.load_state_dict(basic_seq_linear)\n","\n","# Local test for forward\n","student_seq.eval()\n","outputs = student_seq(local_test.input_ids, local_test.masks, local_test.token_type_ids)\n","forward_test = torch.allclose(outputs, local_test.outputs, rtol=0.0001, atol=0.0001)\n","print('Your forward outputs the expected shape:', outputs.shape == local_test.outputs.shape)\n","print('Your forward outputs the expected values:', forward_test)\n","if not forward_test:\n","    print('If you forward values do not match the expected values but you are matching in shape and are getting the desired scores in 4.5, then no need to worry about the discrepancy.')"]},{"cell_type":"markdown","id":"X3e9zwNXAYIv","metadata":{"id":"X3e9zwNXAYIv"},"source":["## 4.3 : Loading Dataset & Tokenizer [No Points]\n","\n","Run the below cell to download the conll2003 dataset. Each word in the dataset has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE.\n","\n","For more details on the structure and the supported labels, please refer : https://huggingface.co/datasets/conll2003."]},{"cell_type":"code","execution_count":65,"id":"9mm9KV558cuY","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437,"referenced_widgets":["6c72df97f0014d0eb7de6358effc40c3","7156ce28445847c68c0342ecdc2a3b62","b44287d0bdf04a53b3529d859263d14a","f611b563a9994fef95d5cfe591762050","42e179ccad114c519056c89f1c09b022","c5e9f013698f4f6d9386dd7228ec0877","3f2f906dc3ff4b78b959af4f6f777864","d6cd72ed625543648c54107eee8be8d5","9858075adbd544e1b667f8a95239991a","49ea8173beae4a98a6b022cb0665506b","bb07319cc8da4868b7e2cf6767bbc106","ee5fd348200f4615981d831e3ae3640c","7633db7c1c91409cb71abdfc5e8dcf1d","0c1fb45c07da4f32b5d9ae80430c1f0e","bfdb62df3a314b53b0ab1236fe670f43","f61bc0085f2b4d7690805f939c0f6cac","ffec30d4fbf54dbeacc045eca44677bc","dfafb31fd3a043a09540be2417a658cf","23f8883565f448fba1ca8b68e6efa1c4","afa1c80d5a064f0ca4616733da834b50","1a389e72980b4c2da6a936d2ca2216f4","96aabcb6304244fe9ca4a738a3e806d4","51f11b332d5e4f188ef9aaf54024ce4a","de96ce8f4a59459882861491d7250248","21f1c8e59b4543338eb3ac173c6a0fa5","99cf3fd1305642ed85bac577bc914a52","6fd7b535532c493aa834fb07e87088af","a3b5c145b1254070b1634de37ca502dc","3dfcfbfb21ee431b9b30de48e5c651a2","a65c9e4f465b4d2da0e89582e2d4746f","864bf38165b948dc935aaac7d0f2954f","1a714cc040234c39befbddad12945fd9","d45ca1847f9749e8a8bfea7b9c821334","299e8b1093c94919ba864a0001355c8d","a6537cb2626c46d795e68d3043f885f5","c1c40d9b3086495995c5321a01f7a2ec","4bf888b3598341b38e954581160620a6","5797b9761bec4ef090c2e718c72c5c01","6436861a20c04ed7aabc9d618f321edf","e606476122f04ea884993fbed28ae2ed","ba2292e75e2544e390c28229ab3a5a30","c3805394bd0b4de5b9ea7296c37d6866","5fe69b95eb9e4996ae4e4e4f4d54f3d3","7a7fc0c068cc432a8e00b33ab94cc0b9","9c736ea17e30420191bf5cc9001027f3","e425bfb2654649fbb103101c278ba4ba","0b9098e5643d4ec1880c5c3e1417f513","275eb6df3b82480bbf0dc5081d48ef4d","f121af0b91eb484a91258770bb062429","94a3656ac8f840bab314470c7d837d6f","7eb773efaa834b9ca5e8d55ffee7f9f5","7216ffbcbe09452c87974fcdcb4605b8","42c0a3e930a7435a90d1e1193ab228c9","a81c37e9e90248928d7bde069d148140","ed3fbc8ab76f4130872996864ea3a483","d3bd409fe2f24974916f5da96078950e","17cb839e1efe475f99a3000ac11188ec","1f889187a0ed46beb1f972c598958155","3e50cc60da0c4f6bbf8a04ca92f7993e","95a983a4978b4add822eb42c2cc1005f","6c3dc2933a5144c4aa623e31fd40032b","2af3acfc9c8b443aa101544b01dfdb6a","75af02eb79e84a41a95e67cc46893b8e","807fcaf8da9f443794f3fb3f9c5e9f7b","8a5e4e5ba76e4aefa22fa072e6ebb1a3","64d93dfd0c2741728faa0986873ea04d","fe8841175a1f4563b2e87cd6d88e98ad","1fe7325c7f6a4beb993c8dab1063d47c","08b44b132b4b4a6f8d8d2b591f45be8d","285caa3f66834686b53c244aab23b003","904273a7d71f4830af0cde87674f2c54","0613327f65074b4a9170348713e60230","0509e68b0b644c47a127b51531084abe","b618281831eb46c28e8b6c0bd8cbfd52","ebdbe28631d341bd8d4eed6cd1109984","1874872c24da4b5780d009bbc6250fcf","369351e045de4a3abf1c9bb8557b8f82"]},"id":"9mm9KV558cuY","outputId":"ca478945-b861-46b9-f058-7a8a96b9b2b0","executionInfo":{"status":"ok","timestamp":1701048076088,"user_tz":300,"elapsed":7543,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c72df97f0014d0eb7de6358effc40c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5fd348200f4615981d831e3ae3640c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f11b332d5e4f188ef9aaf54024ce4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299e8b1093c94919ba864a0001355c8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c736ea17e30420191bf5cc9001027f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3bd409fe2f24974916f5da96078950e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8841175a1f4563b2e87cd6d88e98ad"}},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from datasets import load_dataset\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","dataset = load_dataset(\"conll2003\")\n","\n","train = dataset['train']\n","val = dataset['validation']\n","test = dataset['test']"]},{"cell_type":"markdown","id":"SmmmwqdHvPiq","metadata":{"id":"SmmmwqdHvPiq"},"source":["## 4.4 :  Pre-process Dataset [No Points]\n","\n","Run the below cells to vectorize the dataset for tokenizers and to intialize the dataloaders."]},{"cell_type":"code","execution_count":66,"id":"gSJmgNdcCWwN","metadata":{"id":"gSJmgNdcCWwN","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701048076089,"user_tz":300,"elapsed":4,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"7b513ba8-7b26-4c39-ac03-ea2c8764a0af"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","### The code is used to vectorize the data for each batch as defined in the data loader.\n","### For data in the batch, the input tokens are encoded and\n","### then special tokens [CLS] (101) is added at the beginning and [SEP] (102) is added at the end.\n","### These tokens are added because the BERT model was pretrained with these tokens. So to get the same results for inference we need to add them.\n","### The input is padded with 0 if it is lesser than Max length.\n","\n","MAX_LEN = 128\n","\n","def vectorize_batch(batch):\n","    batch_input_ids = []\n","    batch_mask = []\n","    batch_token_type_ids = []\n","    batch_pos = []\n","    batch_ner = []\n","\n","    for data in batch:\n","        target_pos = []\n","        target_ner = []\n","        inputs = []\n","        tokens = data['tokens']\n","        pos_tags = data['pos_tags']\n","        ner_tags = data['ner_tags']\n","        for i in range(len(tokens)):\n","            input = tokenizer.encode(tokens[i], add_special_tokens=False)\n","            input_len = len(input)\n","            target_pos.extend([pos_tags[i]] * input_len)\n","            target_ner.extend([ner_tags[i]] * input_len)\n","            inputs.extend(input)\n","        inputs = inputs[:MAX_LEN - 2]\n","        target_pos = target_pos[:MAX_LEN - 2]\n","        target_ner = target_ner[:MAX_LEN - 2]\n","\n","        inputs = [101] + inputs + [102]\n","        target_pos = [0] + target_pos + [0]\n","        target_ner = [0] + target_ner + [0]\n","\n","        mask = [1] * len(inputs)\n","        token_type_ids = [0] * len(inputs)\n","\n","        padding_len = MAX_LEN - len(inputs)\n","        inputs = inputs + ([0] * padding_len)\n","        mask = mask + ([0] * padding_len)\n","\n","        token_type_ids = token_type_ids + ([0] * padding_len)\n","        target_pos = target_pos + ([0] * padding_len)\n","        target_ner = target_ner + ([0] * padding_len)\n","\n","        batch_input_ids.append(inputs)\n","        batch_mask.append(mask)\n","        batch_token_type_ids.append(token_type_ids)\n","        batch_pos.append(target_pos)\n","        batch_ner.append(target_ner)\n","\n","    return torch.tensor(batch_input_ids, dtype=torch.long), torch.tensor(batch_mask, dtype=torch.long), torch.tensor(batch_token_type_ids, dtype=torch.long), torch.tensor(batch_pos, dtype=torch.long), torch.tensor(batch_ner, dtype=torch.long)"]},{"cell_type":"code","execution_count":67,"id":"PItcg3k8DnBr","metadata":{"id":"PItcg3k8DnBr","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701048076216,"user_tz":300,"elapsed":130,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"9899a310-a271-4683-e342-7b3ad076aec4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","train_loader = DataLoader(train, batch_size=8, collate_fn=vectorize_batch, shuffle=True)\n","test_loader  = DataLoader(test, batch_size=1, collate_fn=vectorize_batch)"]},{"cell_type":"markdown","id":"C0x_Xd6Dy2Rm","metadata":{"id":"C0x_Xd6Dy2Rm"},"source":["## 4.5 POS Tagging and NER using CoNLL-2003 dataset [10pts]\n","\n","Run the below cell to classify the conll2003 dataset for POS Tagging and NER using the sequenceLabeling functions that you have already implemented in 4.\n","\n","**You must reach an F1-score of >= 90% in both tasks to receive credit for this section.**"]},{"cell_type":"code","execution_count":68,"id":"f9ebec76","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f9ebec76","executionInfo":{"status":"ok","timestamp":1701048076216,"user_tz":300,"elapsed":3,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"e87e1ba3-53ac-4d9d-cf79-0a35e66c5edb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device available for running:  cuda\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Use cuda if present\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device available for running: \", device)"]},{"cell_type":"code","execution_count":69,"id":"NuatO5oXD7D4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"NuatO5oXD7D4","outputId":"e4eb4151-78e8-4373-d363-6bf0d63b4cde","executionInfo":{"status":"ok","timestamp":1701050228833,"user_tz":300,"elapsed":2152619,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1756/1756 [11:54<00:00,  2.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["POS Tagging loss on epoch 0: 552.810280\n","NER loss on epoch 0: 552.810280\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1756/1756 [11:55<00:00,  2.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["POS Tagging loss on epoch 1: 325.416786\n","NER loss on epoch 1: 325.416786\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1756/1756 [11:59<00:00,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["POS Tagging loss on epoch 2: 240.904050\n","NER loss on epoch 2: 240.904050\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from sequenceLabeling import SequenceLabeling\n","from tqdm import tqdm\n","\n","NUM_CLASSES_POS = 47\n","NUM_CLASSES_NER = 9\n","\n","model_pos = SequenceLabeling(NUM_CLASSES_POS)\n","model_pos.to(device)\n","\n","model_ner = SequenceLabeling(NUM_CLASSES_NER)\n","model_ner.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer_pos = optim.Adam(model_pos.parameters(), lr=0.0001)\n","optimizer_ner = optim.Adam(model_ner.parameters(), lr=0.0001)\n","N_EPOCHS = 3 if not SHORT else 1\n","\n","model_pos.train()\n","model_ner.train()\n","\n","for epoch in range(N_EPOCHS):\n","    total_loss_pos = 0.0\n","    total_loss_ner = 0.0\n","    for input_ids, mask, token_type_ids, target_pos, target_ner in tqdm(train_loader):\n","        input_ids = input_ids.to(device)\n","        mask = mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        target_pos = target_pos.to(device)\n","        target_ner = target_ner.to(device)\n","\n","        outputs_pos = model_pos(input_ids, mask, token_type_ids)\n","        outputs_ner = model_ner(input_ids, mask, token_type_ids)\n","\n","        active_loss_pos = mask.view(-1) == 1\n","        active_logits_pos = outputs_pos.view(-1, NUM_CLASSES_POS)\n","\n","        active_labels_pos = torch.where(\n","            active_loss_pos,\n","            target_pos.view(-1),\n","            torch.tensor(criterion.ignore_index).type_as(target_pos)\n","        )\n","\n","        loss_pos = criterion(active_logits_pos, active_labels_pos)\n","\n","        optimizer_pos.zero_grad()\n","        loss_pos.backward()\n","        optimizer_pos.step()\n","\n","        active_loss_ner = mask.view(-1) == 1\n","        active_logits_ner = outputs_ner.view(-1, NUM_CLASSES_NER)\n","\n","        active_labels_ner = torch.where(\n","            active_loss_ner,\n","            target_ner.view(-1),\n","            torch.tensor(criterion.ignore_index).type_as(target_ner)\n","        )\n","\n","        loss_ner = criterion(active_logits_ner, active_labels_ner)\n","\n","        optimizer_ner.zero_grad()\n","        loss_ner.backward()\n","        optimizer_ner.step()\n","\n","        total_loss_pos += loss_pos.item()\n","        total_loss_ner += loss_ner.item()\n","\n","        if SHORT:\n","            break\n","\n","    print(\"POS Tagging loss on epoch %i: %f\" % (epoch, total_loss_pos))\n","    print(\"NER loss on epoch %i: %f\" % (epoch, total_loss_pos))"]},{"cell_type":"code","execution_count":70,"id":"38coF05PHyWO","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"38coF05PHyWO","outputId":"da4e7fd6-7639-432d-fbf7-9210aa35086a","executionInfo":{"status":"ok","timestamp":1701050364377,"user_tz":300,"elapsed":135558,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3453/3453 [02:15<00:00, 25.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test F1-score on Conll2003 Dataset for POS Tagging : 0.928\n","Test F1-score on Conll2003 Dataset for NER : 0.963\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","with torch.no_grad():\n","    y_true_pos = []\n","    y_pred_pos = []\n","    y_true_ner = []\n","    y_pred_ner = []\n","    for input_ids, mask, token_type_ids, target_pos, target_ner in tqdm(test_loader):\n","        input_ids = input_ids.to(device)\n","        mask = mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        target_pos = target_pos.to(device).view(-1)\n","        target_ner = target_ner.to(device).view(-1)\n","\n","        outputs_pos = model_pos(input_ids, mask, token_type_ids)\n","        predicted_pos = torch.argmax(outputs_pos, dim=-1)\n","\n","        outputs_ner = model_ner(input_ids, mask, token_type_ids)\n","        predicted_ner = torch.argmax(outputs_ner, dim=-1)\n","\n","        active_loss = mask == 1\n","        active_loss = active_loss.view(-1)\n","        predicted_pos = predicted_pos.view(-1)\n","        predicted_ner = predicted_ner.view(-1)\n","\n","        for i in range(len(active_loss)):\n","            if not active_loss[i]:\n","                break\n","            y_true_pos.append(target_pos[i].cpu().detach().numpy())\n","            y_pred_pos.append(predicted_pos[i].cpu().detach().numpy())\n","            y_true_ner.append(target_ner[i].cpu().detach().numpy())\n","            y_pred_ner.append(predicted_ner[i].cpu().detach().numpy())\n","\n","        if SHORT:\n","            break\n","from sklearn.metrics import f1_score\n","\n","print(\"Test F1-score on Conll2003 Dataset for POS Tagging : {:.3f}\".format(f1_score(y_true_pos, y_pred_pos, average='micro')))\n","print(\"Test F1-score on Conll2003 Dataset for NER : {:.3f}\".format(f1_score(y_true_ner, y_pred_ner, average='micro')))"]},{"cell_type":"markdown","id":"2-eb50kEywdY","metadata":{"id":"2-eb50kEywdY"},"source":["### ðŸ™ <font color='darkred'>Submit these files to Gradescope</font>\n","**Run the cell below to save the results of your model. You will be required to upload the `bert_pos.pkl` and `bert_ner.pkl` files that are saved in the `outputs folder` to Gradescope for accuracy evaluation. You must reach an accuracy of >= 90% on both tasks to receive credit for this section.**"]},{"cell_type":"code","execution_count":71,"id":"2KLnDxFMOjk-","metadata":{"id":"2KLnDxFMOjk-","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1701050364528,"user_tz":300,"elapsed":157,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"2c82c64b-439c-4f9f-9d74-eb8f35d98be1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","with open('./outputs/bert_pos.pkl', 'wb') as fp:\n","    pickle.dump(np.array(y_pred_pos), fp)\n","\n","with open('./outputs/bert_ner.pkl', 'wb') as fp:\n","    pickle.dump(np.array(y_pred_ner), fp)"]},{"cell_type":"markdown","id":"YTB35zhNXIAh","metadata":{"id":"YTB35zhNXIAh"},"source":["# Q5: Topic Modeling [20pts]\n","\n","Topic Models are a type of statistical language models used for uncovering hidden structure in a collection of texts. There are several existing algorithms you can use to perform the topic modeling. In this HW, we will be exploring LDA (Latent Dirichlet Allocation) method. For more details please refer to class lectures and slides."]},{"cell_type":"markdown","id":"dBuuFtJD5o_h","metadata":{"id":"dBuuFtJD5o_h"},"source":["## 5.1: Latent Dirichlet Allocation [20pts]\n","\n","In the **lda.py** file complete the following functions:\n","\n","* **tokenize_words**\n","* **remove_stopwords**\n","* **create_dictionary**\n","* **build_LDAModel**\n","\n","Latent Dirichlet Allocation (LDA) is a generative statistical model that explains a set of observations through unobserved groups, and each group explains why some parts of the data are similar. The LDA is an example of a topic model. In this, observations (e.g., words) are collected into documents, and each word's presence is attributable to one of the document's topics. Each document will contain a small number of topics."]},{"cell_type":"markdown","id":"ee7b4f68","metadata":{"id":"ee7b4f68"},"source":["## 5.2: Local Tests for LDA Functions [No Points]\n","You may test your implementation of the LDA functions contained in **lda.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."]},{"cell_type":"code","execution_count":74,"id":"c5b8b3c1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"c5b8b3c1","executionInfo":{"status":"ok","timestamp":1701050881956,"user_tz":300,"elapsed":570,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}},"outputId":"0cb1cbb7-b54e-479b-fad1-6d4440044c12"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["Local Tests for LDA Functions \n","\n","Your tokenize_words works as expected: True\n","Your remove_stopwords works as expected: True\n","Your create_dictionary works as expected: True\n","Your build_LDAModel works as expected: True\n"]}],"source":["# ###############################\n","# ### DO NOT CHANGE THIS CELL ###\n","# ###############################\n","\n","from lda import LDA\n","from local_tests.lda_test import LDA_Test\n","\n","local_test = LDA_Test()\n","\n","sample_data = local_test.input_sequences\n","stop_words = stopwords.words('english')\n","lda = LDA()\n","\n","print('Local Tests for LDA Functions \\n')\n","\n","# Local test for tokenize_words\n","output = list(lda.tokenize_words(sample_data))\n","tokens_test = (output == local_test.output_tokenized)\n","print('Your tokenize_words works as expected:', tokens_test)\n","\n","# Local test for remove_stopwords\n","filtered_output = lda.remove_stopwords(local_test.output_tokenized, stop_words)\n","remove_stopwords_test = (filtered_output == local_test.output_stopword_removal)\n","print('Your remove_stopwords works as expected:', remove_stopwords_test)\n","\n","# Local test for create_dictionary\n","id2word_test, corpus_test  = lda.create_dictionary(local_test.output_stopword_removal)\n","id2word_corpus_test = ((id2word_test == local_test.output_id2word_dictionary) and (corpus_test == local_test.output_sample_corpus))\n","print('Your create_dictionary works as expected:', id2word_corpus_test)\n","\n","# Instantiate build_LDAModel\n","lda_model_build = lda.build_LDAModel(id2word_test, corpus_test)\n","lda_model_test = isinstance(lda_model_build, gensim.models.LdaMulticore)\n","print(\"Your build_LDAModel works as expected:\", lda_model_test)"]},{"cell_type":"markdown","id":"9HvQUwhK7htj","metadata":{"id":"9HvQUwhK7htj"},"source":["## 5.3: Topic Modeling on Clickbait dataset using LDA [No Points]\n","\n","Run the below cell to build LDA Model and visualize topics using gensim library."]},{"cell_type":"code","execution_count":75,"id":"1LJMR0E2XLpj","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"1LJMR0E2XLpj","outputId":"84174a5b-1212-40c7-cb3a-7ee1d1e4a20f","executionInfo":{"status":"ok","timestamp":1701050898652,"user_tz":300,"elapsed":10667,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","from lda import LDA\n","\n","stop_words = stopwords.words('english')\n","lda = LDA()\n","\n","data = list(lda.tokenize_words(x_train))\n","data = lda.remove_stopwords(data, stop_words)\n","id2word, corpus = lda.create_dictionary(data)\n","lda_model = lda.build_LDAModel(id2word, corpus)"]},{"cell_type":"code","execution_count":76,"id":"UgmdIaO2YjMe","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":881},"id":"UgmdIaO2YjMe","outputId":"6b5245a3-9c7b-4dff-c127-92b246b16a4a","executionInfo":{"status":"ok","timestamp":1701050913045,"user_tz":300,"elapsed":14396,"user":{"displayName":"Sejal Dua","userId":"00474242671009571452"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n","topic                                                \n","6     -0.020648 -0.129173       1        1  11.316978\n","9     -0.056071  0.106044       2        1  10.946241\n","2      0.120643  0.069352       3        1  10.833301\n","7     -0.016480  0.088057       4        1  10.390677\n","4      0.005677 -0.064178       5        1  10.249255\n","1     -0.024772 -0.137896       6        1  10.122919\n","0     -0.197255  0.046562       7        1   9.927286\n","3      0.082547 -0.046508       8        1   9.006524\n","5      0.106578  0.059458       9        1   9.005128\n","8     -0.000219  0.008283      10        1   8.201690, topic_info=            Term        Freq       Total Category  logprob  loglift\n","135        based  441.000000  441.000000  Default  30.0000  30.0000\n","1101    favorite  239.000000  239.000000  Default  29.0000  29.0000\n","145         make  507.000000  507.000000  Default  28.0000  28.0000\n","32    understand  174.000000  174.000000  Default  27.0000  27.0000\n","381       zodiac  193.000000  193.000000  Default  26.0000  26.0000\n","...          ...         ...         ...      ...      ...      ...\n","428     actually   35.482076  370.526863  Topic10  -5.5547   0.1549\n","103         love   30.166355  217.179350  Topic10  -5.7170   0.5268\n","135        based   31.521170  441.357344  Topic10  -5.6730  -0.1384\n","759        guess   25.924828  150.978658  Topic10  -5.8685   0.7389\n","88          well   25.754975  159.414551  Topic10  -5.8751   0.6779\n","\n","[776 rows x 6 columns], token_table=      Topic      Freq         Term\n","term                              \n","3449      8  0.882160       aboard\n","839       2  0.029758   absolutely\n","839       4  0.208306   absolutely\n","839       5  0.743951   absolutely\n","7294      7  0.058248  accessories\n","...     ...       ...          ...\n","381       4  0.020682       zodiac\n","381       5  0.227498       zodiac\n","381       6  0.010341       zodiac\n","381       9  0.134431       zodiac\n","381      10  0.010341       zodiac\n","\n","[2344 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 10, 3, 8, 5, 2, 1, 4, 6, 9])"],"text/html":["\n","<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n","\n","\n","<div id=\"ldavis_el41761403111783523845061559142\" style=\"background-color:white;\"></div>\n","<script type=\"text/javascript\">\n","\n","var ldavis_el41761403111783523845061559142_data = {\"mdsDat\": {\"x\": [-0.020648054719949474, -0.05607127402672727, 0.12064271642015663, -0.0164798297196384, 0.005676717107967172, -0.02477177251487938, -0.19725483819078404, 0.08254729303906583, 0.10657791704933245, -0.0002188744445432424], \"y\": [-0.12917318191092933, 0.10604379786739088, 0.06935228412283057, 0.08805669282635638, -0.06417794822401873, -0.13789637062741616, 0.04656160995946774, -0.046507539317396845, 0.05945806737136823, 0.008282587932347414], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.316978040694755, 10.946240967291624, 10.833300504674991, 10.390677073238479, 10.24925487628116, 10.122919397651643, 9.927286489220855, 9.006524253823915, 9.005128032829985, 8.201690364292592]}, \"tinfo\": {\"Term\": [\"based\", \"favorite\", \"make\", \"understand\", \"zodiac\", \"people\", \"earthquake\", \"tweets\", \"well\", \"know\", \"sign\", \"ever\", \"first\", \"remember\", \"us\", \"north\", \"time\", \"like\", \"times\", \"music\", \"iran\", \"laugh\", \"anyone\", \"every\", \"football\", \"wikinews\", \"korea\", \"halloween\", \"perfect\", \"dies\", \"wish\", \"else\", \"bar\", \"britney\", \"spears\", \"horoscope\", \"screenshot\", \"reading\", \"inspiring\", \"anderson\", \"dissident\", \"goes\", \"jaw\", \"hadid\", \"shakes\", \"puppy\", \"biden\", \"halloweentown\", \"frank\", \"restore\", \"cooper\", \"severe\", \"nepal\", \"burris\", \"kylo\", \"ren\", \"martha\", \"ancient\", \"manufacturer\", \"pulls\", \"born\", \"detained\", \"faith\", \"largest\", \"remember\", \"tree\", \"annual\", \"elect\", \"changed\", \"well\", \"next\", \"celebrity\", \"moves\", \"time\", \"members\", \"every\", \"posts\", \"first\", \"kids\", \"better\", \"make\", \"questions\", \"wars\", \"years\", \"star\", \"laugh\", \"bff\", \"love\", \"old\", \"songs\", \"lyrics\", \"year\", \"tweets\", \"people\", \"movie\", \"know\", \"girl\", \"christmas\", \"new\", \"things\", \"get\", \"actually\", \"watch\", \"pictures\", \"one\", \"rocket\", \"satellite\", \"orange\", \"replace\", \"emas\", \"escape\", \"kelly\", \"delta\", \"funeral\", \"barcelona\", \"hear\", \"letting\", \"thailand\", \"diversity\", \"sir\", \"lawyers\", \"wait\", \"diego\", \"jason\", \"significant\", \"tennis\", \"cereal\", \"detainee\", \"reviews\", \"slytherin\", \"panic\", \"asbestos\", \"cleared\", \"sounds\", \"leak\", \"sentences\", \"fund\", \"town\", \"iran\", \"lesbian\", \"nuclear\", \"nyc\", \"ie\", \"korea\", \"discovery\", \"unemployment\", \"cookies\", \"say\", \"adele\", \"iraq\", \"bombings\", \"european\", \"like\", \"adults\", \"africa\", \"strike\", \"north\", \"israeli\", \"fraud\", \"launch\", \"could\", \"may\", \"prove\", \"case\", \"home\", \"us\", \"france\", \"things\", \"ireland\", \"pictures\", \"vote\", \"talks\", \"everyone\", \"go\", \"says\", \"life\", \"know\", \"two\", \"look\", \"would\", \"new\", \"people\", \"ever\", \"aircraft\", \"nick\", \"nail\", \"healthier\", \"daughters\", \"robot\", \"leaving\", \"snl\", \"investigate\", \"osama\", \"chili\", \"form\", \"forget\", \"laden\", \"munich\", \"diet\", \"bernie\", \"bayern\", \"breed\", \"records\", \"efforts\", \"ride\", \"trash\", \"criticism\", \"touch\", \"lake\", \"norway\", \"holders\", \"grammy\", \"somalia\", \"bin\", \"everywhere\", \"price\", \"cost\", \"lift\", \"sinks\", \"favorite\", \"based\", \"development\", \"zodiac\", \"york\", \"kind\", \"sign\", \"know\", \"new\", \"prices\", \"term\", \"report\", \"police\", \"person\", \"oil\", \"somali\", \"chinese\", \"last\", \"song\", \"tv\", \"government\", \"run\", \"world\", \"australian\", \"london\", \"president\", \"uk\", \"ends\", \"things\", \"show\", \"one\", \"football\", \"arrested\", \"tour\", \"us\", \"first\", \"character\", \"lazy\", \"front\", \"diys\", \"putting\", \"bit\", \"fair\", \"design\", \"promises\", \"launched\", \"disneyland\", \"smartphone\", \"hilton\", \"producer\", \"makers\", \"points\", \"puppies\", \"shops\", \"wednesday\", \"welcomes\", \"binge\", \"genocide\", \"posting\", \"elects\", \"yes\", \"bee\", \"researchers\", \"sentence\", \"ending\", \"serbia\", \"citigroup\", \"guns\", \"kim\", \"paper\", \"flag\", \"nears\", \"wikinews\", \"interviews\", \"john\", \"clinton\", \"guantanamo\", \"sent\", \"lead\", \"buzzfeed\", \"media\", \"kardashian\", \"needs\", \"dies\", \"age\", \"british\", \"opposition\", \"us\", \"one\", \"tweet\", \"former\", \"obama\", \"president\", \"takes\", \"government\", \"kid\", \"australian\", \"want\", \"part\", \"india\", \"reasons\", \"tell\", \"loss\", \"times\", \"china\", \"know\", \"new\", \"best\", \"dead\", \"world\", \"things\", \"day\", \"uefa\", \"blast\", \"proof\", \"joke\", \"charge\", \"cities\", \"squash\", \"feud\", \"lifts\", \"wild\", \"appeal\", \"twin\", \"insurgents\", \"shanghai\", \"wireless\", \"authority\", \"parts\", \"operation\", \"broken\", \"operations\", \"played\", \"diva\", \"areas\", \"republicans\", \"coal\", \"ontario\", \"tibetan\", \"butts\", \"regulators\", \"knope\", \"dying\", \"mark\", \"holidays\", \"kanye\", \"unexpected\", \"taylor\", \"music\", \"swift\", \"taiwan\", \"merger\", \"styles\", \"perfect\", \"champions\", \"memorial\", \"makeup\", \"pope\", \"brazil\", \"family\", \"absolutely\", \"gifts\", \"seriously\", \"west\", \"direction\", \"video\", \"lady\", \"need\", \"knows\", \"date\", \"people\", \"talk\", \"right\", \"first\", \"league\", \"really\", \"sign\", \"uk\", \"zodiac\", \"go\", \"actually\", \"time\", \"new\", \"show\", \"one\", \"things\", \"life\", \"make\", \"based\", \"turkey\", \"beach\", \"globes\", \"planning\", \"truly\", \"soldiers\", \"costa\", \"pichilemu\", \"simpsons\", \"founder\", \"brownies\", \"ring\", \"approve\", \"card\", \"experiences\", \"roundup\", \"large\", \"lucky\", \"cake\", \"basically\", \"leaks\", \"colonial\", \"alexander\", \"rescued\", \"ruined\", \"hills\", \"worse\", \"groom\", \"hysterical\", \"pixar\", \"magnitude\", \"earthquake\", \"hits\", \"anyone\", \"loans\", \"comments\", \"law\", \"immediately\", \"strikes\", \"sense\", \"sets\", \"lived\", \"leaves\", \"final\", \"capital\", \"celebrities\", \"tweets\", \"dinners\", \"depression\", \"make\", \"real\", \"life\", \"football\", \"control\", \"north\", \"free\", \"body\", \"game\", \"laugh\", \"photos\", \"living\", \"dead\", \"way\", \"dies\", \"actually\", \"things\", \"need\", \"new\", \"get\", \"australian\", \"week\", \"people\", \"peak\", \"breaks\", \"nd\", \"hemsworth\", \"asks\", \"dubai\", \"routine\", \"candidates\", \"ron\", \"riots\", \"australians\", \"karl\", \"placed\", \"linked\", \"removed\", \"shocked\", \"bffs\", \"relatable\", \"toilet\", \"lawmaker\", \"montana\", \"detainees\", \"smoke\", \"optimism\", \"jeremy\", \"caitlyn\", \"entertainment\", \"proves\", \"rio\", \"eclipse\", \"rove\", \"heartbreaking\", \"appreciate\", \"understand\", \"efron\", \"fox\", \"honest\", \"zac\", \"freed\", \"jones\", \"confessions\", \"aid\", \"secrets\", \"ever\", \"worst\", \"problems\", \"lovers\", \"bank\", \"twitter\", \"times\", \"obsessed\", \"wedding\", \"things\", \"world\", \"take\", \"australia\", \"never\", \"said\", \"people\", \"man\", \"reasons\", \"best\", \"everyone\", \"day\", \"got\", \"says\", \"russia\", \"dead\", \"school\", \"new\", \"love\", \"foods\", \"hole\", \"dirty\", \"middle\", \"showing\", \"meat\", \"adventure\", \"harris\", \"sunny\", \"voices\", \"creative\", \"expand\", \"milan\", \"trend\", \"voters\", \"alan\", \"homeless\", \"education\", \"suspends\", \"detects\", \"rapper\", \"content\", \"burger\", \"starting\", \"edinburgh\", \"aboard\", \"hurts\", \"las\", \"cnn\", \"subject\", \"kingdom\", \"justice\", \"belong\", \"mars\", \"minor\", \"gave\", \"hogwarts\", \"lawyer\", \"houses\", \"supreme\", \"shop\", \"bomb\", \"channel\", \"charged\", \"myanmar\", \"thanksgiving\", \"delicious\", \"trying\", \"back\", \"elections\", \"ideas\", \"characters\", \"military\", \"cute\", \"fire\", \"forces\", \"court\", \"food\", \"presidential\", \"fall\", \"made\", \"new\", \"three\", \"make\", \"times\", \"disney\", \"actually\", \"guaranteed\", \"women\", \"life\", \"know\", \"live\", \"based\", \"us\", \"favorite\", \"athletes\", \"landing\", \"butter\", \"category\", \"snapchats\", \"ohio\", \"elected\", \"egyptian\", \"carrying\", \"warming\", \"cameron\", \"edward\", \"recall\", \"winners\", \"murdoch\", \"relations\", \"confused\", \"rebuke\", \"fallon\", \"teenage\", \"risk\", \"carey\", \"austin\", \"underground\", \"hire\", \"survivors\", \"hughes\", \"derby\", \"scenes\", \"swedish\", \"throw\", \"costume\", \"glorious\", \"electric\", \"unit\", \"english\", \"emergency\", \"guys\", \"buy\", \"artist\", \"budget\", \"support\", \"deal\", \"plant\", \"halloween\", \"captain\", \"took\", \"disney\", \"told\", \"character\", \"zealand\", \"minute\", \"claims\", \"new\", \"us\", \"try\", \"plane\", \"movies\", \"texas\", \"guess\", \"read\", \"identify\", \"becomes\", \"would\", \"one\", \"based\", \"things\", \"need\", \"sign\", \"china\", \"people\", \"like\", \"favorite\", \"robert\", \"retail\", \"training\", \"died\", \"carrie\", \"attacked\", \"speak\", \"bonds\", \"fisher\", \"falling\", \"enters\", \"intense\", \"syracuse\", \"cable\", \"comment\", \"shelf\", \"exes\", \"tyler\", \"creating\", \"strangers\", \"accounts\", \"bobby\", \"polar\", \"colombian\", \"honors\", \"trapped\", \"indicted\", \"seize\", \"nominated\", \"screencap\", \"words\", \"senator\", \"southern\", \"dessert\", \"therapy\", \"powerful\", \"alive\", \"plays\", \"films\", \"seen\", \"accessories\", \"month\", \"gilmore\", \"struggles\", \"bowl\", \"humans\", \"birth\", \"return\", \"debt\", \"released\", \"miss\", \"baseball\", \"delay\", \"people\", \"lives\", \"stories\", \"photos\", \"super\", \"shopping\", \"keep\", \"hospital\", \"girls\", \"union\", \"give\", \"jobs\", \"things\", \"new\", \"former\", \"everyone\", \"shows\", \"know\", \"weird\", \"actually\", \"love\", \"based\", \"guess\", \"well\"], \"Freq\": [441.0, 239.0, 507.0, 174.0, 193.0, 590.0, 100.0, 170.0, 159.0, 564.0, 186.0, 241.0, 322.0, 101.0, 503.0, 157.0, 256.0, 301.0, 305.0, 110.0, 95.0, 114.0, 81.0, 216.0, 138.0, 80.0, 94.0, 156.0, 102.0, 217.0, 34.972916999982246, 24.586330716044486, 23.04215101720244, 26.475729765930105, 26.475747442367588, 18.701720942260046, 18.387422099486926, 18.3389754034502, 17.932862198307614, 17.35373055002641, 17.594776762825656, 40.15504157953359, 14.901310451590609, 14.216712339055766, 17.94995973246488, 15.781112409344077, 13.145265392163964, 14.295734852831997, 13.027313470900165, 13.315432036721692, 12.648130318265821, 12.353882447746406, 11.632756713667252, 11.619413212920842, 10.78778764901423, 10.787769972576745, 10.665376846394865, 10.551941991426684, 10.53760787366289, 10.23944467224057, 26.514718094875956, 12.203950168481285, 21.104903324081665, 14.820785440628162, 84.73648700682674, 16.150324578200483, 20.816930588869386, 13.738595638854914, 21.103552549650527, 103.23989305087082, 44.88343852350386, 65.43706384567115, 17.695069923042045, 129.24361774486047, 19.390645362869314, 104.83052495438672, 40.396899435420686, 136.34071917933807, 59.81094840152, 54.987979570932616, 181.4743323225657, 63.19724709908494, 45.66190293819288, 53.98012213485627, 67.45771044388212, 56.11078098782742, 31.09062925088277, 80.67379942890224, 61.48821252514938, 34.54729784607508, 36.38631610305583, 85.15297922684587, 59.28087917851458, 107.70523219826377, 51.122649417526986, 91.26357046958306, 50.30290462916491, 50.04216539197103, 86.71754427721737, 77.02218918898066, 50.470901491021365, 53.953943330941144, 43.13391901558206, 44.59851202768482, 44.77782770167744, 38.451827936776475, 25.71527433378112, 17.3667689114533, 16.996078014897805, 18.48921542947243, 17.69267610071855, 14.891299338703973, 16.46916276300505, 14.099981831253821, 13.451585501647644, 20.954418032422396, 12.977277427926104, 13.060028691587895, 13.003547534665017, 12.805124024246231, 12.466249905735355, 12.176999474588055, 12.120315998804296, 11.64706297519883, 12.553574715477628, 11.404137864070462, 11.864188157222726, 11.940928983457567, 10.769127349238778, 10.58827067258924, 10.542748216500637, 12.79224400662394, 10.129218438324633, 12.59500876331765, 9.869707454946147, 19.179558727974385, 26.560442852962698, 40.660047117328254, 77.71330176006207, 14.20206309481402, 51.79719033733869, 17.550514330993234, 21.739826974266393, 67.62687447320414, 16.014519512648867, 21.288564728536063, 17.872687170016448, 80.64320371562243, 36.56388806168374, 68.6284725161453, 18.271225405557303, 44.41135224982022, 143.96640837139216, 17.399828098277414, 28.749022856201908, 37.99358711512645, 68.9723518892919, 37.75080448206913, 28.662966101291918, 29.219115003801285, 43.15376385663606, 50.266588313983306, 37.4784063571648, 44.43748842717235, 48.58996906430018, 99.13771220543411, 39.691130694322965, 104.24744316111023, 25.90003419718688, 49.51791164363491, 32.15016248305283, 32.810462855494656, 53.98376709889904, 38.42295903002173, 47.73062397704982, 52.53189275847919, 57.96105385031093, 41.2061114219692, 40.50601407472363, 39.963468978437454, 52.706502484103844, 42.635599607866766, 38.23832739687991, 23.12609636996278, 21.72865049426322, 18.748388190449123, 18.554956209563674, 17.744079723304633, 17.867817080509578, 16.870769116285228, 17.018634355693813, 16.913766691648185, 19.07603442438272, 16.123093834412213, 16.095834164097166, 16.164129988224985, 25.587162916017142, 15.496026941793126, 15.077584234072226, 14.717551278237329, 14.722940604739714, 14.142722216494054, 14.065214338457267, 13.928913166721644, 13.939299817432415, 13.218510534622975, 12.418959812484067, 12.343502191049705, 33.38089330193126, 12.049513161272424, 11.809480145087637, 11.829327728861662, 18.77375271298311, 28.314463883385564, 19.7485383311008, 22.956205677920167, 23.51940439822135, 22.506164483126543, 21.68627194410553, 169.7475407012926, 251.33009927377117, 20.88188746706077, 112.49734852190166, 58.64302427269493, 24.49355830041202, 87.84811454788516, 188.48341160985743, 199.3840760336748, 33.029044451543726, 25.07165169780496, 44.42214272111435, 52.46977778712408, 40.31025298925745, 38.11040097902564, 27.579933369083257, 37.716478155802385, 42.86124034929849, 42.302016645064874, 49.22008441019559, 44.1712556126344, 29.649792906368468, 62.80505081593822, 49.18173022891226, 38.994473318087486, 47.95465024228077, 46.59213769331331, 29.64385082842994, 64.81904015576725, 42.06100573826538, 48.01948008929115, 38.21816212762985, 32.43667822242469, 31.61523318510982, 38.84057998584853, 34.94059146526123, 33.02971564971619, 25.77057497090111, 21.879863799393267, 19.10559840299472, 19.101780386956772, 16.573921062805386, 15.798739380082658, 15.67363342204431, 19.145639558793334, 13.830989635789473, 16.26897748784676, 13.486539129734679, 13.210062292844327, 13.062966564079447, 13.760339433242423, 14.487232612734937, 11.590693325454778, 11.587686789977498, 11.440581593939413, 11.235760519257541, 10.914101120982936, 10.592420759460515, 10.556852890252589, 12.582390193972419, 10.446716043623383, 10.010589873694602, 9.926914731915014, 17.95959985833346, 10.562558951061694, 9.401053012886047, 9.312598250604118, 9.668178212548488, 40.18517736852096, 11.250240713628878, 19.430237963628382, 15.309532914212912, 65.02307174714669, 57.070345857773766, 40.285305954901915, 34.45805322899662, 17.69428493655511, 19.79738693343269, 31.200653946257336, 37.09096953146743, 45.11914688337136, 30.74397432619441, 35.2410535269214, 92.18109724613333, 64.61663359352998, 73.66418200600557, 34.22179066375783, 147.9711215345059, 93.21939203337979, 19.59195927703172, 50.35122730685954, 62.533920045739215, 65.66843141730598, 36.793973056132955, 46.516727393789246, 26.355154747066287, 54.46243127137718, 44.418795880550725, 27.183038034801665, 39.042298966615476, 46.67912629346074, 41.93082353089142, 30.906237979105796, 55.21312111831131, 44.26777934821021, 66.27500772653569, 70.48863676742097, 47.71323384101415, 44.82170409372852, 44.512370408936675, 49.40099979992729, 41.01117802135559, 22.106073522505554, 19.4871005764179, 18.58186759111232, 15.621979651109829, 15.58325989786137, 15.168551383034917, 14.986089348467026, 14.44623534670798, 14.420532015470448, 13.57882162424834, 17.996582180971373, 11.960787117505845, 11.81757445794908, 11.944009980762024, 11.19753278639061, 11.165591391268372, 11.109966431529953, 11.01609464276188, 10.808450227330065, 11.167530447268462, 11.749992319725067, 11.805299773217856, 14.690875243024914, 12.197117154982347, 18.390109827470724, 10.183203054215108, 10.162167598412264, 9.768709990055331, 10.661583577828859, 9.577066955561314, 12.589624245692177, 19.433067150087197, 24.052258738464666, 25.43071877416188, 13.67440701290091, 60.837574502054444, 79.76182188480304, 58.671152012656734, 38.113884628807874, 24.270574965711223, 17.131935298652213, 66.44276039127482, 23.202678728154467, 15.272089102486621, 48.42966521741103, 33.36018645549118, 25.715962116243357, 51.858156356345695, 24.66488303722609, 50.11564472665825, 23.776706007174145, 40.836401964646505, 25.089773096870356, 72.82186642015581, 30.48652814237405, 85.23458899275818, 24.28178640473755, 34.24441200025088, 112.9263524537546, 35.193582246900114, 41.38150949411684, 70.31791077857717, 36.582463958189145, 45.35657296024327, 46.120066088072655, 45.27839171646664, 43.527897072603395, 35.35979543242699, 49.422157723810486, 44.29171304291783, 57.00990597313203, 38.34625651069286, 42.14445565740543, 47.62559532501421, 40.53397593162511, 40.64270981421431, 38.986269058289416, 41.949066689757274, 21.380602777012307, 19.90238407997316, 18.911355150771044, 18.347714677704165, 19.805274476268618, 14.747119942902144, 14.28643665255828, 16.675948757325205, 12.929106571965097, 12.74469964958319, 12.833163058263114, 12.714012377086497, 12.499841830899191, 14.082426241975181, 13.143970184074828, 22.072613289163034, 11.564007828484815, 24.188751733624088, 11.31114944652903, 11.198025540122694, 10.93736555488426, 10.990530035690142, 15.994612250949308, 10.785517578274337, 12.613080369882049, 10.649925028061654, 10.589144727804037, 10.529231418757359, 10.243362148802609, 33.85391441333353, 87.30851841185414, 47.003330303601096, 66.72925663744707, 12.789123067025267, 19.11974399873098, 47.21214605908739, 26.982250119909942, 20.145364296110667, 25.06009371200999, 29.273794853072143, 17.47688261664141, 28.837666651188922, 36.54365318886071, 19.27267307912293, 36.10313996152154, 85.88964117859489, 17.12826518719874, 24.722130524104813, 145.47104807014813, 69.70838074075027, 98.88491709952999, 55.346631803032444, 22.497665612445687, 56.078461982942834, 33.641514742811125, 33.61079057707141, 49.28403896424235, 43.86084028497908, 50.86357572992182, 27.879883804410017, 55.26172990991965, 41.91477969083461, 48.864251833784806, 58.31182607186442, 65.91500168216945, 47.40337954904359, 61.180908172169175, 39.322072779678464, 39.07632688793037, 35.9069733179274, 44.72469293503218, 34.718801545720495, 26.838225408174804, 22.9861447981567, 20.905033341073985, 18.86752425842318, 17.410571281095137, 17.285409569543507, 17.999302831623883, 15.406805453716826, 14.98593994358633, 13.792721634152587, 13.589250347563274, 12.514619280705654, 12.5079995864129, 12.536924407170911, 12.020978482216348, 16.123953646486925, 13.989645586956739, 11.546838840523106, 11.41869096588138, 11.18638014056086, 18.732760565944467, 11.034598807278794, 10.98630592137261, 10.980779387605265, 10.635033129418794, 10.506021451217688, 10.365364253825982, 10.159623302386928, 10.212911647620807, 15.807652946282742, 38.59153591204846, 27.485981166316023, 125.8263841627259, 13.353931392569997, 24.691860279067093, 35.12095023527115, 13.353734985477962, 22.451653908827826, 29.01745771355238, 48.41119016748898, 47.301360882295505, 31.436957915781754, 108.19020574047788, 60.155104142591036, 18.79652697110806, 19.94009821942211, 46.8204736232693, 40.87483554886264, 100.76753723219022, 42.95705308798998, 41.39309442575631, 139.06008727977974, 86.36226581114381, 47.698087702384434, 43.20376365432133, 49.901826961101136, 42.941032988469864, 100.52218342537623, 46.64510276451222, 48.17200250964338, 59.64290028960052, 52.745920531753924, 45.88383921299746, 36.97803356084879, 43.59131878007296, 33.27325826985742, 41.98255862642443, 33.85746858081358, 39.12446329755257, 34.658246138081296, 38.702066635229635, 20.229071425903975, 17.66448879563498, 21.99605944807514, 15.7967951710092, 14.400797988258736, 14.036782357613006, 14.20563985286306, 13.067624576642828, 12.426135140928814, 15.727306851658557, 12.195512465052403, 12.016010449520545, 11.605473107105759, 11.494215596385006, 21.609274156919117, 15.549426132552883, 10.166173359358686, 10.158956655960584, 10.149899435289084, 10.17555530823702, 9.84375928061167, 9.655007200401005, 9.494606706176603, 9.360755380544928, 9.303661245189812, 10.362659715181595, 9.327733335439428, 9.22521124794333, 9.228474942267617, 16.846190126667445, 29.12253529683778, 25.521515186976043, 15.844148046311274, 23.185256344447705, 21.988275349543073, 33.77582485175545, 14.02610266821133, 22.81251994437727, 24.912793992552437, 17.207595036314544, 49.247374829867795, 37.44332632121862, 24.960070668094783, 16.354544587695717, 45.26946601918252, 50.92253159083249, 25.249191313361276, 53.456823058154185, 34.831948832349546, 25.600204920389665, 37.812691174997155, 31.352644357155032, 26.484328458720984, 35.33008424624199, 26.57616440914343, 35.34270292645271, 40.51663613198205, 31.664207590116987, 38.54360395951027, 37.283534252768035, 79.6236845609904, 31.901327174738086, 56.699439356598056, 47.83233356870567, 38.76474972988469, 46.927357086897175, 30.183128100263843, 34.882737730663294, 41.986494327987465, 47.1772876095843, 28.629862819565734, 37.23086966806102, 36.917208010946595, 29.753342698542127, 20.421628293029375, 19.928614915939104, 17.889432793546842, 17.18366281630545, 17.163634763225346, 18.347473558724484, 17.64976074990778, 16.218006374905332, 14.870492426827866, 14.698281879942211, 14.281373229160721, 13.467991879224803, 13.156386692405192, 13.4127110770116, 12.316445052026529, 12.084580514770483, 11.975344580621691, 11.365095534948749, 15.455185690836062, 11.031842422083812, 12.3412202002652, 10.270210269987576, 10.198402543888994, 11.775995887018434, 10.050595582485155, 9.879934581229035, 9.718838683686863, 10.194315353563582, 10.278849983176167, 9.919494879672685, 19.841812229750758, 32.558602672883296, 20.79323793477553, 16.954535184529714, 13.221322265685336, 18.8577007233453, 24.10761992232976, 39.62915359377092, 41.38364714495378, 29.932458057784817, 29.58529654216641, 42.75685870148962, 41.332983332328126, 21.758414978170745, 72.61154410298772, 19.410094986319063, 24.3825787066475, 60.611979960079246, 25.346349203329066, 52.33893943426949, 39.20288320248783, 19.217421528994333, 30.756628793136684, 91.05424556271531, 73.96002387980856, 38.88788706596607, 26.371738167291085, 34.40213297528467, 26.460538149812812, 36.71330255206209, 23.816094361969757, 27.47297281854212, 24.90068956559832, 32.172132865107436, 38.07150391091877, 38.80846875002438, 41.52643507883441, 33.59331704155681, 29.895913629919683, 29.344887233624945, 27.86521650057751, 26.55889561725379, 25.734138820771232, 22.96651402088519, 18.467947765979993, 16.847948545951304, 16.85923143428038, 16.079007269419826, 14.390004043731683, 14.05383396758202, 13.670413260309907, 13.489832602224498, 13.261734426643063, 12.80309873402576, 13.147338386566704, 12.451585894032267, 12.446410433475982, 12.399086141714426, 21.36075265511375, 11.566071852161585, 11.851486545331063, 11.10913569197118, 12.14957086842669, 10.923003797315497, 11.895865479073894, 10.806171618421185, 10.171723993441432, 9.92870046430443, 12.862674177879708, 9.88251204094879, 9.601622673129576, 8.983074003196176, 9.325884212320277, 47.73286277312947, 35.028311298771946, 26.81949281357779, 15.377439856578027, 14.265709721832332, 20.407067293069154, 20.428068048032685, 14.406883005541788, 18.80685075859502, 38.884157518662185, 15.001469549310514, 41.94391798273782, 20.18331616274044, 35.5552047827482, 16.581124090019266, 15.360271589938971, 33.164596780125954, 23.558702857473754, 21.291804161819996, 26.9193702349319, 21.128830531571793, 25.960398387599618, 18.82499689690684, 118.42547773398334, 27.885031322331358, 26.66380197869158, 55.12412929770998, 29.96349115751629, 22.236686543718736, 27.939352307262446, 20.775942692981666, 31.376359863016756, 26.306475285936223, 31.103388480128636, 26.071495712098642, 55.356615085272914, 52.8736665324862, 30.860978789650847, 35.1737238056392, 24.98001157765202, 42.91773298262261, 24.333546593043124, 35.48207578129883, 30.166354692703866, 31.52117027422523, 25.924827771730115, 25.75497487831675], \"Total\": [441.0, 239.0, 507.0, 174.0, 193.0, 590.0, 100.0, 170.0, 159.0, 564.0, 186.0, 241.0, 322.0, 101.0, 503.0, 157.0, 256.0, 301.0, 305.0, 110.0, 95.0, 114.0, 81.0, 216.0, 138.0, 80.0, 94.0, 156.0, 102.0, 217.0, 35.92664023545266, 25.483192577023406, 23.93902000568585, 27.62272528839082, 27.622875013175836, 19.59843968043457, 19.285297282400165, 19.235711769018444, 18.829686043239278, 18.26184044985418, 18.579198697735308, 42.42437458658321, 15.83901054024453, 15.11846596454984, 19.098010292722865, 16.841387152639857, 14.042075293302448, 15.276143705415643, 13.924715551639203, 14.248687089269968, 13.545073450282423, 13.251365990738623, 12.529765999294275, 12.526861459612844, 11.684478262499391, 11.68446077823245, 11.562069343276779, 11.448740411676413, 11.443215390257377, 11.136487634284371, 28.883173672630615, 13.27782472045058, 23.235735670201684, 16.26835931231982, 101.22018141524312, 17.894985490620964, 23.488548305090667, 15.165313721462605, 24.973572923647332, 159.41455146686243, 61.14845780156655, 97.24781616682822, 20.418958482565206, 256.04941129187876, 23.00178888596769, 216.2732792653072, 62.05535807665867, 322.1278276158808, 107.5192489580757, 96.1234282914823, 507.56204112569975, 119.07920576039972, 78.97783878602256, 105.4746908408113, 149.46889162283495, 114.28936028202645, 46.14119726239022, 217.1793501510631, 142.41779297129776, 55.26591185738747, 60.38792405048051, 267.83000535391125, 170.12917859742387, 590.1400781197017, 137.7665039949267, 564.9791110935929, 148.46957216641545, 161.1152049037654, 790.1636336614627, 652.4224690130533, 185.41597007738923, 370.5268630865956, 111.14442055093647, 162.16646414422803, 307.5996915828345, 39.61064275657972, 27.034172294527597, 18.27237850238645, 17.89570715371389, 19.508288433129643, 18.716920723844364, 15.795134615694236, 17.491680947662072, 15.008421683098044, 14.354122348833993, 22.371717917390136, 13.876958489681243, 13.968419999455863, 13.91163178125294, 13.723047096023361, 13.372204795053428, 13.076642687950354, 13.020347040135569, 12.546729829991415, 13.523406243726438, 12.319553750030774, 12.830108860151721, 12.92760158086859, 11.668605324558534, 11.488230480504301, 11.442259229229164, 13.907149499078411, 11.029106396423597, 13.731050525536837, 10.769287306564099, 20.950630055063666, 29.966253008375293, 47.236051833643515, 95.59398130125199, 15.72104299195602, 64.95872461666637, 19.850904528370744, 25.241332756926415, 94.06752033389505, 18.14341344367573, 25.2724805234701, 20.623327878465993, 125.14107973854559, 49.982563054431346, 111.05952362490443, 21.536814995860727, 65.55041481080742, 301.9359738654153, 20.482888570813426, 40.27058523612558, 59.1748178745431, 157.74143374564898, 65.27990916939012, 44.146368233715584, 45.790220869586044, 85.62575934614084, 119.09148020675195, 72.869803467665, 102.20211903132896, 126.51701978576884, 503.1593048282433, 89.23921057465425, 652.4224690130533, 39.11874146292967, 162.16646414422803, 62.72524353209353, 66.22542017660703, 220.77010961044027, 107.16913677743888, 207.07036667156632, 321.1741537174188, 564.9791110935929, 159.9860212242088, 152.12110897794298, 146.60391893866608, 790.1636336614627, 590.1400781197017, 241.19174277940994, 24.026367552365524, 22.629523995059202, 19.64501549198859, 19.451514842350935, 18.643323059925347, 18.80035742257799, 17.76739378764383, 17.93583614448176, 17.825485787971502, 20.133874372699232, 17.02073217430965, 16.996531161087148, 17.069002421088044, 27.074027833381653, 16.401316085938923, 15.97440260814088, 15.619056934771907, 15.629653865888768, 15.039385523906871, 14.965903322128993, 14.832032744613345, 14.84600117500238, 14.118162631436299, 13.318935829163616, 13.239915676799713, 35.890576281694486, 12.957516733338098, 12.706279410010687, 12.727640918978413, 20.214095561372126, 30.640132295776972, 21.344152274727104, 25.000504787063747, 25.64113966443591, 24.60840982396467, 24.230780200317326, 239.7039376509719, 441.3573444920555, 23.91417436803586, 193.4084402866143, 98.05393893299313, 31.44066375373633, 186.6225584034802, 564.9791110935929, 790.1636336614627, 51.31972506195924, 33.71728143866158, 82.77353946440094, 127.68413837465525, 84.84245720499932, 77.46639187546508, 42.881145641079804, 79.17445463865464, 102.31567934179297, 102.77683145007721, 145.4838007529259, 124.5401700198565, 52.890273577564386, 297.5289732266183, 188.71243437791134, 108.41636889820671, 209.1047150145214, 210.89226570294818, 55.56962327310533, 652.4224690130533, 173.53575950155837, 307.5996915828345, 138.06449571856416, 83.19378281386072, 74.9405612368715, 503.1593048282433, 322.1278276158808, 156.26087979287945, 26.68729587830355, 22.77752110534669, 20.003181472950097, 20.017352369320193, 17.47882105002843, 16.696304732237483, 16.578641021186144, 20.30144608268789, 14.728573497059063, 17.33454947270985, 14.384237340644063, 14.107890611956721, 13.960804449043092, 14.779656448190154, 15.571613762697098, 12.488384204453364, 12.485466778099662, 12.338335594806235, 12.133285370210015, 11.815756472557716, 11.497376351718389, 11.461942467221194, 13.669491059213097, 11.354128396002555, 10.909162161252354, 10.82842626031151, 19.62522275634817, 11.547976441801586, 10.29873960248358, 10.210120270451174, 10.607402646517926, 45.558329332047826, 12.401464261936514, 21.94411176386194, 17.104967339430804, 80.56640214298773, 71.32049540123856, 52.774950864802115, 45.10211433926261, 20.880646475681168, 23.881648771809626, 41.10323567605088, 51.5455194546126, 66.30329398845278, 42.758716163783845, 56.50701448822691, 217.92201128337095, 134.72729936973326, 172.2429163969212, 56.426031325045614, 503.1593048282433, 307.5996915828345, 25.595265532938747, 125.29531744935855, 183.5921130573962, 209.1047150145214, 75.77838629225833, 124.5401700198565, 42.65489082908724, 188.71243437791134, 126.77849633139547, 46.14494241435624, 103.70918216553635, 160.43312377106528, 135.13928532542118, 64.34830096255133, 305.2754187625174, 169.95569696597826, 564.9791110935929, 790.1636336614627, 266.02544112046974, 260.60906733908456, 297.5289732266183, 652.4224690130533, 184.6222682370342, 23.130389814814496, 20.4022299373188, 19.56738577538704, 16.5229033841329, 16.484098244001306, 16.069342141717335, 15.887130494188558, 15.347208273420986, 15.348810866648195, 14.47952744110485, 19.316476538849194, 12.861627322219634, 12.71840626425571, 12.859843596611764, 12.098341874441376, 12.06929684478401, 12.018432036666885, 11.917170113059045, 11.709207698071507, 12.103932188672019, 12.736760262053377, 12.814293239471954, 15.968986598811785, 13.259153004709866, 19.996731365473586, 11.084010628707485, 11.06991871060607, 10.669431318813677, 11.65731010176935, 10.477759015789795, 13.868786418726657, 21.780286186318943, 28.109298928317873, 30.057925042673855, 15.363540736190412, 81.22380761363567, 110.15578478639972, 79.03829769858591, 49.26220557882453, 29.639781193944984, 19.965695355323884, 102.41250732224793, 28.928728869601017, 17.553553641683422, 76.7063630519208, 48.109072835862555, 34.777889954854395, 86.99800583760623, 33.60436582330116, 88.4161517525983, 32.07665318095563, 69.58955541523198, 35.11787526081494, 181.60919673699848, 48.825283116114406, 245.783983226805, 35.57844976118665, 66.07042065345026, 590.1400781197017, 73.49536424983386, 102.69553544567306, 322.1278276158808, 84.98207861456913, 139.83251258136758, 186.6225584034802, 210.89226570294818, 193.4084402866143, 107.16913677743888, 370.5268630865956, 256.04941129187876, 790.1636336614627, 173.53575950155837, 307.5996915828345, 652.4224690130533, 321.1741537174188, 507.56204112569975, 441.3573444920555, 43.20694947991316, 22.281242831925503, 20.80212054599665, 19.822945121872255, 19.25187818933419, 20.88818974777199, 15.648583543353002, 15.198556073262752, 17.77529503160602, 13.828834683038673, 13.644692650795578, 13.741819634144298, 13.614449563081429, 13.399662276617862, 15.100758982037549, 14.130760239510671, 23.770678392268835, 12.465543193526957, 26.07824941455723, 12.223452751737632, 12.102247351031318, 11.83709629045611, 11.894756622676216, 17.324620066303172, 11.685412659316455, 13.682307593582916, 11.553541294908038, 11.49229974404236, 11.429295363493578, 11.165405331872707, 37.68252790937966, 100.09372091628197, 55.87729520619084, 81.65177049926261, 14.048503563312314, 21.789682811271653, 59.48873970863338, 32.54311858206433, 23.55634100054184, 30.33209377195418, 36.43583983692179, 20.23643433848739, 37.72507016887213, 52.259978738206975, 23.183036413161275, 53.12091080417875, 170.12917859742387, 20.298467709008282, 33.64395715938245, 507.56204112569975, 174.00841476976714, 321.1741537174188, 138.06449571856416, 31.491356451796122, 157.74143374564898, 64.94263140261191, 65.5141211018142, 141.1058737680204, 114.28936028202645, 188.16735792093127, 49.40791691688002, 260.60906733908456, 135.38894059170516, 217.92201128337095, 370.5268630865956, 652.4224690130533, 245.783983226805, 790.1636336614627, 185.41597007738923, 188.71243437791134, 137.00226106231284, 590.1400781197017, 35.61514383934878, 27.769502410265833, 23.88244246015786, 21.80549593911839, 19.76377546231124, 18.30688946879053, 18.18155065208148, 19.018281057653024, 16.302988547533417, 15.897642865122567, 14.699185057384197, 14.491190995982262, 13.410877956722917, 13.404113073002117, 13.450980486563488, 12.921076926000701, 17.336385153425663, 15.06458201117052, 12.452085064222285, 12.318989119098417, 12.082509967388896, 20.24952367341374, 11.930778941746212, 11.882383031071507, 11.881896764706832, 11.538442751750601, 11.402094015305012, 11.261462382186119, 11.055660978541837, 11.114734342596838, 17.24116776534642, 42.70989899266527, 30.718968996273613, 174.00849026718706, 14.800222045963523, 29.204382114324282, 43.86070599599468, 14.800264938293187, 27.282478656766994, 40.68579426511837, 79.2787434408502, 78.6519507741906, 46.104509253268546, 241.19174277940994, 113.3007879384525, 23.39654070656322, 25.37143278195149, 86.95863850418756, 75.7587483006538, 305.2754187625174, 83.96718348402396, 81.41263330965725, 652.4224690130533, 297.5289732266183, 110.93406045507209, 98.6942802282366, 138.23707134702585, 104.6849661635666, 590.1400781197017, 139.34967194049457, 160.43312377106528, 266.02544112046974, 220.77010961044027, 184.6222682370342, 102.2869348395003, 207.07036667156632, 77.88151011621197, 260.60906733908456, 105.8797513193264, 790.1636336614627, 217.1793501510631, 40.236309984850614, 21.139464365370177, 18.56706616662729, 23.243341105815468, 16.708052342542608, 15.298805946410265, 14.934998231113706, 15.123832256806743, 13.965698892539827, 13.329905179176663, 16.878222095348082, 13.11181254961529, 12.926393903261797, 12.503532648094074, 12.39234058586775, 23.40295922291093, 16.88191334603001, 11.064291799573569, 11.056969209586152, 11.05081238294049, 11.083993048095397, 10.742972554196152, 10.552958457660496, 10.392618194396174, 10.258742261365978, 10.20223458881458, 11.365825784090642, 10.23148546793591, 10.12333567986487, 10.13105258471963, 18.603543509545396, 32.40383104778323, 28.55300778184879, 17.60347448342294, 26.158241304212154, 25.228537581795454, 40.393709233521854, 15.719377667185, 26.570368653676475, 29.367002028645086, 20.307342222519054, 70.12590908708759, 52.643194679391506, 33.720760021496595, 19.536873382753246, 75.36100972907295, 88.46185482028773, 35.04513296212864, 110.97911180650432, 60.120238367145085, 38.56728494591044, 71.07721295416108, 53.187082684218, 47.03333128018998, 84.1023279643202, 48.78076982963257, 87.25301081758795, 117.58201796066287, 70.64216635180895, 116.39932003505297, 110.44729660297156, 790.1636336614627, 82.899340907131, 507.56204112569975, 305.2754187625174, 173.02533695133195, 370.5268630865956, 75.40187390870986, 134.9431951205329, 321.1741537174188, 564.9791110935929, 74.00718971564618, 441.3573444920555, 503.1593048282433, 239.7039376509719, 21.322577128284518, 20.829415747756123, 18.794317991992678, 18.088038771927383, 18.07251129215194, 19.339465487104974, 18.618005272332642, 17.118775205655172, 15.77121594751134, 15.603263085992689, 15.182768993496975, 14.369356515560792, 14.060427144451817, 14.340017609324388, 13.217404891545028, 12.985304420498636, 12.87653880146648, 12.275807634651164, 16.76475970135919, 11.967363506601677, 13.392067972107686, 11.171502447328793, 11.099220799136166, 12.819948272543561, 10.95133277332539, 10.78386386226617, 10.619631195012992, 11.151364467903536, 11.264332938221843, 10.873479848624353, 22.341785186718415, 37.445487145650766, 23.52147272821523, 19.113551959163665, 14.734270908935441, 22.70509956239341, 30.8847336871989, 56.89118569344421, 61.37871044114841, 41.81339196858533, 42.17134593305054, 69.21257377929165, 66.74795968010999, 28.812267718467563, 156.23306040708246, 25.888394656567737, 37.401324745792245, 173.02533695133195, 41.80880885408661, 156.26087979287945, 93.24701007707415, 26.326375695022712, 71.71323351569423, 790.1636336614627, 503.1593048282433, 125.82370465505404, 52.56505343459987, 104.42386623188209, 55.89930777742901, 150.97865792287962, 44.6582836752243, 72.45516730135215, 57.4200399024388, 146.60391893866608, 307.5996915828345, 441.3573444920555, 652.4224690130533, 245.783983226805, 186.6225584034802, 169.95569696597826, 590.1400781197017, 301.9359738654153, 239.7039376509719, 23.866688370242652, 19.367636340741207, 17.748323121816814, 17.76376788123219, 17.01860892519333, 15.28990707728969, 14.953528761830274, 14.574204910361225, 14.390516537389423, 14.167150966733862, 13.702998539947407, 14.073306244117113, 13.351497805114903, 13.35341160984659, 13.303544151905756, 23.025090544780443, 12.472530014960595, 12.787668807484428, 12.009623450251844, 13.147846820166002, 11.823288128455658, 12.882323520172767, 11.70588942680374, 11.071533972423879, 10.8326476380297, 14.0390545202242, 10.789894283677445, 10.506831260746473, 9.88275926566784, 10.261455822404429, 52.598095147145685, 38.61141296814983, 30.38084397324588, 17.232893284471192, 15.975492685281345, 23.605983640076868, 23.930832570260666, 16.226300165871958, 22.228691720696187, 53.56380836550664, 17.168032996964072, 67.37992410359855, 25.80218993561443, 58.54376917679731, 19.994660888885374, 17.99991576360069, 54.319346538006855, 34.226291123160806, 29.511329465256523, 42.92872948265284, 29.52004735927967, 42.113184304513325, 25.094953309085863, 590.1400781197017, 50.88623973846939, 48.7428181273924, 188.16735792093127, 61.62803116131545, 35.689272626814315, 57.69895817835355, 31.895620497350343, 87.23593531157029, 57.33390518501717, 88.85573387504992, 59.58661629709022, 652.4224690130533, 790.1636336614627, 125.29531744935855, 220.77010961044027, 57.11634182924093, 564.9791110935929, 55.91632492785489, 370.5268630865956, 217.1793501510631, 441.3573444920555, 150.97865792287962, 159.41455146686243], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.8911, -6.2435, -6.3083, -6.1694, -6.1694, -6.5171, -6.534, -6.5366, -6.559, -6.5919, -6.5781, -5.7529, -6.7442, -6.7913, -6.5581, -6.6869, -6.8696, -6.7857, -6.8786, -6.8567, -6.9082, -6.9317, -6.9918, -6.993, -7.0673, -7.0673, -7.0787, -7.0894, -7.0907, -7.1194, -6.168, -6.9439, -6.3962, -6.7496, -5.0061, -6.6637, -6.4099, -6.8255, -6.3962, -4.8086, -5.6416, -5.2646, -6.5724, -4.584, -6.4809, -4.7933, -5.7469, -4.5305, -5.3545, -5.4386, -4.2446, -5.2994, -5.6244, -5.4571, -5.2342, -5.4183, -6.0088, -5.0553, -5.3268, -5.9033, -5.8515, -5.0012, -5.3634, -4.7663, -5.5114, -4.9319, -5.5276, -5.5328, -4.983, -5.1016, -5.5243, -5.4575, -5.6814, -5.648, -5.644, -5.763, -6.1653, -6.5578, -6.5794, -6.4952, -6.5392, -6.7116, -6.6109, -6.7662, -6.8133, -6.37, -6.8492, -6.8428, -6.8471, -6.8625, -6.8893, -6.9128, -6.9175, -6.9573, -6.8824, -6.9784, -6.9388, -6.9324, -7.0357, -7.0526, -7.0569, -6.8635, -7.0969, -6.8791, -7.1229, -6.4585, -6.1329, -5.7071, -5.0593, -6.759, -5.465, -6.5473, -6.3332, -5.1984, -6.6389, -6.3542, -6.5291, -5.0223, -5.8133, -5.1837, -6.507, -5.6189, -4.4428, -6.5559, -6.0538, -5.7749, -5.1787, -5.7814, -6.0568, -6.0375, -5.6476, -5.495, -5.7886, -5.6183, -5.5289, -4.8159, -5.7312, -4.7656, -6.1581, -5.51, -5.9419, -5.9216, -5.4237, -5.7637, -5.5468, -5.4509, -5.3526, -5.6938, -5.7109, -5.7244, -5.4476, -5.6597, -5.7685, -6.261, -6.3234, -6.4709, -6.4813, -6.5259, -6.519, -6.5764, -6.5677, -6.5739, -6.4536, -6.6217, -6.6234, -6.6192, -6.1599, -6.6614, -6.6888, -6.713, -6.7126, -6.7528, -6.7583, -6.768, -6.7673, -6.8204, -6.8828, -6.8889, -5.894, -6.913, -6.9331, -6.9314, -6.4695, -6.0586, -6.4189, -6.2684, -6.2442, -6.2882, -6.3253, -4.2677, -3.8752, -6.3631, -4.6791, -5.3305, -6.2036, -4.9264, -4.163, -4.1068, -5.9046, -6.1803, -5.6083, -5.4418, -5.7054, -5.7615, -6.0849, -5.7719, -5.644, -5.6572, -5.5057, -5.6139, -6.0125, -5.262, -5.5065, -5.7386, -5.5317, -5.5606, -6.0127, -5.2304, -5.6629, -5.5304, -5.7587, -5.9227, -5.9484, -5.7425, -5.8483, -5.9046, -6.111, -6.2747, -6.4103, -6.4105, -6.5524, -6.6003, -6.6083, -6.4082, -6.7334, -6.571, -6.7586, -6.7793, -6.7905, -6.7385, -6.687, -6.9101, -6.9103, -6.9231, -6.9412, -6.9702, -7.0001, -7.0035, -6.828, -7.014, -7.0566, -7.065, -6.4722, -7.003, -7.1195, -7.1289, -7.0914, -5.6668, -6.9399, -6.3934, -6.6318, -5.1855, -5.316, -5.6643, -5.8205, -6.487, -6.3747, -5.9198, -5.7469, -5.551, -5.9346, -5.7981, -4.8365, -5.1918, -5.0608, -5.8274, -4.3633, -4.8253, -6.3852, -5.4413, -5.2246, -5.1757, -5.7549, -5.5205, -6.0886, -5.3628, -5.5666, -6.0577, -5.6956, -5.517, -5.6243, -5.9293, -5.3491, -5.57, -5.1665, -5.1048, -5.4951, -5.5576, -5.5645, -5.4603, -5.6464, -6.2507, -6.3768, -6.4244, -6.5979, -6.6004, -6.6273, -6.6395, -6.6761, -6.6779, -6.7381, -6.4564, -6.8649, -6.877, -6.8663, -6.9309, -6.9337, -6.9387, -6.9472, -6.9662, -6.9336, -6.8827, -6.878, -6.6593, -6.8454, -6.4348, -7.0258, -7.0279, -7.0674, -6.9799, -7.0872, -6.8137, -6.3796, -6.1663, -6.1106, -6.731, -5.2384, -4.9675, -5.2746, -5.706, -6.1573, -6.5056, -5.1502, -6.2023, -6.6205, -5.4665, -5.8392, -6.0995, -5.3981, -6.1412, -5.4322, -6.1779, -5.637, -6.1241, -5.0586, -5.9293, -4.9012, -6.1568, -5.813, -4.6198, -5.7857, -5.6237, -5.0935, -5.747, -5.532, -5.5153, -5.5337, -5.5732, -5.781, -5.4462, -5.5558, -5.3033, -5.6999, -5.6055, -5.4832, -5.6444, -5.6418, -5.6834, -5.5977, -6.2717, -6.3433, -6.3944, -6.4247, -6.3482, -6.6431, -6.6749, -6.5202, -6.7747, -6.7891, -6.7821, -6.7915, -6.8085, -6.6892, -6.7582, -6.2398, -6.8863, -6.1483, -6.9084, -6.9184, -6.942, -6.9371, -6.5619, -6.956, -6.7994, -6.9686, -6.9743, -6.98, -7.0075, -5.8121, -4.8647, -5.484, -5.1335, -6.7856, -6.3834, -5.4795, -6.039, -6.3312, -6.1129, -5.9575, -6.4733, -5.9725, -5.7357, -6.3755, -5.7478, -4.8811, -6.4934, -6.1265, -4.3542, -5.0898, -4.7402, -5.3206, -6.2208, -5.3074, -5.8184, -5.8193, -5.4366, -5.5531, -5.405, -6.0063, -5.3221, -5.5985, -5.4451, -5.2684, -5.1458, -5.4755, -5.2203, -5.6624, -5.6687, -5.7532, -5.5336, -5.7674, -6.0248, -6.1798, -6.2747, -6.3772, -6.4576, -6.4648, -6.4243, -6.5798, -6.6075, -6.6905, -6.7054, -6.7878, -6.7883, -6.786, -6.828, -6.5343, -6.6763, -6.8682, -6.8794, -6.9, -6.3844, -6.9136, -6.918, -6.9185, -6.9505, -6.9627, -6.9762, -6.9962, -6.991, -6.5542, -5.6616, -6.001, -4.4798, -6.7228, -6.1082, -5.7559, -6.7229, -6.2033, -5.9468, -5.4349, -5.4581, -5.8667, -4.6308, -5.2177, -6.381, -6.3219, -5.4683, -5.6041, -4.7018, -5.5545, -5.5915, -4.3797, -4.8561, -5.4498, -5.5487, -5.4046, -5.5548, -4.7043, -5.4721, -5.4399, -5.2263, -5.3492, -5.4885, -5.7043, -5.5398, -5.8099, -5.5774, -5.7925, -5.6479, -5.7691, -5.5614, -6.2102, -6.3458, -6.1265, -6.4575, -6.55, -6.5756, -6.5637, -6.6472, -6.6975, -6.4619, -6.7162, -6.7311, -6.7658, -6.7755, -6.1442, -6.4733, -6.8983, -6.899, -6.8999, -6.8973, -6.9305, -6.9498, -6.9666, -6.9808, -6.9869, -6.8791, -6.9843, -6.9954, -6.995, -6.3932, -5.8458, -5.9778, -6.4545, -6.0738, -6.1268, -5.6976, -6.5764, -6.09, -6.0019, -6.372, -5.3205, -5.5945, -6.0, -6.4228, -5.4047, -5.287, -5.9885, -5.2384, -5.6668, -5.9747, -5.5847, -5.772, -5.9408, -5.6526, -5.9373, -5.6522, -5.5156, -5.7621, -5.5655, -5.5988, -4.84, -5.7547, -5.1796, -5.3496, -5.5598, -5.3687, -5.81, -5.6653, -5.48, -5.3634, -5.8629, -5.6002, -5.6086, -5.8244, -6.2006, -6.225, -6.333, -6.3732, -6.3744, -6.3077, -6.3464, -6.431, -6.5178, -6.5294, -6.5582, -6.6168, -6.6403, -6.621, -6.7062, -6.7252, -6.7343, -6.7866, -6.4792, -6.8164, -6.7042, -6.8879, -6.8949, -6.7511, -6.9095, -6.9267, -6.9431, -6.8953, -6.8871, -6.9227, -6.2294, -5.7341, -6.1825, -6.3866, -6.6353, -6.2802, -6.0346, -5.5376, -5.4943, -5.8182, -5.8299, -5.4616, -5.4955, -6.1372, -4.932, -6.2514, -6.0233, -5.1127, -5.9845, -5.2594, -5.5484, -6.2613, -5.7911, -4.7057, -4.9136, -5.5565, -5.9449, -5.679, -5.9415, -5.614, -6.0468, -5.904, -6.0023, -5.7461, -5.5777, -5.5585, -5.4908, -5.7028, -5.8194, -5.838, -5.8898, -5.9378, -5.9693, -5.9897, -6.2077, -6.2995, -6.2988, -6.3462, -6.4572, -6.4808, -6.5085, -6.5218, -6.5388, -6.574, -6.5475, -6.6019, -6.6023, -6.6061, -6.0622, -6.6756, -6.6513, -6.7159, -6.6264, -6.7328, -6.6475, -6.7436, -6.8041, -6.8283, -6.5694, -6.8329, -6.8618, -6.9284, -6.8909, -5.2581, -5.5676, -5.8346, -6.3908, -6.4658, -6.1078, -6.1068, -6.456, -6.1895, -5.4631, -6.4156, -5.3874, -6.1189, -5.5526, -6.3154, -6.3919, -5.6222, -5.9642, -6.0654, -5.8309, -6.0731, -5.8671, -6.1885, -4.3494, -5.7956, -5.8404, -5.1141, -5.7237, -6.022, -5.7937, -6.0899, -5.6777, -5.8539, -5.6864, -5.8629, -5.1099, -5.1558, -5.6942, -5.5634, -5.9056, -5.3644, -5.9319, -5.5547, -5.717, -5.673, -5.8685, -5.8751], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.152, 2.143, 2.1407, 2.1365, 2.1365, 2.132, 2.1312, 2.1311, 2.1301, 2.1279, 2.1244, 2.1239, 2.1178, 2.1174, 2.1169, 2.1138, 2.1129, 2.1125, 2.1122, 2.1111, 2.1104, 2.1087, 2.1046, 2.1037, 2.099, 2.099, 2.0981, 2.0973, 2.0964, 2.0949, 2.0933, 2.0945, 2.0827, 2.0857, 2.0011, 2.0763, 2.0581, 2.0801, 2.0105, 1.7444, 1.8696, 1.7827, 2.0357, 1.4952, 2.0081, 1.4547, 1.7496, 1.3191, 1.5924, 1.6203, 1.1504, 1.5453, 1.631, 1.509, 1.3833, 1.4675, 1.7841, 1.1886, 1.3389, 1.709, 1.6723, 1.033, 1.1246, 0.4779, 1.1875, 0.3558, 1.0965, 1.0096, -0.0307, 0.0423, 0.8777, 0.2521, 1.2323, 0.8879, 0.2518, 2.1825, 2.1622, 2.1613, 2.1606, 2.1585, 2.1559, 2.1532, 2.1519, 2.1497, 2.1472, 2.1467, 2.1451, 2.1449, 2.1447, 2.1429, 2.142, 2.1409, 2.1405, 2.1378, 2.1378, 2.135, 2.1339, 2.1328, 2.132, 2.1306, 2.1303, 2.1286, 2.1271, 2.1258, 2.1249, 2.1239, 2.0915, 2.0623, 2.0051, 2.1106, 1.9858, 2.089, 2.0628, 1.8822, 2.0874, 2.0406, 2.069, 1.7728, 1.8996, 1.7308, 2.0477, 1.8228, 1.4715, 2.049, 1.8752, 1.7691, 1.3849, 1.6645, 1.7803, 1.7629, 1.527, 1.3496, 1.5473, 1.3793, 1.2552, 0.5878, 1.402, 0.3782, 1.7998, 1.0259, 1.5438, 1.5099, 0.8037, 1.1864, 0.7447, 0.4016, -0.0648, 0.8557, 0.8889, 0.9124, -0.4953, -0.4155, 0.3704, 2.1844, 2.1819, 2.1758, 2.1754, 2.1731, 2.1717, 2.1708, 2.1701, 2.17, 2.1686, 2.1684, 2.1681, 2.1681, 2.1661, 2.1658, 2.1648, 2.1631, 2.1628, 2.1611, 2.1605, 2.1597, 2.1595, 2.1567, 2.1526, 2.1524, 2.1501, 2.1499, 2.1494, 2.1494, 2.1486, 2.1436, 2.1448, 2.1372, 2.1362, 2.1332, 2.1116, 1.8775, 1.6595, 2.087, 1.6807, 1.7085, 1.9729, 1.4691, 1.1248, 0.8455, 1.7819, 1.9263, 1.6002, 1.3332, 1.4784, 1.5132, 1.7812, 1.481, 1.3525, 1.3348, 1.1388, 1.186, 1.6438, 0.6671, 0.8778, 1.2, 0.75, 0.7126, 1.5942, -0.0865, 0.8053, 0.3654, 0.9381, 1.2807, 1.3595, -0.3389, 0.0012, 0.6684, 2.2293, 2.2241, 2.2184, 2.2174, 2.2111, 2.209, 2.2081, 2.2056, 2.2014, 2.2008, 2.1998, 2.1985, 2.1978, 2.1928, 2.1921, 2.1897, 2.1896, 2.1887, 2.1874, 2.1849, 2.1823, 2.182, 2.1814, 2.181, 2.1783, 2.1773, 2.1756, 2.1751, 2.1731, 2.1722, 2.1715, 2.1388, 2.1668, 2.1426, 2.1534, 2.0499, 2.0414, 1.9942, 1.9951, 2.0987, 2.0767, 1.9886, 1.9352, 1.8793, 1.9344, 1.7921, 1.4039, 1.5295, 1.4149, 1.7642, 1.0404, 1.0704, 1.997, 1.3526, 1.1873, 1.106, 1.5418, 1.2794, 1.7828, 1.0215, 1.2155, 1.7351, 1.2873, 1.0297, 1.094, 1.5309, 0.5542, 0.919, 0.1213, -0.1525, 0.5459, 0.5039, 0.3645, -0.3165, 0.7598, 2.2327, 2.2321, 2.2263, 2.2219, 2.2218, 2.2203, 2.2196, 2.2175, 2.2156, 2.2137, 2.2072, 2.2054, 2.2045, 2.2041, 2.2006, 2.2001, 2.1994, 2.1993, 2.1979, 2.1974, 2.1973, 2.196, 2.1945, 2.1945, 2.1942, 2.1932, 2.1924, 2.1898, 2.1887, 2.1881, 2.1812, 2.1639, 2.1221, 2.1108, 2.1615, 1.989, 1.9551, 1.98, 2.0214, 2.0781, 2.1249, 1.8453, 2.0574, 2.1387, 1.8181, 1.9119, 1.9761, 1.7606, 1.9687, 1.7102, 1.9785, 1.7449, 1.9417, 1.3641, 1.807, 1.2189, 1.896, 1.6208, 0.6243, 1.5416, 1.369, 0.756, 1.4351, 1.1521, 0.8801, 0.7394, 0.7866, 1.1691, 0.2634, 0.5234, -0.351, 0.7682, 0.2903, -0.3394, 0.2081, -0.2468, -0.1487, 2.2608, 2.2491, 2.2462, 2.2433, 2.2423, 2.2371, 2.231, 2.2285, 2.2265, 2.2231, 2.2221, 2.222, 2.2219, 2.2209, 2.2206, 2.218, 2.2163, 2.2153, 2.2152, 2.2128, 2.2127, 2.2113, 2.2113, 2.2105, 2.2102, 2.209, 2.2089, 2.2085, 2.2083, 2.2042, 2.1832, 2.1537, 2.1174, 2.0885, 2.1964, 2.1597, 2.0592, 2.103, 2.1339, 2.0994, 2.0715, 2.1438, 2.0217, 1.9326, 2.1056, 1.9042, 1.6069, 2.1206, 1.9822, 1.0407, 1.3756, 1.1123, 1.3763, 1.9541, 1.2562, 1.6326, 1.6229, 1.2385, 1.3327, 0.9822, 1.7182, 0.7394, 1.1179, 0.7953, 0.4412, -0.002, 0.6446, -0.268, 0.7396, 0.7157, 0.9513, -0.2895, 2.2844, 2.2758, 2.2716, 2.2677, 2.2635, 2.2597, 2.2593, 2.2548, 2.2533, 2.2508, 2.2462, 2.2456, 2.2407, 2.2407, 2.2395, 2.2377, 2.2374, 2.2359, 2.2344, 2.234, 2.2328, 2.232, 2.2318, 2.2315, 2.231, 2.2284, 2.228, 2.227, 2.2254, 2.2253, 2.2231, 2.2085, 2.1987, 1.9857, 2.2071, 2.142, 2.0877, 2.207, 2.115, 1.9719, 1.8166, 1.8014, 1.927, 1.5082, 1.6768, 2.091, 2.069, 1.6908, 1.6928, 1.2015, 1.6397, 1.6335, 0.7641, 1.0729, 1.4658, 1.4838, 1.291, 1.4188, 0.5399, 1.2155, 1.1068, 0.8147, 0.8782, 0.9177, 1.2924, 0.7517, 1.4594, 0.4841, 1.1697, -0.6956, 0.4747, 2.3683, 2.3632, 2.3574, 2.3521, 2.3511, 2.3467, 2.3452, 2.3446, 2.3408, 2.337, 2.3366, 2.3348, 2.3342, 2.3327, 2.332, 2.3275, 2.325, 2.3226, 2.3225, 2.3222, 2.3217, 2.3198, 2.3183, 2.3168, 2.3156, 2.315, 2.3148, 2.3147, 2.3143, 2.3139, 2.308, 2.3005, 2.295, 2.3019, 2.2866, 2.2698, 2.2283, 2.2932, 2.2547, 2.2427, 2.2416, 2.0538, 2.0665, 2.1064, 2.2294, 1.8976, 1.855, 2.0794, 1.6768, 1.8614, 1.9974, 1.7761, 1.8787, 1.8329, 1.5399, 1.7999, 1.5035, 1.3418, 1.6048, 1.302, 1.3212, 0.1123, 1.4522, 0.2154, 0.5537, 0.9113, 0.3409, 1.4917, 1.0544, 0.3726, -0.0757, 1.4575, -0.0655, -0.205, 0.3208, 2.3642, 2.3632, 2.358, 2.3561, 2.3558, 2.3547, 2.354, 2.3533, 2.3486, 2.3476, 2.3462, 2.3426, 2.3409, 2.3405, 2.3368, 2.3355, 2.3348, 2.3303, 2.326, 2.326, 2.3257, 2.3233, 2.3227, 2.3224, 2.3215, 2.3198, 2.3187, 2.3176, 2.3158, 2.3156, 2.2887, 2.2675, 2.2841, 2.2875, 2.299, 2.2217, 2.1596, 2.0458, 2.0132, 2.0731, 2.0529, 1.9257, 1.9281, 2.1266, 1.6412, 2.1194, 1.9795, 1.3584, 1.9069, 1.3136, 1.5409, 2.0926, 1.5608, 0.2466, 0.49, 1.2332, 1.7176, 1.297, 1.6595, 0.9934, 1.7787, 1.4376, 1.5719, 0.8907, 0.318, -0.0238, -0.347, 0.4173, 0.576, 0.651, -0.6456, -0.0235, 0.1758, 2.4624, 2.4533, 2.4488, 2.4486, 2.444, 2.4402, 2.4388, 2.4368, 2.4362, 2.4348, 2.4329, 2.4328, 2.431, 2.4305, 2.4304, 2.4258, 2.4254, 2.4248, 2.4229, 2.4219, 2.4216, 2.4212, 2.4209, 2.4161, 2.4137, 2.4133, 2.413, 2.4107, 2.4054, 2.4052, 2.4038, 2.4034, 2.3761, 2.3869, 2.3876, 2.3552, 2.3426, 2.3819, 2.3337, 2.1805, 2.3659, 2.0268, 2.2552, 2.0021, 2.3136, 2.3422, 2.0074, 2.1273, 2.1744, 2.0341, 2.1664, 2.017, 2.2133, 0.8948, 1.8993, 1.8976, 1.2731, 1.7797, 2.0277, 1.7756, 2.0722, 1.4783, 1.7218, 1.4511, 1.6742, 0.0339, -0.2035, 1.0996, 0.664, 1.6738, -0.0767, 1.6688, 0.1549, 0.5268, -0.1384, 0.7389, 0.6779]}, \"token.table\": {\"Topic\": [8, 2, 4, 5, 7, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 7, 2, 5, 8, 1, 2, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 8, 3, 8, 9, 6, 3, 4, 10, 1, 1, 1, 10, 2, 3, 4, 6, 7, 9, 5, 2, 7, 6, 5, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 9, 2, 7, 9, 10, 9, 1, 2, 3, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 7, 5, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 6, 7, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 6, 3, 6, 2, 3, 4, 5, 7, 9, 10, 4, 5, 8, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 4, 5, 6, 7, 1, 3, 4, 8, 10, 4, 1, 2, 3, 4, 6, 7, 8, 10, 4, 5, 10, 2, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 8, 9, 2, 8, 10, 1, 9, 8, 10, 2, 5, 7, 7, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 5, 6, 2, 5, 6, 7, 9, 8, 1, 9, 5, 1, 2, 5, 8, 9, 10, 1, 4, 5, 7, 9, 10, 7, 6, 10, 9, 7, 1, 2, 6, 1, 9, 6, 9, 10, 9, 1, 2, 3, 5, 8, 9, 10, 9, 2, 4, 6, 9, 1, 4, 5, 6, 7, 8, 9, 2, 2, 5, 1, 5, 7, 5, 7, 8, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 7, 8, 9, 10, 5, 1, 2, 7, 8, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 8, 10, 5, 4, 2, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 8, 8, 5, 8, 10, 6, 10, 1, 6, 4, 5, 6, 7, 8, 9, 10, 9, 8, 2, 3, 6, 8, 2, 5, 9, 1, 3, 4, 6, 5, 6, 7, 9, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 10, 8, 3, 3, 5, 6, 8, 9, 1, 3, 4, 5, 7, 8, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 9, 10, 4, 5, 6, 10, 2, 4, 10, 1, 2, 3, 5, 6, 8, 9, 10, 2, 1, 4, 6, 8, 10, 9, 4, 8, 10, 1, 2, 1, 7, 8, 3, 4, 10, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 6, 2, 4, 5, 10, 8, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 5, 2, 4, 7, 5, 1, 2, 3, 5, 6, 7, 9, 10, 7, 8, 8, 9, 3, 7, 9, 1, 6, 9, 1, 3, 6, 8, 9, 10, 5, 9, 4, 1, 2, 2, 3, 6, 9, 4, 3, 4, 7, 9, 10, 4, 5, 9, 10, 7, 2, 2, 3, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 3, 10, 8, 6, 4, 1, 9, 1, 3, 4, 5, 7, 8, 9, 10, 10, 5, 9, 1, 2, 4, 5, 6, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 5, 2, 5, 10, 2, 4, 5, 6, 8, 1, 2, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 4, 6, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 8, 1, 3, 5, 6, 7, 8, 9, 3, 7, 8, 10, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 9, 10, 1, 2, 5, 6, 9, 10, 1, 2, 7, 4, 2, 8, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 7, 8, 10, 1, 2, 3, 4, 5, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 7, 8, 9, 10, 6, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 8, 1, 2, 4, 5, 6, 7, 8, 10, 1, 3, 4, 5, 6, 7, 9, 3, 6, 4, 8, 1, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 3, 4, 7, 9, 1, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 8, 3, 2, 5, 7, 7, 6, 4, 9, 1, 2, 5, 6, 8, 10, 3, 6, 8, 9, 3, 8, 1, 2, 5, 1, 2, 3, 4, 5, 7, 8, 9, 10, 8, 2, 4, 6, 7, 9, 10, 10, 1, 1, 2, 4, 10, 2, 8, 9, 10, 9, 1, 10, 8, 6, 3, 5, 7, 8, 1, 4, 5, 6, 8, 9, 1, 2, 3, 6, 4, 5, 6, 1, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 5, 10, 1, 4, 5, 6, 9, 10, 3, 1, 2, 3, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 4, 8, 9, 1, 2, 3, 4, 5, 6, 8, 10, 2, 1, 7, 2, 4, 6, 7, 10, 1, 2, 4, 6, 7, 8, 9, 5, 2, 5, 6, 7, 8, 5, 8, 9, 5, 9, 3, 4, 5, 7, 7, 2, 3, 4, 9, 10, 2, 1, 2, 4, 5, 6, 8, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 3, 4, 5, 7, 10, 1, 3, 4, 10, 8, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 2, 3, 5, 6, 7, 8, 9, 1, 3, 10, 1, 2, 3, 4, 5, 6, 3, 8, 9, 6, 1, 8, 2, 3, 4, 5, 6, 8, 9, 1, 6, 7, 8, 10, 2, 3, 5, 6, 7, 4, 3, 4, 6, 8, 9, 7, 5, 8, 2, 4, 1, 2, 3, 4, 5, 9, 2, 3, 5, 6, 7, 9, 10, 2, 6, 1, 3, 4, 6, 8, 9, 3, 2, 5, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 5, 8, 9, 10, 2, 6, 7, 2, 3, 4, 5, 6, 10, 1, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 10, 2, 5, 7, 8, 6, 1, 4, 5, 8, 9, 2, 3, 4, 6, 7, 8, 9, 10, 2, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 3, 5, 8, 10, 1, 1, 2, 3, 4, 5, 6, 7, 9, 10, 8, 1, 3, 4, 5, 6, 8, 1, 2, 3, 4, 3, 5, 5, 10, 8, 8, 1, 4, 5, 6, 7, 8, 9, 1, 8, 1, 8, 9, 3, 10, 7, 1, 5, 7, 8, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 3, 9, 1, 2, 3, 4, 5, 6, 8, 9, 3, 4, 8, 3, 7, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 9, 10, 3, 10, 2, 3, 4, 5, 6, 7, 9, 3, 2, 4, 5, 6, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 7, 8, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 5, 5, 1, 3, 4, 7, 7, 2, 3, 2, 4, 1, 4, 5, 6, 7, 10, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 1, 3, 4, 6, 7, 8, 9, 6, 1, 3, 6, 9, 5, 6, 10, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 8, 9, 4, 1, 3, 4, 5, 7, 8, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 2, 4, 5, 6, 7, 8, 9, 10, 3, 4, 1, 2, 3, 5, 7, 2, 6, 7, 8, 4, 4, 5, 1, 2, 4, 7, 8, 9, 10, 7, 1, 4, 1, 4, 1, 2, 3, 4, 6, 7, 8, 9, 10, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 8, 9, 9, 3, 5, 7, 9, 3, 10, 1, 2, 4, 5, 7, 8, 9, 10, 7, 1, 2, 1, 2, 3, 4, 5, 6, 7, 9, 5, 6, 4, 1, 10, 2, 4, 5, 9, 10, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 7, 9, 10, 3, 2, 7, 6, 7, 7, 9, 6, 1, 3, 6, 7, 9, 10, 1, 2, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 7, 8, 9, 10, 10, 1, 2, 4, 7, 2, 6, 9, 10, 10, 4, 10, 1, 6, 4, 9, 4, 10, 2, 10, 4, 1, 5, 8, 9, 1, 5, 6, 7, 1, 1, 5, 4, 10, 7, 2, 3, 8, 4, 8, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 2, 6, 3, 9, 2, 2, 4, 7, 9, 3, 6, 3, 9, 3, 6, 1, 2, 3, 5, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 2, 2, 10, 10, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 2, 4, 7, 9, 10, 10, 1, 2, 3, 4, 5, 7, 10, 5, 6, 10, 1, 2, 3, 5, 7, 9, 10, 2, 5, 8, 8, 1, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 8, 9, 3, 8, 9, 8, 9, 2, 3, 4, 5, 8, 9, 10, 10, 1, 2, 5, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 2, 3, 4, 5, 6, 7, 10, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 10, 2, 3, 4, 5, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 2, 3, 8, 1, 2, 3, 4, 5, 7, 9, 10, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 3, 6, 9, 2, 5, 9, 3, 1, 3, 4, 5, 8, 2, 4, 8, 10, 10, 3, 1, 7, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 8, 10, 6, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 4, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 10, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 5, 9, 1, 2, 3, 6, 10, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 8, 1, 2, 4, 6, 7, 8, 10, 8, 2, 1, 2, 3, 4, 5, 7, 8, 9, 10, 9, 1, 3, 4, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 4, 1, 3, 4, 5, 6, 7, 8, 10, 1, 2, 4, 6, 8, 9, 10, 4, 1, 2, 4, 5, 6, 8, 9, 10, 2, 3, 4, 5, 6, 7, 9, 4, 5, 6, 9, 10, 5, 9, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 4, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 4, 1, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 9, 10], \"Freq\": [0.8821596799849444, 0.02975803814475211, 0.20830626701326477, 0.7439509536188027, 0.05824779112300379, 0.8737168668450568, 0.9303672447536644, 0.14573842109628551, 0.09446008774759247, 0.051278333348693056, 0.08636350879779883, 0.13224412284662945, 0.15653385969601039, 0.07556807019807397, 0.12684640354676702, 0.03238631579917456, 0.09446008774759247, 0.7402581568237457, 0.12004186326871553, 0.08002790884581035, 0.06002093163435777, 0.8299610643893127, 0.09764247816344857, 0.9373954910040868, 0.09932808218569707, 0.7201285958463037, 0.12416010273212133, 0.024832020546424267, 0.024832020546424267, 0.024832020546424267, 0.02968960276582674, 0.04453440414874011, 0.06680160622311017, 0.4824560449446845, 0.01484480138291337, 0.22267202074370057, 0.007422400691456685, 0.06680160622311017, 0.01484480138291337, 0.05937920553165348, 0.1907136422218558, 0.0889996997035327, 0.07628545688874232, 0.025428485629580774, 0.5975694122951482, 0.012714242814790387, 0.9572816177839387, 0.9400520588209432, 0.0427296390373156, 0.9247772231866899, 0.08357419216937069, 0.041787096084685345, 0.8357419216937069, 0.9608043858502767, 0.9309028871805604, 0.8940526986697035, 0.08514787606378128, 0.02449426372227975, 0.02449426372227975, 0.012247131861139874, 0.8205578346963716, 0.08572992302797912, 0.02449426372227975, 0.9318469630731306, 0.06510635172171994, 0.8789357482432192, 0.9548678365412845, 0.9393207206471145, 0.38464412745357884, 0.22838245067556243, 0.10818116084631904, 0.09616103186339471, 0.03606038694877302, 0.09616103186339471, 0.03606038694877302, 0.012020128982924339, 0.023915782789191233, 0.2152420451027211, 0.047831565578382466, 0.717473483675737, 0.93477099680718, 0.9613547794161227, 0.9379729232387153, 0.9156366961048699, 0.9009641470307793, 0.020264598874168562, 0.08105839549667425, 0.14185219211917996, 0.05066149718542141, 0.4356888757946241, 0.040529197748337124, 0.1722490904304328, 0.05066149718542141, 0.02119627152914412, 0.07948601823429045, 0.25965432623201545, 0.2861496656434456, 0.08478508611657648, 0.20666364740915516, 0.01589720364685809, 0.03709347517600221, 0.9524337536635775, 0.9114035508003826, 0.10812845592891741, 0.153181979232633, 0.009010704660743118, 0.13516056991114675, 0.018021409321486236, 0.018021409321486236, 0.4775673470193852, 0.045053523303715586, 0.018021409321486236, 0.02299944012927121, 0.06899832038781363, 0.034499160193906815, 0.14949636084026285, 0.04599888025854242, 0.04599888025854242, 0.5404868430378734, 0.09199776051708485, 0.9607745009836317, 0.9056631735520918, 0.3561829922795088, 0.023745532818633917, 0.6173838532844819, 0.02039163981820178, 0.011328688787889878, 0.5687001771520719, 0.056643443939449395, 0.08836377254554105, 0.011328688787889878, 0.0838322970303851, 0.08836377254554105, 0.07250360824249523, 0.8999093974029791, 0.959714151618996, 0.9424967968981657, 0.03483104510895775, 0.17415522554478877, 0.017415522554478875, 0.278648360871662, 0.017415522554478875, 0.43538806386197193, 0.03483104510895775, 0.9166606795449832, 0.035022580025201484, 0.9105870806552386, 0.035022580025201484, 0.9603652808644463, 0.06766270144759837, 0.1127711690793306, 0.04886750660104326, 0.18043387052692897, 0.08645789629415346, 0.0939759742327755, 0.2255423381586612, 0.09021693526346448, 0.04886750660104326, 0.05262654557035428, 0.5721810070404414, 0.18725923866778083, 0.031209873111296804, 0.09362961933389041, 0.010403291037098935, 0.010403291037098935, 0.10403291037098936, 0.6718507936348709, 0.06501781873885847, 0.1517082437240031, 0.08669042498514462, 0.9229144287232455, 0.925789082344582, 0.9138341743994084, 0.032636934799978874, 0.032636934799978874, 0.032636934799978874, 0.9309602838842926, 0.0552289412741908, 0.018409647091396933, 0.018409647091396933, 0.018409647091396933, 0.07363858836558773, 0.018409647091396933, 0.20250611800536628, 0.6075183540160988, 0.9726056437869618, 0.9312707512057833, 0.931508976715954, 0.030527769683299875, 0.06105553936659975, 0.1679027332581493, 0.5189720846160979, 0.045791654524949814, 0.045791654524949814, 0.1221110787331995, 0.057040258758464024, 0.04278019406884802, 0.014260064689616006, 0.014260064689616006, 0.14260064689616006, 0.6987431697911843, 0.014260064689616006, 0.8357781781317021, 0.09286424201463357, 0.9606012874189105, 0.9348003202842252, 0.03462223408460093, 0.10002670268400297, 0.8502269728140253, 0.05750780172679321, 0.7476014224483118, 0.20127730604377625, 0.9722896579529144, 0.9308890963494056, 0.023223015980420886, 0.12192083389720966, 0.040640277965736556, 0.4296257956377864, 0.017417261985315666, 0.14514384987763054, 0.06966904794126266, 0.02902876997552611, 0.12192083389720966, 0.9412539757953277, 0.9394316236965963, 0.9527513981226987, 0.023712783594518373, 0.047425567189036746, 0.18970226875614699, 0.023712783594518373, 0.7113835078355513, 0.9476015697513621, 0.9579414635252838, 0.9577362694229662, 0.9372570759574362, 0.0488768822029339, 0.016292294067644635, 0.11404605847351244, 0.016292294067644635, 0.66798405677343, 0.11404605847351244, 0.1358022981253242, 0.7178121472338566, 0.038800656607235494, 0.038800656607235494, 0.038800656607235494, 0.8986467541486847, 0.9533348855356665, 0.920307173172555, 0.03834613221552312, 0.922097939183322, 0.9464577763591697, 0.0862699762169453, 0.04313498810847265, 0.8195647740609803, 0.23176408114891878, 0.7339195903049094, 0.8955449586919632, 0.8951347454962149, 0.9401473451989697, 0.9510997788580128, 0.009784532938044668, 0.43051944927396535, 0.1565525270087147, 0.058707197628268, 0.12719892819458067, 0.12719892819458067, 0.06849173056631268, 0.9398476094812436, 0.1694248058580354, 0.0564749352860118, 0.6776992234321416, 0.0752999137146824, 0.66839547212549, 0.06169804358081446, 0.04113202905387631, 0.020566014526938153, 0.020566014526938153, 0.03084902179040723, 0.13367909442509798, 0.9352999363294642, 0.17283856551520024, 0.7950574013699211, 0.8408888893953664, 0.08008465613289205, 0.040042328066446024, 0.07598323058395048, 0.13297065352191334, 0.702844882901542, 0.07598323058395048, 0.04479688076298018, 0.211185295025478, 0.03199777197355727, 0.09599331592067181, 0.038397326368268724, 0.038397326368268724, 0.13439064228894054, 0.3327768285249956, 0.070395098341826, 0.02813841337996517, 0.05627682675993034, 0.0984844468298781, 0.12662286020984326, 0.02813841337996517, 0.5346298542193383, 0.0984844468298781, 0.02813841337996517, 0.9706324096814047, 0.17793193261881018, 0.02965532210313503, 0.02965532210313503, 0.7413830525783757, 0.9400300666354237, 0.041187204224176495, 0.029419431588697496, 0.07060663581287399, 0.25889099798053794, 0.15886493057896647, 0.047071090541915994, 0.11767772635478999, 0.17063270321444549, 0.09414218108383199, 0.16419437379557428, 0.4799527849409094, 0.03789100933744022, 0.06315168222906703, 0.1894550466872011, 0.07578201867488044, 0.31033694200286777, 0.04344717188040149, 0.16137520984149123, 0.0558606495605162, 0.1799954263616633, 0.19861564288183536, 0.04344717188040149, 0.01241347768011471, 0.9334545165392156, 0.8814783530069328, 0.013944427701494634, 0.1254998493134517, 0.013944427701494634, 0.013944427701494634, 0.19522198782092487, 0.11155542161195707, 0.43227725874633366, 0.09761099391046243, 0.9066917699916918, 0.15520336690526967, 0.7538449249684527, 0.022171909557895667, 0.044343819115791334, 0.8890350260636755, 0.9001471125965542, 0.05000817292203079, 0.9032172077425971, 0.929281956493753, 0.9020152722446506, 0.09178655868113021, 0.8719723074707371, 0.050454886472619184, 0.025227443236309592, 0.012613721618154796, 0.6054586376714303, 0.050454886472619184, 0.050454886472619184, 0.20181954589047674, 0.931927452323861, 0.9308410637327794, 0.1587737259794925, 0.06350949039179699, 0.698604394309767, 0.06350949039179699, 0.8727980326974697, 0.04848877959430387, 0.04848877959430387, 0.9597585459921549, 0.9359958377079408, 0.0389998265711642, 0.9585532108029996, 0.08011646338932582, 0.026705487796441937, 0.026705487796441937, 0.881281097282584, 0.011678728546599104, 0.5021853275037614, 0.011678728546599104, 0.046714914186396415, 0.046714914186396415, 0.18685965674558566, 0.03503618563979731, 0.046714914186396415, 0.11678728546599103, 0.011460922558771186, 0.18337476094033897, 0.09168738047016949, 0.10314830302894067, 0.011460922558771186, 0.011460922558771186, 0.02292184511754237, 0.4011322895569915, 0.1489919932640254, 0.9159321310585576, 0.9479671442651454, 0.9009728820619717, 0.127569105497895, 0.17009214066386, 0.1063075879149125, 0.552799457157545, 0.0212615175829825, 0.015135366024762537, 0.24216585639620059, 0.12108292819810029, 0.5146024448419263, 0.015135366024762537, 0.04540609807428761, 0.030270732049525073, 0.9654931120456632, 0.13541161767064205, 0.11916222355016502, 0.04874818236143114, 0.22207505297985297, 0.07583050589555955, 0.0324987882409541, 0.2491573765139814, 0.08666343530921092, 0.010832929413651365, 0.02166585882730273, 0.12278928099751821, 0.061394640498759104, 0.07674330062344888, 0.17267242640275998, 0.015348660124689776, 0.2110440767144844, 0.16116093130924267, 0.061394640498759104, 0.04220881534289689, 0.07674330062344888, 0.014981731348681013, 0.07490865674340506, 0.08989038809208608, 0.029963462697362025, 0.014981731348681013, 0.08989038809208608, 0.6142509852959215, 0.04494519404604304, 0.13554116579902548, 0.03388529144975637, 0.06777058289951274, 0.7115911204448837, 0.03984864955448794, 0.15939459821795177, 0.7571243415352709, 0.2034775331872411, 0.011304307399291173, 0.033912922197873514, 0.11304307399291172, 0.011304307399291173, 0.5765196773638498, 0.033912922197873514, 0.011304307399291173, 0.9147205490355431, 0.08916905897210654, 0.029723019657368847, 0.7430754914342211, 0.029723019657368847, 0.11889207862947539, 0.8967512476865539, 0.965097198229536, 0.0580285610484871, 0.8704284157273066, 0.9037624951862433, 0.9282464287697931, 0.04938387767179593, 0.9382936757641227, 0.9049108475895704, 0.8781402893870758, 0.04181620425652742, 0.04181620425652742, 0.9570041735323997, 0.9216344205734055, 0.027532785534904083, 0.0688319638372602, 0.0458879758915068, 0.4221693782018626, 0.05047677348065749, 0.22485108186838335, 0.013766392767452042, 0.06424316624810952, 0.0229439879457534, 0.05506557106980817, 0.9390022505352217, 0.0985296047303323, 0.8375016402078246, 0.02847552685272549, 0.2278042148218039, 0.7118881713181372, 0.02847552685272549, 0.9694584937901206, 0.8818627238843603, 0.05511642024277252, 0.06935400451423669, 0.10403100677135503, 0.0577950037618639, 0.005779500376186391, 0.02889750188093195, 0.08091300526660947, 0.052015503385677515, 0.22540051467126923, 0.35254952294736985, 0.02889750188093195, 0.9230121628017585, 0.9688254209905237, 0.9364542995657629, 0.9344698166550499, 0.9498489040702511, 0.9286121505776005, 0.9373567093402233, 0.0499531834187879, 0.00999063668375758, 0.00999063668375758, 0.00999063668375758, 0.8691853914869094, 0.00999063668375758, 0.01998127336751516, 0.01998127336751516, 0.8997066139201675, 0.8773005277551078, 0.9038084118845647, 0.904703003639871, 0.9439029862635976, 0.8783652001724866, 0.9346463054619943, 0.9231592736645202, 0.0659399481188943, 0.9668060426832604, 0.09980000350895017, 0.14970000526342525, 0.06653333567263345, 0.5821666871355426, 0.0831666695907918, 0.016633333918158362, 0.052318899288657184, 0.8894212879071721, 0.9510229710591992, 0.9810387738677975, 0.922684737910261, 0.1295138251963597, 0.06475691259817985, 0.032378456299089926, 0.7770829511781582, 0.9525478386136977, 0.5398632964013532, 0.035990886426756886, 0.07198177285351377, 0.07198177285351377, 0.2879270914140551, 0.044042969168754754, 0.044042969168754754, 0.8368164142063403, 0.9486974666239653, 0.9647350728063387, 0.9616966522206271, 0.6712390779981096, 0.15255433590866127, 0.07627716795433064, 0.04576630077259838, 0.015255433590866126, 0.03051086718173225, 0.024876473509657014, 0.15755099889449442, 0.029022552427933185, 0.06633726269241871, 0.11609020971173274, 0.12438236754828508, 0.44777652317382627, 0.00414607891827617, 0.03316863134620936, 0.48549686931594627, 0.03236645795439642, 0.12484205210981475, 0.12484205210981475, 0.04623779707770917, 0.09709937386318926, 0.06935669561656375, 0.01849511883108367, 0.08606237517174058, 0.24459832943547322, 0.05435518431899405, 0.040766388239245534, 0.08153277647849107, 0.045295986932495036, 0.2400687307422237, 0.049825585625744545, 0.15853595426373263, 0.04685123996159203, 0.9370247992318407, 0.9621143413249915, 0.9152052742206178, 0.9271057181068244, 0.9582958778361869, 0.9037802933406206, 0.04303715682574384, 0.09450227025971814, 0.12886673217234293, 0.01718223095631239, 0.23196011791021726, 0.1632311940849677, 0.3350535036480916, 0.01718223095631239, 0.008591115478156195, 0.9176156893171767, 0.059648931318647284, 0.8947339697797092, 0.08046161440834018, 0.011494516344048597, 0.011494516344048597, 0.597714849890527, 0.12643967978453455, 0.011494516344048597, 0.022989032688097193, 0.14942871247263176, 0.016687251945874663, 0.7092082076996732, 0.016687251945874663, 0.008343625972937332, 0.008343625972937332, 0.012515438959405998, 0.12515438959405997, 0.10846713764818532, 0.9122180236679173, 0.04498690307846335, 0.04498690307846335, 0.8547511584908036, 0.07654040618802668, 0.01913510154700667, 0.15308081237605337, 0.7079987572392468, 0.03827020309401334, 0.011890277287261808, 0.011890277287261808, 0.10701249558535626, 0.26158610031975976, 0.011890277287261808, 0.4161597050541633, 0.15457360473440349, 0.023780554574523615, 0.4221926463371935, 0.015521788468279174, 0.10865251927795422, 0.04656536540483752, 0.21730503855590844, 0.04656536540483752, 0.06829586926042837, 0.018626146161935007, 0.01241743077462334, 0.043461007711181686, 0.9033727153728927, 0.8658359109932, 0.09114062220981052, 0.05953291261204459, 0.01700940360344131, 0.10205642162064787, 0.17859873783613378, 0.0765423162154859, 0.11056112342236853, 0.34869277387054687, 0.08504701801720656, 0.03401880720688262, 0.024853173672648173, 0.9692737732332787, 0.0072429917249575695, 0.2752336855483876, 0.24626171864855737, 0.3983645448726663, 0.028971966899830278, 0.021728975174872708, 0.021728975174872708, 0.4099976295956428, 0.02049988147978214, 0.5534967999541177, 0.02049988147978214, 0.9373717107352838, 0.941368556228187, 0.039905721153712576, 0.07981144230742515, 0.1037548749996527, 0.39905721153712576, 0.023943432692227547, 0.023943432692227547, 0.015962288461485032, 0.023943432692227547, 0.039905721153712576, 0.24741547115301799, 0.9400647486186776, 0.8560359161900536, 0.10272430994280643, 0.20170505637700437, 0.44823345861556524, 0.23532256577317176, 0.011205836465389132, 0.022411672930778264, 0.033617509396167394, 0.033617509396167394, 0.011205836465389132, 0.9335917815908027, 0.6569056790010654, 0.09060767986221592, 0.24917111962109378, 0.10778744021940677, 0.04619461723688861, 0.09238923447377723, 0.5235389953514044, 0.015398205745629539, 0.2309730861844431, 0.036653561158453085, 0.10996068347535926, 0.8063783454859679, 0.9658645424253749, 0.9010135498907303, 0.10011261665452559, 0.9328096115373882, 0.29764884252124374, 0.05669501762309405, 0.014173754405773512, 0.12047691244907485, 0.347256982941451, 0.007086877202886756, 0.021260631608660267, 0.07795564923175431, 0.05669501762309405, 0.039637652272067704, 0.039637652272067704, 0.8720283499854895, 0.9567400129818269, 0.2696639344449721, 0.09168573771129052, 0.02157311475559777, 0.14561852460028493, 0.06471934426679331, 0.21033786886707825, 0.07011262295569275, 0.05932606557789386, 0.02696639344449721, 0.03775295082229609, 0.1017913562352652, 0.022620301385614487, 0.1017913562352652, 0.033930452078421734, 0.5655075346403622, 0.12441165762087968, 0.011310150692807244, 0.022620301385614487, 0.011310150692807244, 0.038756400231738194, 0.038756400231738194, 0.11626920069521458, 0.775128004634764, 0.3367693411546736, 0.1751200574004303, 0.006735386823093473, 0.19532621786971072, 0.053883094584747784, 0.0740892550540282, 0.14144312328496292, 0.006735386823093473, 0.0802421613868061, 0.2521896500728192, 0.011463165912400871, 0.1260948250364096, 0.034389497737202616, 0.011463165912400871, 0.011463165912400871, 0.06877899547440523, 0.045852663649603484, 0.355358143284427, 0.1575587684604235, 0.21382975719628905, 0.011254197747173107, 0.22508395494346214, 0.033762593241519326, 0.34888013016236635, 0.961440443332542, 0.08502868944940238, 0.8928012392187249, 0.018662089293053238, 0.3545796965680115, 0.06531731252568633, 0.07464835717221295, 0.32658656262843166, 0.009331044646526619, 0.018662089293053238, 0.037324178586106475, 0.09331044646526619, 0.9428542056256989, 0.023571355140642472, 0.17597555375223653, 0.019552839305804058, 0.009776419652902029, 0.1368698751406284, 0.07821135722321623, 0.36172752715737505, 0.10754061618192232, 0.09776419652902028, 0.05620676444302212, 0.3532996622132819, 0.3773882755460057, 0.008029537777574588, 0.08029537777574589, 0.11241352888604424, 0.008029537777574588, 0.9428298674035175, 0.9571626432474868, 0.8620422754134486, 0.09578247504593873, 0.38460582604499616, 0.013262269863620557, 0.026524539727241114, 0.15914723836344669, 0.3978680959086167, 0.25169120273549206, 0.01987035811069674, 0.14571595947844276, 0.006623452703565581, 0.013246905407131162, 0.03974071622139348, 0.006623452703565581, 0.1059752432570493, 0.2450677500319265, 0.1722097702927051, 0.9427378532936791, 0.01757741533791295, 0.0351548306758259, 0.0351548306758259, 0.21092898405495542, 0.703096613516518, 0.9260198774682268, 0.09601040881434343, 0.03200346960478114, 0.10881179665625589, 0.16001734802390571, 0.05760624528860606, 0.006400693920956229, 0.006400693920956229, 0.4672506562298047, 0.07040763313051852, 0.9164616587782406, 0.9256913037830776, 0.9767876771546927, 0.9386851773093445, 0.0702413274382878, 0.9131372566977415, 0.9630599578488213, 0.9501321258189721, 0.9214701444440063, 0.9131308679028921, 0.017896356584726145, 0.03579271316945229, 0.017896356584726145, 0.8411287594821287, 0.053689069754178434, 0.017896356584726145, 0.02475633010622659, 0.02475633010622659, 0.841715223611704, 0.09902532042490636, 0.9444149316082061, 0.946097765502668, 0.0711508317976995, 0.03557541589884975, 0.8538099815723941, 0.07904074895957075, 0.3872996699018967, 0.07904074895957075, 0.05532852427169952, 0.0632325991676566, 0.007904074895957075, 0.1264651983353132, 0.039520374479785375, 0.15017742302318443, 0.9477598701075312, 0.045598901216561315, 0.022799450608280657, 0.022799450608280657, 0.797980771289823, 0.045598901216561315, 0.045598901216561315, 0.9231353528839468, 0.9694649324031647, 0.15676133343809265, 0.15676133343809265, 0.031352266687618535, 0.6583976004399892, 0.037635909875177155, 0.8656259271290746, 0.037635909875177155, 0.037635909875177155, 0.9416522868229197, 0.11111163109131804, 0.8333372331848853, 0.8798304839405103, 0.9624390349675629, 0.05185742275622838, 0.2592871137811419, 0.02592871137811419, 0.6741464958309689, 0.013801638133562603, 0.13801638133562602, 0.09661146693493822, 0.15181801946918863, 0.22082621013700166, 0.37264422960619026, 0.039617559406628096, 0.8715863069458182, 0.039617559406628096, 0.039617559406628096, 0.030728462531281055, 0.12291385012512422, 0.8296684883445884, 0.16391991186339988, 0.02892704327001174, 0.37605156251015265, 0.009642347756670581, 0.06749643429669407, 0.019284695513341162, 0.0482117387833529, 0.12535052083671755, 0.16391991186339988, 0.9267931396814176, 0.9559373405730696, 0.9435144428217593, 0.9237346061046761, 0.014021215001019664, 0.7992092550581208, 0.014021215001019664, 0.028042430002039327, 0.014021215001019664, 0.12619093500917697, 0.9536906989357601, 0.03138272890367324, 0.8159509514955042, 0.010460909634557747, 0.052304548172788734, 0.020921819269115495, 0.010460909634557747, 0.03138272890367324, 0.04184363853823099, 0.6212884563870682, 0.02701254158204644, 0.1260585273828834, 0.07203344421879052, 0.01800836105469763, 0.07203344421879052, 0.04502090263674407, 0.02701254158204644, 0.025563194586605914, 0.6646430592517537, 0.07668958375981774, 0.07668958375981774, 0.12781597293302957, 0.01531864876535248, 0.5821086530833942, 0.10723054135746736, 0.03063729753070496, 0.01531864876535248, 0.03063729753070496, 0.19914243394958223, 0.03063729753070496, 0.9564245155989153, 0.947028853973376, 0.9257781158874938, 0.3020812578155909, 0.03356458420173232, 0.20138750521039392, 0.03356458420173232, 0.4363395946225202, 0.03789676669000721, 0.05684515003501082, 0.7579353338001442, 0.03789676669000721, 0.03789676669000721, 0.018948383345003605, 0.018948383345003605, 0.9683528147580256, 0.024578603369120947, 0.024578603369120947, 0.14747162021472568, 0.7127794977045074, 0.07373581010736284, 0.030860548511235705, 0.8949559068258355, 0.06172109702247141, 0.8317274051521183, 0.09980728861825419, 0.07016113366240323, 0.7249983811781667, 0.14032226732480646, 0.04677408910826882, 0.9661041665851726, 0.19064469008258075, 0.08665667731026397, 0.17331335462052794, 0.03466267092410559, 0.48527739293747824, 0.9496595226922485, 0.07033191133979502, 0.09377588178639337, 0.6095432316115569, 0.023443970446598343, 0.023443970446598343, 0.11721985223299171, 0.046887940893196686, 0.5580396122688266, 0.07440528163584353, 0.018601320408960884, 0.08370594184032398, 0.009300660204480442, 0.02790198061344133, 0.03720264081792177, 0.018601320408960884, 0.17671254388512841, 0.021949883032619327, 0.8779953213047731, 0.043899766065238655, 0.021949883032619327, 0.021949883032619327, 0.09541783288985073, 0.7633426631188058, 0.06361188859323381, 0.06361188859323381, 0.9138044045897694, 0.05375320026998644, 0.9544025573531687, 0.16106790182712646, 0.10265866270300368, 0.33275566531318435, 0.11681847824824557, 0.060179216067278024, 0.026549654147328537, 0.005309930829465708, 0.08318891632829609, 0.031859584976794246, 0.07610900855567515, 0.28106901978931165, 0.674565647494348, 0.722885005989658, 0.010630661852789089, 0.010630661852789089, 0.15945992779183632, 0.010630661852789089, 0.010630661852789089, 0.08504529482231271, 0.9414198694094728, 0.960329957552256, 0.036935767598163693, 0.02048119204187385, 0.02048119204187385, 0.22529311246061234, 0.06144357612562155, 0.6144357612562155, 0.06144357612562155, 0.9194614135196044, 0.0557249341527033, 0.9601805562959455, 0.925509976490838, 0.9220352041671893, 0.8796376663197911, 0.12705774993266236, 0.4202679420849601, 0.08796305764568933, 0.10751040378917584, 0.029321019215229775, 0.029321019215229775, 0.1954734614348652, 0.48998436828950176, 0.38498771794175135, 0.008749720862312531, 0.09624692948543784, 0.008749720862312531, 0.6333229988689978, 0.021838724098930958, 0.043677448197861915, 0.043677448197861915, 0.24022596508824054, 0.9505333291642574, 0.13447923151814542, 0.033619807879536355, 0.7900654851691045, 0.016809903939768178, 0.016809903939768178, 0.8929304096020706, 0.0636157500107368, 0.8906205001503152, 0.8973838034875875, 0.9742463274871429, 0.09731593958990024, 0.02432898489747506, 0.02432898489747506, 0.7541985318217269, 0.02432898489747506, 0.07298695469242518, 0.023534373748033088, 0.09413749499213235, 0.4353859143386121, 0.32948123247246325, 0.011767186874016544, 0.047068747496066175, 0.047068747496066175, 0.9285665536943004, 0.9089220936359901, 0.05301514327335164, 0.02650757163667582, 0.02650757163667582, 0.7687195774635989, 0.07952271491002746, 0.02650757163667582, 0.9568088715308654, 0.8905261570217303, 0.06360901121583788, 0.9368047046956767, 0.09652084279258341, 0.1650195054195781, 0.0747258137749033, 0.028022180165588734, 0.12765659853212646, 0.30824398182147605, 0.028022180165588734, 0.13077017410608077, 0.009340726721862912, 0.03736290688745165, 0.9346398310386421, 0.04063651439298444, 0.9121227775645435, 0.043055485683181995, 0.47692230295216975, 0.1026707735522032, 0.016559802185839228, 0.026495683497342763, 0.02980764393451061, 0.09935881311503536, 0.04967940655751768, 0.08942293180353182, 0.06623920874335691, 0.9698515619197468, 0.040536602072403206, 0.2567318131252203, 0.20268301036201603, 0.013512200690801068, 0.391853820033231, 0.040536602072403206, 0.05404880276320427, 0.049415820162453925, 0.8400689427617167, 0.049415820162453925, 0.01965167803986923, 0.09825839019934617, 0.19651678039869233, 0.11791006823921539, 0.01965167803986923, 0.5502469851163385, 0.42503309814353724, 0.5667107975247163, 0.9253654626923765, 0.018447398859832886, 0.10146069372908087, 0.35972427776674126, 0.09223699429916443, 0.07378959543933154, 0.08301329486924798, 0.11068439315899731, 0.0645658960094151, 0.09223699429916443, 0.009223699429916443, 0.2235061276402467, 0.2695220950955916, 0.17749016018490177, 0.03286854818238922, 0.03286854818238922, 0.026294838545911376, 0.03286854818238922, 0.12490048309307902, 0.08545822527421197, 0.03108085170988332, 0.1864851102592999, 0.03108085170988332, 0.48175320150319145, 0.046621277564824974, 0.01554042585494166, 0.13986383269447494, 0.046621277564824974, 0.01554042585494166, 0.3729636355558618, 0.04604489327850146, 0.027626935967100877, 0.08748529722915277, 0.15194814781905483, 0.009208978655700292, 0.1611571264747551, 0.13813467983550437, 0.07882881574676943, 0.03941440787338472, 0.7882881574676944, 0.03941440787338472, 0.962653597496762, 0.596145679223983, 0.016559602200666195, 0.3477516462139901, 0.016559602200666195, 0.016559602200666195, 0.06337864497637388, 0.07243273711585586, 0.13581138209222976, 0.1086491056737838, 0.11770319781326578, 0.3350014091608334, 0.06337864497637388, 0.08148682925533784, 0.05307499552072712, 0.9022749238523611, 0.02653749776036356, 0.35660665166876543, 0.029553037431113156, 0.023642429944890526, 0.023642429944890526, 0.0807783023117093, 0.28567936183409387, 0.013791417467852807, 0.11230154223823, 0.03743384741274333, 0.035463644917335786, 0.9472479992398181, 0.10429382494102844, 0.013036728117628555, 0.05214691247051422, 0.6257629496461706, 0.11733055305865699, 0.039110184352885664, 0.039110184352885664, 0.07176191992952968, 0.03588095996476484, 0.05740953594362374, 0.02870476797181187, 0.23681433576744793, 0.05740953594362374, 0.3372810236687895, 0.12917145587315343, 0.05023334395067077, 0.9612682821093514, 0.04591307898553415, 0.8723485007251489, 0.9089114773942543, 0.05680696733714089, 0.9513867866911198, 0.08396906296436346, 0.4198453148218173, 0.016793812592872694, 0.02519071888930904, 0.016793812592872694, 0.1595412196322906, 0.1091597818536725, 0.1259535944465452, 0.04198453148218173, 0.9151040969498002, 0.01508220692887683, 0.07541103464438415, 0.6786993117994574, 0.04524662078663049, 0.13573986235989147, 0.01508220692887683, 0.826022710415841, 0.04347487949557058, 0.04347487949557058, 0.04347487949557058, 0.056968521611792444, 0.8545278241768867, 0.8097225766600087, 0.16869220347083513, 0.9465076427629251, 0.9283331522933063, 0.01880155762513228, 0.2068171338764551, 0.01880155762513228, 0.05640467287539684, 0.01880155762513228, 0.5828482863791007, 0.05640467287539684, 0.07645773952234121, 0.879264004506924, 0.0759694392866285, 0.151938878573257, 0.7217096732229707, 0.23712699084812072, 0.7113809725443622, 0.9104068632833222, 0.13357094297349228, 0.044523647657830755, 0.014841215885943585, 0.17809459063132302, 0.6233310672096306, 0.8815336989577288, 0.09794818877308098, 0.3701915815609148, 0.05081060923385105, 0.014517316923957442, 0.07258658461978722, 0.0653279261578085, 0.10887987692968082, 0.0653279261578085, 0.21050109539738293, 0.021775975385936164, 0.014517316923957442, 0.06703448409443014, 0.12449261331822739, 0.009576354870632877, 0.009576354870632877, 0.06703448409443014, 0.0861871938356959, 0.06703448409443014, 0.3255960656015178, 0.22983251689518905, 0.9145607536251136, 0.907893803546581, 0.06354636766079531, 0.03631221009188304, 0.00907805252297076, 0.09985857775267835, 0.7262442018376608, 0.01815610504594152, 0.01815610504594152, 0.03631221009188304, 0.10237052576516974, 0.05118526288258487, 0.8189642061213579, 0.9671664554170684, 0.9630505773590785, 0.0584625495130163, 0.8769382426952445, 0.0569605871635706, 0.07323504063887648, 0.03661752031943824, 0.0284802935817853, 0.34583213635025006, 0.19122482833484417, 0.020343066844132358, 0.10578394758948825, 0.13833285454010003, 0.0040686133688264715, 0.035393835935478325, 0.05309075390321749, 0.017696917967739163, 0.6193921288708707, 0.1946660976451308, 0.05309075390321749, 0.017696917967739163, 0.9577194019964848, 0.10127529369350466, 0.2170184864860814, 0.06510554594582442, 0.14467899099072093, 0.021701848648608142, 0.028935798198144187, 0.36169747747680236, 0.014467899099072094, 0.043403697297216284, 0.11010377634928493, 0.06707471432772531, 0.25184656889089313, 0.08858924533850512, 0.07213695691849703, 0.07719919950926875, 0.04935686526002428, 0.10124485181543443, 0.11516601894005667, 0.06707471432772531, 0.7359138990230945, 0.016353642200513212, 0.032707284401026424, 0.1308291376041057, 0.04906092660153963, 0.016353642200513212, 0.9721812975298708, 0.9106768421715485, 0.4374247042236184, 0.006339488467008962, 0.05705539620308066, 0.025357953868035847, 0.3550113541525019, 0.025357953868035847, 0.08875283853812548, 0.9261033766698117, 0.8005083275089183, 0.06157756365453218, 0.015394390913633045, 0.09236634548179827, 0.03078878182726609, 0.9067596881680909, 0.05037553823156061, 0.0599154278297406, 0.152511998112067, 0.09259657028232639, 0.3431519957521507, 0.04902171367887868, 0.021787428301723855, 0.08714971320689542, 0.07080914198060254, 0.11438399858405024, 0.010893714150861928, 0.02381882917843172, 0.01190941458921586, 0.0595470729460793, 0.27391653555196477, 0.512104827336282, 0.02381882917843172, 0.09527531671372688, 0.930739270534747, 0.012908823759438795, 0.05163529503775518, 0.4905353028586742, 0.03872647127831638, 0.02581764751887759, 0.2323588276698983, 0.03872647127831638, 0.05163529503775518, 0.02581764751887759, 0.012908823759438795, 0.4283172679996078, 0.02106478367211186, 0.06319435101633558, 0.08425913468844744, 0.15447508026215362, 0.02106478367211186, 0.07723754013107681, 0.04915116190159434, 0.04212956734422372, 0.056172756458964954, 0.14629403484912729, 0.05201565683524526, 0.1560469705057358, 0.3023410053548631, 0.1365410991925188, 0.029258806969825458, 0.016254892761014144, 0.02600782841762263, 0.1235371849837075, 0.013003914208811316, 0.9022005062048652, 0.9230379272631181, 0.9087955739123208, 0.07088926699377021, 0.23039011772975318, 0.6025587694470468, 0.08861158374221276, 0.9257402299888714, 0.9303660165412909, 0.9436832498450113, 0.9613486095386289, 0.8869920331715997, 0.021670847284206127, 0.5851128766735655, 0.043341694568412255, 0.06501254185261839, 0.26005016741047354, 0.021670847284206127, 0.9152608232455146, 0.9827280259733459, 0.18300739774208946, 0.07286405650842451, 0.02880672001495853, 0.015250616478507456, 0.1914799624523714, 0.07625308239253728, 0.17114580714769478, 0.01694512942056384, 0.04744636237757875, 0.19995252716265333, 0.009764432354472406, 0.09764432354472406, 0.6444525353951789, 0.029293297063417222, 0.14646648531708611, 0.06835102648130685, 0.2593041352732492, 0.08250586122330657, 0.47146206413318037, 0.07071930961997705, 0.07071930961997705, 0.023573103206659018, 0.010628836064331671, 0.1647469589971409, 0.01594325409649751, 0.021257672128663342, 0.05314418032165836, 0.27103531964045763, 0.06377301638599003, 0.02657209016082918, 0.07971627048248753, 0.29229299176912094, 0.9211401354519955, 0.2774926384284841, 0.30832515380942677, 0.012333006152377072, 0.024666012304754143, 0.024666012304754143, 0.12949656459995926, 0.172662086133279, 0.006166503076188536, 0.024666012304754143, 0.024666012304754143, 0.8956235535358535, 0.9693623371975477, 0.15219236883214438, 0.09512023052009022, 0.019024046104018047, 0.11414427662410827, 0.057072138312054134, 0.057072138312054134, 0.4946251987044692, 0.958485224228148, 0.06941487631388613, 0.10412231447082919, 0.06941487631388613, 0.7635636394527474, 0.9421548143409431, 0.061628343478031714, 0.862796808692444, 0.8990718761300123, 0.9396979246030277, 0.015663652709403342, 0.12530922167522673, 0.4072549704444869, 0.07048643719231504, 0.1879638325128401, 0.10181374261112172, 0.007831826354701671, 0.039159131773508354, 0.031327305418806684, 0.007831826354701671, 0.02078610002341507, 0.02078610002341507, 0.6859413007726973, 0.12471660014049042, 0.14550270016390549, 0.9596977154140972, 0.6445857576163997, 0.03222928788081999, 0.06445857576163998, 0.08057321970204996, 0.16114643940409992, 0.08472428137264808, 0.8472428137264808, 0.09564585857669966, 0.13868649493621452, 0.2295500605840792, 0.3156313333031089, 0.01434687878650495, 0.05260522221718482, 0.0286937575730099, 0.04304063635951485, 0.0860812727190297, 0.014155851266223133, 0.11324681012978506, 0.212337768993347, 0.0849351075973388, 0.014155851266223133, 0.45298724051914024, 0.014155851266223133, 0.09909095886356194, 0.9199814242111268, 0.03999919235700551, 0.05845705518449378, 0.11691411036898756, 0.6430276070294316, 0.07794274024599171, 0.11691411036898756, 0.042741361320969944, 0.042741361320969944, 0.812085865098429, 0.042741361320969944, 0.9311784322636976, 0.9358939221675593, 0.9710034962309205, 0.164677265876322, 0.5077549031186596, 0.0137231054896935, 0.2058465823454025, 0.0137231054896935, 0.0137231054896935, 0.06861552744846751, 0.8879841410133771, 0.8979491854518274, 0.9608929228587308, 0.9500405076485655, 0.9491764769610865, 0.52905962546276, 0.00839777183274222, 0.10917103382564888, 0.041988859163711104, 0.00839777183274222, 0.03359108733096888, 0.21834206765129777, 0.00839777183274222, 0.03359108733096888, 0.9022019372087513, 0.537414294166321, 0.4478452451386008, 0.93575949859008, 0.12643066732783292, 0.06896218217881796, 0.011493697029802994, 0.08045587920862096, 0.04022793960431048, 0.4022793960431048, 0.17240545544704491, 0.005746848514901497, 0.01724054554470449, 0.06896218217881796, 0.04290847592764695, 0.09296836450990173, 0.035757063273039125, 0.21454237963823475, 0.3218135694573521, 0.10727118981911737, 0.007151412654607825, 0.0286056506184313, 0.007151412654607825, 0.12872542778294085, 0.012466253557799935, 0.07479752134679961, 0.2929569586082985, 0.1371287891357993, 0.08103064812569959, 0.29919008538719843, 0.09973002846239948, 0.8960713891402211, 0.9245807304744468, 0.9354597379564265, 0.9436139129841298, 0.9293321241584318, 0.9241215770849983, 0.3494163507928037, 0.6289494314270466, 0.83975348405372, 0.009879452753573176, 0.009879452753573176, 0.039517811014292706, 0.009879452753573176, 0.009879452753573176, 0.009879452753573176, 0.07903562202858541, 0.9664722964237452, 0.9414212781211465, 0.9499484906620187, 0.09664924384972835, 0.12081155481216045, 0.531570841173506, 0.09664924384972835, 0.036243466443648134, 0.012081155481216044, 0.048324621924864176, 0.048324621924864176, 0.905035185561054, 0.9235411765895177, 0.923495230018062, 0.9123647616480892, 0.9293854801546285, 0.1460865269335747, 0.02921730538671494, 0.02921730538671494, 0.08765191616014482, 0.7012153292811586, 0.9427004936784226, 0.9430148788869239, 0.00973752165233132, 0.01947504330466264, 0.0973752165233132, 0.06816265156631925, 0.3992383877455841, 0.03895008660932528, 0.02921256495699396, 0.16553786808963245, 0.1363253031326385, 0.02921256495699396, 0.9460173649564503, 0.9045139878483257, 0.9435361032614538, 0.8960527996865746, 0.9636862744928093, 0.9574286060318825, 0.9593381312573581, 0.9200767059527528, 0.9199788107402048, 0.9350137579191458, 0.9280113863377001, 0.058000711646106255, 0.9413445909614502, 0.09453534008795444, 0.5672120405277267, 0.07562827207036356, 0.07562827207036356, 0.09453534008795444, 0.07562827207036356, 0.06420009052905087, 0.11556016295229157, 0.2696403802220137, 0.4237205974917358, 0.012840018105810175, 0.1027201448464814, 0.012840018105810175, 0.00955247001214611, 0.01910494002429222, 0.08597223010931497, 0.2292592802915066, 0.00955247001214611, 0.41075621052228267, 0.00955247001214611, 0.13373458017004553, 0.09552470012146108, 0.9617457385689245, 0.09589177290999348, 0.647269467142456, 0.06392784860666233, 0.02397294322749837, 0.01598196215166558, 0.055936867530829534, 0.00799098107583279, 0.01598196215166558, 0.07191882968249512, 0.0869269721656974, 0.2318052591085264, 0.12073190578569083, 0.1014148008599803, 0.07726841970284214, 0.009658552462855267, 0.21248815418281586, 0.06760986723998687, 0.0289756573885658, 0.06760986723998687, 0.8877578508060836, 0.3494530308104939, 0.009444676508391727, 0.11333611810070073, 0.08500208857552553, 0.018889353016783454, 0.32111900128531873, 0.018889353016783454, 0.018889353016783454, 0.06611273555874209, 0.8770685325516658, 0.9333535146708299, 0.02168985238529799, 0.2819680810088739, 0.6723854239442377, 0.18669322262827892, 0.018669322262827893, 0.05600796678848368, 0.7281035682502878, 0.951761739751166, 0.051798156199302524, 0.9064677334877942, 0.13187352083483603, 0.8242095052177252, 0.8374631161818441, 0.12561946742727662, 0.917187041567594, 0.05095483564264411, 0.9068939669147464, 0.0477312614165656, 0.8738933449516109, 0.062350644523831704, 0.7482077342859804, 0.12470128904766341, 0.062350644523831704, 0.10978201731874591, 0.02744550432968648, 0.7959196255609079, 0.02744550432968648, 0.9055670191576323, 0.9425065608462232, 0.933137320827268, 0.0434308824130418, 0.9120485306738778, 0.9287151580881586, 0.04924327314930892, 0.09848654629861785, 0.8371356435382518, 0.08405887201371594, 0.2801962400457198, 0.6164317281005836, 0.9611174506546121, 0.149825027848318, 0.046100008568713234, 0.24202504498574448, 0.034575006426534924, 0.21897504070138785, 0.028812505355445772, 0.028812505355445772, 0.09220001713742647, 0.08067501499524816, 0.074912513924159, 0.9576220897549057, 0.017508124084516317, 0.05252437225354896, 0.2801299853522611, 0.05252437225354896, 0.12255686859161423, 0.035016248169032635, 0.43770310211290797, 0.00535840901847454, 0.03215045411084724, 0.47153999362575955, 0.05894249920321994, 0.24648681484982887, 0.01607522705542362, 0.16075227055423622, 0.01071681803694908, 0.9612962714945247, 0.9563835632417083, 0.9079360969033877, 0.08253964517303525, 0.9473114760181153, 0.9575016812786934, 0.9037670675293458, 0.9219850651587062, 0.9406551046053194, 0.947823110283616, 0.9574788548698085, 0.6529676290452515, 0.32648381452262576, 0.9399381704867278, 0.04947043002561725, 0.18486656702614007, 0.16540692839180954, 0.4086524113209412, 0.12648765112314847, 0.0583789159029916, 0.019459638634330534, 0.019459638634330534, 0.6333017736198177, 0.018094336389137648, 0.19903770028051412, 0.018094336389137648, 0.054283009167412945, 0.036188672778275296, 0.036188672778275296, 0.018094336389137648, 0.9467593157437416, 0.06583095590633523, 0.8887179047355256, 0.9362338631223815, 0.9412488738988342, 0.9441604325895689, 0.44825380902044604, 0.01338071071702824, 0.1739492393213671, 0.0669035535851412, 0.01338071071702824, 0.04683248750959884, 0.16056852860433887, 0.02007106607554236, 0.05352284286811296, 0.00669035535851412, 0.8659992921565144, 0.020515842916313077, 0.041031685832626154, 0.3487693295773223, 0.041031685832626154, 0.5539277587404531, 0.9126969734386129, 0.03379816063380562, 0.6421650520423068, 0.10139448190141687, 0.06759632126761124, 0.01689908031690281, 0.06759632126761124, 0.08449540158451406, 0.042451414673314425, 0.8490282934662885, 0.042451414673314425, 0.03416247413042653, 0.06832494826085306, 0.051243711195639786, 0.017081237065213264, 0.10248742239127957, 0.10248742239127957, 0.6149245343476775, 0.10017181793103423, 0.851460452413791, 0.8883578408796768, 0.9308520898259033, 0.01622638239703673, 0.09735829438222038, 0.03245276479407346, 0.06490552958814692, 0.14603744157333057, 0.178490206367404, 0.4867914719111019, 0.014448241777409516, 0.07224120888704758, 0.14448241777409515, 0.07224120888704758, 0.07224120888704758, 0.6212743964286092, 0.1362072981129749, 0.8512956132060931, 0.9273114096878589, 0.9044069681708273, 0.9196687848982531, 0.012652094353214937, 0.03795628305964482, 0.025304188706429875, 0.7464735668396814, 0.03795628305964482, 0.1391730378853643, 0.012652094353214937, 0.8987755662441745, 0.04059907542709993, 0.04059907542709993, 0.7713824331148987, 0.0608986131406499, 0.0608986131406499, 0.10817236789831522, 0.2073303718051042, 0.009014363991526268, 0.05408618394915761, 0.018028727983052537, 0.03605745596610507, 0.4326894715932609, 0.03605745596610507, 0.10817236789831522, 0.01319637496822972, 0.1451601246505269, 0.48826587382449965, 0.01319637496822972, 0.05278549987291888, 0.1319637496822972, 0.1451601246505269, 0.01360630034570188, 0.4762205120995658, 0.16327560414842257, 0.09524410241991316, 0.02721260069140376, 0.1360630034570188, 0.08163780207421129, 0.31709878086085563, 0.498298084209916, 0.13589947751179526, 0.01509994194575503, 0.03019988389151006, 0.012311661191221011, 0.024623322382442022, 0.03693498357366303, 0.7510113326644817, 0.024623322382442022, 0.1354282731034311, 0.012311661191221011, 0.9191665310351741, 0.1405956821086273, 0.1849943185639833, 0.014799545485118665, 0.31079045518749193, 0.05179840919791533, 0.007399772742559332, 0.1849943185639833, 0.08879727291071199, 0.007399772742559332, 0.8928894847325555, 0.029658381617130025, 0.7414595404282506, 0.17795028970278015, 0.05366792755189248, 0.07155723673585665, 0.1788930918396416, 0.10733585510378496, 0.07155723673585665, 0.035778618367928325, 0.4651220387830682, 0.017889309183964162, 0.9306707559270421, 0.013269461271751215, 0.02653892254350243, 0.013269461271751215, 0.039808383815253645, 0.13269461271751215, 0.013269461271751215, 0.5971257572288047, 0.05307784508700486, 0.10615569017400972, 0.0625958785559914, 0.8763422997838796, 0.11802168634149145, 0.15940591401967677, 0.09962869626229798, 0.07510470949004001, 0.07357196031677389, 0.1011614454355641, 0.21305213508399107, 0.01072924421286286, 0.06437546527717715, 0.08430120452963676, 0.0723769324863701, 0.19300515329698695, 0.060314110405308416, 0.10856539872955516, 0.02412564416212337, 0.02412564416212337, 0.0723769324863701, 0.3860103065939739, 0.03618846624318505, 0.03618846624318505, 0.895183613701982, 0.0895183613701982, 0.9033490002432464, 0.5038090083829517, 0.0390549618901513, 0.0390549618901513, 0.07029893140227234, 0.17184183231666572, 0.08201541996931773, 0.02733847332310591, 0.0390549618901513, 0.007810992378030259, 0.015621984756060518, 0.07206607098986387, 0.0196543829972356, 0.08189326248848167, 0.18016517747465968, 0.11465056748387434, 0.0196543829972356, 0.33084878045346594, 0.1572350639778848, 0.003275730499539267, 0.0196543829972356, 0.9636940269930191, 0.07175521336831304, 0.21526564010493912, 0.09567361782441738, 0.5979601114026087, 0.0802110625864264, 0.2406331877592792, 0.6416885006914111, 0.9063501832589149, 0.26687817211275167, 0.42700507538040267, 0.013343908605637583, 0.26687817211275167, 0.026687817211275167, 0.8679810951261185, 0.1058513530641608, 0.02117027061283216, 0.9578369676571331, 0.9259882837033383, 0.9207997059796907, 0.8941052234094208, 0.0558815764630888, 0.9597287692793901, 0.93497371129079, 0.27021935249173495, 0.023842884043388378, 0.007947628014462792, 0.14305730426033025, 0.07947628014462793, 0.03179051205785117, 0.007947628014462792, 0.07152865213016513, 0.3099574925640489, 0.047685768086776756, 0.028534632785689396, 0.17120779671413636, 0.05706926557137879, 0.7133658196422349, 0.028534632785689396, 0.9720658483313136, 0.034368087540491636, 0.06186255757288494, 0.33680725789681804, 0.006873617508098327, 0.04124170504858996, 0.06186255757288494, 0.1855876727186548, 0.16496682019435985, 0.1031042626214749, 0.07813945111943396, 0.7813945111943396, 0.03906972555971698, 0.07813945111943396, 0.3467953027599781, 0.01763365946237177, 0.005877886487457256, 0.011755772974914511, 0.505498237921324, 0.01763365946237177, 0.023511545949829023, 0.047023091899658045, 0.023511545949829023, 0.9330079078927209, 0.09239856989479311, 0.01319979569925616, 0.0659989784962808, 0.23759632258661087, 0.5411916236695026, 0.0659989784962808, 0.17501529062192273, 0.256272389839244, 0.06875600703004107, 0.08750764531096136, 0.06875600703004107, 0.031252730468200485, 0.16251419843464254, 0.11250982968552176, 0.031252730468200485, 0.9384040344379722, 0.9511296686366043, 0.1517362426418877, 0.09009339406862084, 0.22286260638027258, 0.004741757582558991, 0.2133790912151546, 0.08060987890350285, 0.061642848573266885, 0.12802745472909277, 0.023708787912794956, 0.028450545495353946, 0.9360412183331783, 0.011493692043009133, 0.16665853462363242, 0.02873423010752283, 0.005746846021504566, 0.0172405380645137, 0.0172405380645137, 0.7241025987095754, 0.011493692043009133, 0.02873423010752283, 0.11870619495438739, 0.8309433646807117, 0.9112482754070843, 0.06508916252907745, 0.017441686498991974, 0.2790669839838716, 0.17441686498991973, 0.052325059496975926, 0.45348384897379135, 0.06786898423277671, 0.8822967950260973, 0.01788697916074951, 0.19675677076824466, 0.07751024302991456, 0.2941414350878809, 0.05366093748224854, 0.05564837961122071, 0.061610705998137213, 0.07353535877197022, 0.14707071754394044, 0.02186186341869385, 0.05506329073456411, 0.11563291054258464, 0.16518987220369236, 0.03854430351419488, 0.40196202236231804, 0.13215189776295388, 0.005506329073456411, 0.060569619808020524, 0.027531645367282056, 0.9002314599165959, 0.12754035774937691, 0.5101614309975077, 0.1753679919053933, 0.015942544718672114, 0.015942544718672114, 0.14348290246804904, 0.015942544718672114, 0.8876450678368558, 0.9176667349837094, 0.05521441098104046, 0.039438864986457475, 0.18141877893770436, 0.34706201188082575, 0.007887772997291494, 0.007887772997291494, 0.07098995697562345, 0.18930655193499588, 0.09465327596749794, 0.9613373765046461, 0.5824418685934091, 0.0379853392560919, 0.08863245826421443, 0.025323559504061264, 0.16460313677639823, 0.08863245826421443, 0.012661779752030632, 0.38688401799075006, 0.017994605487941864, 0.1619514493914768, 0.29691099055104075, 0.008997302743970932, 0.04498651371985466, 0.008997302743970932, 0.017994605487941864, 0.008997302743970932, 0.03598921097588373, 0.11079191501494769, 0.08124740434429498, 0.08863353201195814, 0.022158383002989536, 0.08124740434429498, 0.3102173620418535, 0.12556417035027403, 0.014772255335326358, 0.007386127667663179, 0.16988093635625312, 0.049132423769979144, 0.012283105942494786, 0.03684931782748436, 0.07369863565496872, 0.15968037725243223, 0.5036073436422862, 0.08598174159746351, 0.012283105942494786, 0.06141552971247393, 0.8915302972169438, 0.2919659842826008, 0.12408554332010534, 0.0364957480353251, 0.02189744882119506, 0.26276938585434073, 0.04379489764239012, 0.06569234646358518, 0.1459829921413004, 0.17883864887226286, 0.01788386488722629, 0.07153545954890515, 0.1430709190978103, 0.05365159466167886, 0.10730318932335772, 0.4292127572934309, 0.9065969903755425, 0.6461141661927309, 0.06272953069832338, 0.0815483899078204, 0.006272953069832338, 0.018818859209497014, 0.012545906139664676, 0.006272953069832338, 0.1630967798156408, 0.05747989013771551, 0.014369972534428878, 0.014369972534428878, 0.589168873911584, 0.08621983520657327, 0.10058980774100214, 0.1293297528098599, 0.8067879199152921, 0.012412121844850648, 0.04964848737940259, 0.012412121844850648, 0.11170909660365583, 0.966882383209306, 0.9065539774195911, 0.9092155035921325, 0.9742074341107398, 0.07410525585278961, 0.029642102341115844, 0.06669473026751065, 0.06669473026751065, 0.23713681872892675, 0.06669473026751065, 0.18526313963197402, 0.25936839548476365, 0.022231576755836882, 0.019012095346845777, 0.019012095346845777, 0.019012095346845777, 0.038024190693691555, 0.9125805766485974, 0.08066441308127652, 0.050415258175797825, 0.21174408433835087, 0.15124577452739346, 0.06049830981095739, 0.08066441308127652, 0.28904748020790755, 0.01344406884687942, 0.06385932702267724, 0.9520890365318555, 0.10591276740739584, 0.09708670345677953, 0.07060851160493056, 0.10591276740739584, 0.5295638370369792, 0.00882606395061632, 0.00882606395061632, 0.07943457555554688, 0.19099080162866733, 0.2728440023266676, 0.03410550029083345, 0.00682110005816669, 0.09549540081433366, 0.09549540081433366, 0.0682110005816669, 0.2182752018613341, 0.02046330017450007, 0.31736548669250403, 0.08960907859553055, 0.09334279020367765, 0.09334279020367765, 0.09707650181182476, 0.04853825090591238, 0.1269461946770016, 0.0634730973385008, 0.026135981257029744, 0.04853825090591238, 0.5119711617026688, 0.06636663207256817, 0.0948094743893831, 0.05688568463362986, 0.037923789755753244, 0.009480947438938311, 0.16117610646195127, 0.05688568463362986, 0.8807369135900117, 0.01019846842341915, 0.6017096369817297, 0.050992342117095746, 0.01019846842341915, 0.09178621581077234, 0.01019846842341915, 0.13258008950444894, 0.061190810540514895, 0.030595405270257447, 0.8783626546011818, 0.010724204445519926, 0.15013886223727896, 0.05362102222759963, 0.12869045334623913, 0.0857936355641594, 0.07506943111863948, 0.07506943111863948, 0.41824397337527713, 0.005170405172173913, 0.015511215516521739, 0.5790853792834783, 0.02068162068869565, 0.22749782757565218, 0.010340810344347825, 0.13443053447652173, 0.010340810344347825], \"Term\": [\"aboard\", \"absolutely\", \"absolutely\", \"absolutely\", \"accessories\", \"accessories\", \"accounts\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"adele\", \"adele\", \"adele\", \"adele\", \"adults\", \"adults\", \"adventure\", \"africa\", \"africa\", \"africa\", \"africa\", \"africa\", \"africa\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aircraft\", \"alan\", \"alan\", \"alexander\", \"alive\", \"alive\", \"alive\", \"ancient\", \"anderson\", \"annual\", \"annual\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"appeal\", \"appreciate\", \"appreciate\", \"approve\", \"areas\", \"arrested\", \"arrested\", \"arrested\", \"arrested\", \"arrested\", \"arrested\", \"arrested\", \"arrested\", \"artist\", \"artist\", \"artist\", \"artist\", \"asbestos\", \"asks\", \"athletes\", \"attacked\", \"austin\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australians\", \"authority\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bar\", \"barcelona\", \"baseball\", \"baseball\", \"baseball\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"basically\", \"bayern\", \"beach\", \"becomes\", \"becomes\", \"becomes\", \"becomes\", \"becomes\", \"becomes\", \"becomes\", \"bee\", \"belong\", \"belong\", \"belong\", \"bernie\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bff\", \"bff\", \"bff\", \"bff\", \"bffs\", \"biden\", \"bin\", \"bin\", \"bin\", \"bin\", \"binge\", \"birth\", \"birth\", \"birth\", \"birth\", \"birth\", \"birth\", \"birth\", \"birth\", \"bit\", \"blast\", \"bobby\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bombings\", \"bombings\", \"bonds\", \"born\", \"born\", \"bowl\", \"bowl\", \"brazil\", \"brazil\", \"brazil\", \"breaks\", \"breed\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"britney\", \"broken\", \"brownies\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget\", \"burger\", \"burris\", \"butter\", \"butts\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buzzfeed\", \"buzzfeed\", \"buzzfeed\", \"buzzfeed\", \"buzzfeed\", \"cable\", \"caitlyn\", \"cake\", \"cake\", \"cameron\", \"candidates\", \"capital\", \"capital\", \"capital\", \"captain\", \"captain\", \"card\", \"carey\", \"carrie\", \"carrying\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"celebrities\", \"celebrities\", \"celebrities\", \"celebrities\", \"celebrity\", \"celebrity\", \"celebrity\", \"celebrity\", \"celebrity\", \"celebrity\", \"celebrity\", \"cereal\", \"champions\", \"champions\", \"changed\", \"changed\", \"changed\", \"channel\", \"channel\", \"channel\", \"channel\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"charge\", \"charged\", \"charged\", \"charged\", \"charged\", \"chili\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"cities\", \"citigroup\", \"claims\", \"claims\", \"claims\", \"claims\", \"claims\", \"claims\", \"claims\", \"claims\", \"cleared\", \"clinton\", \"clinton\", \"clinton\", \"clinton\", \"cnn\", \"coal\", \"coal\", \"colombian\", \"colonial\", \"comment\", \"comments\", \"comments\", \"confessions\", \"confessions\", \"confessions\", \"confessions\", \"confessions\", \"confessions\", \"confessions\", \"confused\", \"content\", \"control\", \"control\", \"control\", \"control\", \"cookies\", \"cookies\", \"cookies\", \"cooper\", \"cost\", \"cost\", \"costa\", \"costume\", \"costume\", \"costume\", \"costume\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"creating\", \"creative\", \"criticism\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"daughters\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"debt\", \"debt\", \"debt\", \"debt\", \"delay\", \"delay\", \"delay\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delta\", \"depression\", \"depression\", \"depression\", \"depression\", \"depression\", \"derby\", \"design\", \"dessert\", \"dessert\", \"detained\", \"detainee\", \"detainees\", \"detainees\", \"detects\", \"development\", \"development\", \"development\", \"died\", \"diego\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"dies\", \"diet\", \"dinners\", \"dinners\", \"direction\", \"direction\", \"direction\", \"direction\", \"dirty\", \"discovery\", \"discovery\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disney\", \"disneyland\", \"dissident\", \"diva\", \"diversity\", \"diys\", \"dubai\", \"dying\", \"earthquake\", \"earthquake\", \"earthquake\", \"earthquake\", \"earthquake\", \"earthquake\", \"earthquake\", \"earthquake\", \"eclipse\", \"edinburgh\", \"education\", \"edward\", \"efforts\", \"efron\", \"egyptian\", \"elect\", \"elect\", \"elected\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"electric\", \"electric\", \"elects\", \"else\", \"emas\", \"emergency\", \"emergency\", \"emergency\", \"emergency\", \"ending\", \"ends\", \"ends\", \"ends\", \"ends\", \"ends\", \"english\", \"english\", \"english\", \"enters\", \"entertainment\", \"escape\", \"european\", \"european\", \"european\", \"european\", \"european\", \"european\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everywhere\", \"everywhere\", \"exes\", \"expand\", \"experiences\", \"fair\", \"faith\", \"faith\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"falling\", \"fallon\", \"fallon\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"feud\", \"films\", \"films\", \"films\", \"final\", \"final\", \"final\", \"final\", \"final\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fisher\", \"flag\", \"flag\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"foods\", \"foods\", \"football\", \"football\", \"football\", \"football\", \"football\", \"football\", \"football\", \"forces\", \"forces\", \"forces\", \"forces\", \"forget\", \"form\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"founder\", \"fox\", \"fox\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"frank\", \"fraud\", \"fraud\", \"fraud\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"freed\", \"freed\", \"freed\", \"front\", \"fund\", \"fund\", \"funeral\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gave\", \"gave\", \"gave\", \"genocide\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gifts\", \"gilmore\", \"gilmore\", \"gilmore\", \"gilmore\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"girls\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"globes\", \"glorious\", \"glorious\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goes\", \"goes\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"grammy\", \"groom\", \"guantanamo\", \"guantanamo\", \"guaranteed\", \"guaranteed\", \"guaranteed\", \"guaranteed\", \"guaranteed\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guns\", \"guys\", \"guys\", \"guys\", \"guys\", \"guys\", \"hadid\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloween\", \"halloweentown\", \"harris\", \"healthier\", \"hear\", \"heartbreaking\", \"heartbreaking\", \"hemsworth\", \"hills\", \"hilton\", \"hire\", \"hits\", \"hits\", \"hits\", \"hits\", \"hits\", \"hits\", \"hogwarts\", \"hogwarts\", \"hogwarts\", \"hogwarts\", \"holders\", \"hole\", \"holidays\", \"holidays\", \"holidays\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"homeless\", \"honest\", \"honest\", \"honest\", \"honest\", \"honest\", \"honest\", \"honors\", \"horoscope\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"houses\", \"houses\", \"houses\", \"houses\", \"hughes\", \"humans\", \"humans\", \"hurts\", \"hysterical\", \"ideas\", \"ideas\", \"ideas\", \"ideas\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"ie\", \"ie\", \"ie\", \"ie\", \"immediately\", \"immediately\", \"immediately\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"indicted\", \"inspiring\", \"insurgents\", \"intense\", \"interviews\", \"interviews\", \"interviews\", \"interviews\", \"interviews\", \"interviews\", \"investigate\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"ireland\", \"ireland\", \"ireland\", \"ireland\", \"ireland\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"jason\", \"jaw\", \"jeremy\", \"jobs\", \"jobs\", \"jobs\", \"jobs\", \"jobs\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"joke\", \"jones\", \"jones\", \"jones\", \"jones\", \"jones\", \"justice\", \"justice\", \"justice\", \"kanye\", \"kanye\", \"kardashian\", \"kardashian\", \"kardashian\", \"kardashian\", \"karl\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"kelly\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"kim\", \"kim\", \"kim\", \"kim\", \"kim\", \"kind\", \"kind\", \"kind\", \"kind\", \"kingdom\", \"kingdom\", \"knope\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"knows\", \"knows\", \"korea\", \"korea\", \"korea\", \"korea\", \"korea\", \"korea\", \"korea\", \"kylo\", \"laden\", \"laden\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lake\", \"lake\", \"landing\", \"large\", \"largest\", \"las\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"laugh\", \"laugh\", \"laugh\", \"laugh\", \"laugh\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"launched\", \"law\", \"law\", \"law\", \"law\", \"law\", \"lawmaker\", \"lawyer\", \"lawyer\", \"lawyers\", \"lazy\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"league\", \"league\", \"league\", \"league\", \"league\", \"league\", \"league\", \"leak\", \"leaks\", \"leaves\", \"leaves\", \"leaves\", \"leaves\", \"leaves\", \"leaves\", \"leaving\", \"lesbian\", \"lesbian\", \"letting\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"lift\", \"lift\", \"lifts\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"linked\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"lived\", \"lived\", \"lived\", \"lives\", \"lives\", \"lives\", \"lives\", \"lives\", \"lives\", \"living\", \"living\", \"loans\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lovers\", \"lovers\", \"lovers\", \"lovers\", \"lucky\", \"lyrics\", \"lyrics\", \"lyrics\", \"lyrics\", \"lyrics\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"magnitude\", \"magnitude\", \"magnitude\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"makers\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manufacturer\", \"mark\", \"mark\", \"mars\", \"mars\", \"martha\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"meat\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"members\", \"members\", \"members\", \"members\", \"memorial\", \"memorial\", \"merger\", \"merger\", \"middle\", \"milan\", \"military\", \"military\", \"military\", \"military\", \"military\", \"military\", \"military\", \"minor\", \"minor\", \"minute\", \"minute\", \"minute\", \"miss\", \"miss\", \"montana\", \"month\", \"month\", \"month\", \"month\", \"month\", \"moves\", \"moves\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"munich\", \"murdoch\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"myanmar\", \"myanmar\", \"myanmar\", \"nail\", \"nd\", \"nears\", \"nears\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"needs\", \"needs\", \"needs\", \"needs\", \"needs\", \"needs\", \"needs\", \"nepal\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"nick\", \"nominated\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"norway\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nyc\", \"nyc\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obama\", \"obsessed\", \"obsessed\", \"obsessed\", \"obsessed\", \"obsessed\", \"obsessed\", \"obsessed\", \"ohio\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"ontario\", \"operation\", \"operations\", \"opposition\", \"opposition\", \"opposition\", \"opposition\", \"optimism\", \"orange\", \"osama\", \"panic\", \"paper\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"parts\", \"peak\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"photos\", \"pichilemu\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pixar\", \"placed\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"planning\", \"plant\", \"plant\", \"plant\", \"plant\", \"played\", \"plays\", \"plays\", \"points\", \"polar\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"pope\", \"pope\", \"pope\", \"pope\", \"pope\", \"posting\", \"posts\", \"posts\", \"posts\", \"posts\", \"posts\", \"powerful\", \"powerful\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"price\", \"price\", \"prices\", \"prices\", \"prices\", \"prices\", \"prices\", \"problems\", \"problems\", \"problems\", \"problems\", \"producer\", \"promises\", \"proof\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"proves\", \"pulls\", \"puppies\", \"puppy\", \"putting\", \"questions\", \"questions\", \"questions\", \"questions\", \"questions\", \"questions\", \"questions\", \"questions\", \"questions\", \"rapper\", \"read\", \"read\", \"reading\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"reasons\", \"reasons\", \"reasons\", \"reasons\", \"reasons\", \"reasons\", \"reasons\", \"rebuke\", \"recall\", \"records\", \"regulators\", \"relatable\", \"relations\", \"released\", \"released\", \"remember\", \"remember\", \"remember\", \"remember\", \"remember\", \"remember\", \"remember\", \"remember\", \"removed\", \"ren\", \"replace\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"republicans\", \"rescued\", \"researchers\", \"restore\", \"retail\", \"return\", \"return\", \"return\", \"return\", \"return\", \"reviews\", \"ride\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"ring\", \"rio\", \"riots\", \"risk\", \"robert\", \"robot\", \"rocket\", \"ron\", \"roundup\", \"routine\", \"rove\", \"rove\", \"ruined\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"russia\", \"russia\", \"russia\", \"russia\", \"russia\", \"russia\", \"russia\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"satellite\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"scenes\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"screencap\", \"screenshot\", \"secrets\", \"secrets\", \"secrets\", \"seen\", \"seen\", \"seen\", \"seen\", \"seize\", \"senator\", \"senator\", \"sense\", \"sense\", \"sent\", \"sent\", \"sentence\", \"sentence\", \"sentences\", \"sentences\", \"serbia\", \"seriously\", \"seriously\", \"seriously\", \"seriously\", \"sets\", \"sets\", \"sets\", \"sets\", \"severe\", \"shakes\", \"shanghai\", \"shelf\", \"shelf\", \"shocked\", \"shop\", \"shop\", \"shop\", \"shopping\", \"shopping\", \"shopping\", \"shops\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"showing\", \"shows\", \"shows\", \"shows\", \"shows\", \"shows\", \"shows\", \"shows\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"significant\", \"simpsons\", \"sinks\", \"sinks\", \"sir\", \"slytherin\", \"smartphone\", \"smoke\", \"snapchats\", \"snl\", \"soldiers\", \"somali\", \"somali\", \"somalia\", \"somalia\", \"song\", \"song\", \"song\", \"song\", \"song\", \"song\", \"song\", \"songs\", \"songs\", \"songs\", \"songs\", \"songs\", \"songs\", \"songs\", \"songs\", \"sounds\", \"southern\", \"southern\", \"speak\", \"spears\", \"squash\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"starting\", \"stories\", \"stories\", \"stories\", \"stories\", \"stories\", \"strangers\", \"strike\", \"strike\", \"strike\", \"strike\", \"strike\", \"strike\", \"strike\", \"strikes\", \"strikes\", \"strikes\", \"struggles\", \"struggles\", \"struggles\", \"struggles\", \"struggles\", \"struggles\", \"struggles\", \"styles\", \"styles\", \"subject\", \"sunny\", \"super\", \"super\", \"super\", \"super\", \"super\", \"super\", \"super\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"supreme\", \"supreme\", \"survivors\", \"suspends\", \"swedish\", \"swift\", \"swift\", \"swift\", \"swift\", \"swift\", \"swift\", \"swift\", \"syracuse\", \"taiwan\", \"taiwan\", \"taiwan\", \"taiwan\", \"taiwan\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"takes\", \"takes\", \"takes\", \"takes\", \"takes\", \"takes\", \"takes\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talks\", \"talks\", \"talks\", \"talks\", \"talks\", \"taylor\", \"taylor\", \"taylor\", \"taylor\", \"taylor\", \"taylor\", \"taylor\", \"teenage\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tennis\", \"term\", \"term\", \"term\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"thailand\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"thanksgiving\", \"therapy\", \"therapy\", \"things\", \"things\", \"things\", \"things\", \"things\", \"things\", \"things\", \"things\", \"things\", \"things\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"throw\", \"throw\", \"tibetan\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"times\", \"times\", \"times\", \"times\", \"times\", \"times\", \"times\", \"times\", \"times\", \"times\", \"toilet\", \"told\", \"told\", \"told\", \"told\", \"took\", \"took\", \"took\", \"touch\", \"tour\", \"tour\", \"tour\", \"tour\", \"tour\", \"town\", \"town\", \"town\", \"training\", \"trapped\", \"trash\", \"tree\", \"tree\", \"trend\", \"truly\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"turkey\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"tweet\", \"tweet\", \"tweet\", \"tweet\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"tweets\", \"twin\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"tyler\", \"uefa\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"underground\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"unemployment\", \"unemployment\", \"unexpected\", \"unexpected\", \"union\", \"union\", \"union\", \"union\", \"union\", \"unit\", \"unit\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"voices\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"voters\", \"wait\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warming\", \"wars\", \"wars\", \"wars\", \"wars\", \"wars\", \"wars\", \"wars\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wednesday\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"weird\", \"weird\", \"weird\", \"weird\", \"weird\", \"weird\", \"weird\", \"welcomes\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"west\", \"west\", \"west\", \"west\", \"west\", \"west\", \"west\", \"wikinews\", \"wikinews\", \"wikinews\", \"wikinews\", \"wikinews\", \"wild\", \"winners\", \"wireless\", \"wish\", \"women\", \"women\", \"women\", \"women\", \"women\", \"women\", \"women\", \"women\", \"women\", \"words\", \"words\", \"words\", \"words\", \"words\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worse\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"yes\", \"york\", \"york\", \"york\", \"york\", \"york\", \"york\", \"york\", \"york\", \"york\", \"zac\", \"zealand\", \"zealand\", \"zealand\", \"zealand\", \"zealand\", \"zealand\", \"zealand\", \"zealand\", \"zodiac\", \"zodiac\", \"zodiac\", \"zodiac\", \"zodiac\", \"zodiac\", \"zodiac\", \"zodiac\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 10, 3, 8, 5, 2, 1, 4, 6, 9]};\n","\n","function LDAvis_load_lib(url, callback){\n","  var s = document.createElement('script');\n","  s.src = url;\n","  s.async = true;\n","  s.onreadystatechange = s.onload = callback;\n","  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n","  document.getElementsByTagName(\"head\")[0].appendChild(s);\n","}\n","\n","if(typeof(LDAvis) !== \"undefined\"){\n","   // already loaded: just create the visualization\n","   !function(LDAvis){\n","       new LDAvis(\"#\" + \"ldavis_el41761403111783523845061559142\", ldavis_el41761403111783523845061559142_data);\n","   }(LDAvis);\n","}else if(typeof define === \"function\" && define.amd){\n","   // require.js is available: use it to load d3/LDAvis\n","   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n","   require([\"d3\"], function(d3){\n","      window.d3 = d3;\n","      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","        new LDAvis(\"#\" + \"ldavis_el41761403111783523845061559142\", ldavis_el41761403111783523845061559142_data);\n","      });\n","    });\n","}else{\n","    // require.js not available: dynamically load d3 & LDAvis\n","    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n","         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","                 new LDAvis(\"#\" + \"ldavis_el41761403111783523845061559142\", ldavis_el41761403111783523845061559142_data);\n","            })\n","         });\n","}\n","</script>"]},"metadata":{},"execution_count":76}],"source":["###############################\n","### DO NOT CHANGE THIS CELL ###\n","###############################\n","\n","# Visualize the topics\n","pyLDAvis.enable_notebook()\n","\n","LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n","LDAvis_prepared"]},{"cell_type":"code","source":[],"metadata":{"id":"s5uiBTDliM_T"},"id":"s5uiBTDliM_T","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"vscode":{"interpreter":{"hash":"2ee6b31008df61bf287af31da52ead66df33c846dd0c4e1be57a6e10a34390cc"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"9211e2182dbc48c08aa93bac6d3206c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a671306612a14b6cb0c9528e6fb9cddf","IPY_MODEL_77975ff29d2f4a6ab6aab030aa19efac","IPY_MODEL_ea2cf3910d9448ea93a65e80edff3b47"],"layout":"IPY_MODEL_4160b43446f94b3ca6cb917fd2e1d510"}},"a671306612a14b6cb0c9528e6fb9cddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa28abca94164a6e9e15ad9fab7075af","placeholder":"â€‹","style":"IPY_MODEL_2b0051b414cb416792a34a33f4f6f055","value":"config.json: 100%"}},"77975ff29d2f4a6ab6aab030aa19efac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c7e925499104388b209b68b4d46a8d8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29d830aa304b4c0e962e4b412ba66d26","value":570}},"ea2cf3910d9448ea93a65e80edff3b47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49bdaca2324b4764b38742577f3aa23c","placeholder":"â€‹","style":"IPY_MODEL_e0fad9fffae44f7394628bd0aa9f3a46","value":" 570/570 [00:00&lt;00:00, 33.5kB/s]"}},"4160b43446f94b3ca6cb917fd2e1d510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa28abca94164a6e9e15ad9fab7075af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b0051b414cb416792a34a33f4f6f055":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c7e925499104388b209b68b4d46a8d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d830aa304b4c0e962e4b412ba66d26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49bdaca2324b4764b38742577f3aa23c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fad9fffae44f7394628bd0aa9f3a46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8f0bfedcd114928a95ed3d56aa4fda3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ddec7bd60944e259cdf807360b3c5b2","IPY_MODEL_f988bcaa2d134768a9ec0a9b1d1b4a89","IPY_MODEL_ec809a3cac544f5fb7249f9a28a073ef"],"layout":"IPY_MODEL_e32c7a4cf7e5446180dbdae08c351dce"}},"2ddec7bd60944e259cdf807360b3c5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d86e694153f04c2f9ec745746e3009de","placeholder":"â€‹","style":"IPY_MODEL_61b23b7cb4644ce38126f6c807c96b0e","value":"model.safetensors: 100%"}},"f988bcaa2d134768a9ec0a9b1d1b4a89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05f3f577ee774f828ecef966ad318f98","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8c23177ce074d0aaa706d8effdbc96a","value":440449768}},"ec809a3cac544f5fb7249f9a28a073ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_300ed7ffdfda4492b98e1e6daca5fc47","placeholder":"â€‹","style":"IPY_MODEL_9a141c8603a548e5b179b4fa4fffb8e2","value":" 440M/440M [00:05&lt;00:00, 73.3MB/s]"}},"e32c7a4cf7e5446180dbdae08c351dce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d86e694153f04c2f9ec745746e3009de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61b23b7cb4644ce38126f6c807c96b0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05f3f577ee774f828ecef966ad318f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c23177ce074d0aaa706d8effdbc96a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"300ed7ffdfda4492b98e1e6daca5fc47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a141c8603a548e5b179b4fa4fffb8e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af84ab783df2417e8861ef689d0052ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_526217380908426fb0fa13af44f2465f","IPY_MODEL_41d23513e6784fccadfbffd52188ef2d","IPY_MODEL_58255d47fa334bca81e68467b811c779"],"layout":"IPY_MODEL_534db700d0964f8f8f5266ec6df57e9f"}},"526217380908426fb0fa13af44f2465f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b75b4e5e5a24f5e8352a5e15b7a6b26","placeholder":"â€‹","style":"IPY_MODEL_1f81054c2a784fcc9de6449b763e4cc1","value":"tokenizer_config.json: 100%"}},"41d23513e6784fccadfbffd52188ef2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31292cae39f440509eaf538015618192","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2db73d6aef3f46f8aebe2b74c029f5ff","value":28}},"58255d47fa334bca81e68467b811c779":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c23c5b166e6492eb28779468b94b293","placeholder":"â€‹","style":"IPY_MODEL_e6d0a80dae284549b2b2603bc75442cb","value":" 28.0/28.0 [00:00&lt;00:00, 1.51kB/s]"}},"534db700d0964f8f8f5266ec6df57e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b75b4e5e5a24f5e8352a5e15b7a6b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f81054c2a784fcc9de6449b763e4cc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31292cae39f440509eaf538015618192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db73d6aef3f46f8aebe2b74c029f5ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c23c5b166e6492eb28779468b94b293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d0a80dae284549b2b2603bc75442cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83cef0fc947841098ca793536fde2663":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_385ebf6471c54900b379a4512d302ed9","IPY_MODEL_69b44c70d4f54bdb8b297be21a85567c","IPY_MODEL_9d3f686e7d004741b4d10e5d00109ee0"],"layout":"IPY_MODEL_ab8554dda7264b269d36db63c8647ef3"}},"385ebf6471c54900b379a4512d302ed9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10c0c7037364edba1998937ded292f7","placeholder":"â€‹","style":"IPY_MODEL_a38a5767d09f41d6be9115fb87c4763c","value":"vocab.txt: 100%"}},"69b44c70d4f54bdb8b297be21a85567c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c6cc572790472896e77672d0ed7eeb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b75d6815f11e416694e94146ab92491c","value":231508}},"9d3f686e7d004741b4d10e5d00109ee0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c66c38013f34a1b8e9a0e5719922693","placeholder":"â€‹","style":"IPY_MODEL_402a4f745ec346c39fa57a60302f149d","value":" 232k/232k [00:00&lt;00:00, 3.27MB/s]"}},"ab8554dda7264b269d36db63c8647ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10c0c7037364edba1998937ded292f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a38a5767d09f41d6be9115fb87c4763c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4c6cc572790472896e77672d0ed7eeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b75d6815f11e416694e94146ab92491c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c66c38013f34a1b8e9a0e5719922693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"402a4f745ec346c39fa57a60302f149d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"307a5b70deae460cbee27e1b436bfe17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5eb23fbe51a461f8599201ea318cde0","IPY_MODEL_025b5cac04ad4ebaba20af904c39f6df","IPY_MODEL_2fdad60efa3f4b8c9385d22e7df787c2"],"layout":"IPY_MODEL_40af967212ad462da7060eec18fbd769"}},"d5eb23fbe51a461f8599201ea318cde0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a3130810414083af6045b973466d95","placeholder":"â€‹","style":"IPY_MODEL_725f3424b0f849cfa590bfc9447f9f61","value":"tokenizer.json: 100%"}},"025b5cac04ad4ebaba20af904c39f6df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c67987bc25c476bb3c4a009925397bc","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cc2afecbbe4432b9c5dc18679e1a795","value":466062}},"2fdad60efa3f4b8c9385d22e7df787c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_761432352b7643199e3c568565c7cf1c","placeholder":"â€‹","style":"IPY_MODEL_651812e83a87494b84de4d587f927aed","value":" 466k/466k [00:00&lt;00:00, 2.31MB/s]"}},"40af967212ad462da7060eec18fbd769":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a3130810414083af6045b973466d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"725f3424b0f849cfa590bfc9447f9f61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c67987bc25c476bb3c4a009925397bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cc2afecbbe4432b9c5dc18679e1a795":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"761432352b7643199e3c568565c7cf1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651812e83a87494b84de4d587f927aed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c72df97f0014d0eb7de6358effc40c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7156ce28445847c68c0342ecdc2a3b62","IPY_MODEL_b44287d0bdf04a53b3529d859263d14a","IPY_MODEL_f611b563a9994fef95d5cfe591762050"],"layout":"IPY_MODEL_42e179ccad114c519056c89f1c09b022"}},"7156ce28445847c68c0342ecdc2a3b62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5e9f013698f4f6d9386dd7228ec0877","placeholder":"â€‹","style":"IPY_MODEL_3f2f906dc3ff4b78b959af4f6f777864","value":"Downloading builder script: 100%"}},"b44287d0bdf04a53b3529d859263d14a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6cd72ed625543648c54107eee8be8d5","max":9570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9858075adbd544e1b667f8a95239991a","value":9570}},"f611b563a9994fef95d5cfe591762050":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49ea8173beae4a98a6b022cb0665506b","placeholder":"â€‹","style":"IPY_MODEL_bb07319cc8da4868b7e2cf6767bbc106","value":" 9.57k/9.57k [00:00&lt;00:00, 512kB/s]"}},"42e179ccad114c519056c89f1c09b022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5e9f013698f4f6d9386dd7228ec0877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f2f906dc3ff4b78b959af4f6f777864":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6cd72ed625543648c54107eee8be8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9858075adbd544e1b667f8a95239991a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49ea8173beae4a98a6b022cb0665506b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb07319cc8da4868b7e2cf6767bbc106":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee5fd348200f4615981d831e3ae3640c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7633db7c1c91409cb71abdfc5e8dcf1d","IPY_MODEL_0c1fb45c07da4f32b5d9ae80430c1f0e","IPY_MODEL_bfdb62df3a314b53b0ab1236fe670f43"],"layout":"IPY_MODEL_f61bc0085f2b4d7690805f939c0f6cac"}},"7633db7c1c91409cb71abdfc5e8dcf1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffec30d4fbf54dbeacc045eca44677bc","placeholder":"â€‹","style":"IPY_MODEL_dfafb31fd3a043a09540be2417a658cf","value":"Downloading metadata: 100%"}},"0c1fb45c07da4f32b5d9ae80430c1f0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23f8883565f448fba1ca8b68e6efa1c4","max":3735,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afa1c80d5a064f0ca4616733da834b50","value":3735}},"bfdb62df3a314b53b0ab1236fe670f43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a389e72980b4c2da6a936d2ca2216f4","placeholder":"â€‹","style":"IPY_MODEL_96aabcb6304244fe9ca4a738a3e806d4","value":" 3.73k/3.73k [00:00&lt;00:00, 185kB/s]"}},"f61bc0085f2b4d7690805f939c0f6cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffec30d4fbf54dbeacc045eca44677bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfafb31fd3a043a09540be2417a658cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23f8883565f448fba1ca8b68e6efa1c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afa1c80d5a064f0ca4616733da834b50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a389e72980b4c2da6a936d2ca2216f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96aabcb6304244fe9ca4a738a3e806d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51f11b332d5e4f188ef9aaf54024ce4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de96ce8f4a59459882861491d7250248","IPY_MODEL_21f1c8e59b4543338eb3ac173c6a0fa5","IPY_MODEL_99cf3fd1305642ed85bac577bc914a52"],"layout":"IPY_MODEL_6fd7b535532c493aa834fb07e87088af"}},"de96ce8f4a59459882861491d7250248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b5c145b1254070b1634de37ca502dc","placeholder":"â€‹","style":"IPY_MODEL_3dfcfbfb21ee431b9b30de48e5c651a2","value":"Downloading readme: 100%"}},"21f1c8e59b4543338eb3ac173c6a0fa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a65c9e4f465b4d2da0e89582e2d4746f","max":12330,"min":0,"orientation":"horizontal","style":"IPY_MODEL_864bf38165b948dc935aaac7d0f2954f","value":12330}},"99cf3fd1305642ed85bac577bc914a52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a714cc040234c39befbddad12945fd9","placeholder":"â€‹","style":"IPY_MODEL_d45ca1847f9749e8a8bfea7b9c821334","value":" 12.3k/12.3k [00:00&lt;00:00, 623kB/s]"}},"6fd7b535532c493aa834fb07e87088af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b5c145b1254070b1634de37ca502dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dfcfbfb21ee431b9b30de48e5c651a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a65c9e4f465b4d2da0e89582e2d4746f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"864bf38165b948dc935aaac7d0f2954f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a714cc040234c39befbddad12945fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d45ca1847f9749e8a8bfea7b9c821334":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"299e8b1093c94919ba864a0001355c8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6537cb2626c46d795e68d3043f885f5","IPY_MODEL_c1c40d9b3086495995c5321a01f7a2ec","IPY_MODEL_4bf888b3598341b38e954581160620a6"],"layout":"IPY_MODEL_5797b9761bec4ef090c2e718c72c5c01"}},"a6537cb2626c46d795e68d3043f885f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6436861a20c04ed7aabc9d618f321edf","placeholder":"â€‹","style":"IPY_MODEL_e606476122f04ea884993fbed28ae2ed","value":"Downloading data: 100%"}},"c1c40d9b3086495995c5321a01f7a2ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba2292e75e2544e390c28229ab3a5a30","max":982975,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3805394bd0b4de5b9ea7296c37d6866","value":982975}},"4bf888b3598341b38e954581160620a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fe69b95eb9e4996ae4e4e4f4d54f3d3","placeholder":"â€‹","style":"IPY_MODEL_7a7fc0c068cc432a8e00b33ab94cc0b9","value":" 983k/983k [00:00&lt;00:00, 6.96MB/s]"}},"5797b9761bec4ef090c2e718c72c5c01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6436861a20c04ed7aabc9d618f321edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e606476122f04ea884993fbed28ae2ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba2292e75e2544e390c28229ab3a5a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3805394bd0b4de5b9ea7296c37d6866":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fe69b95eb9e4996ae4e4e4f4d54f3d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a7fc0c068cc432a8e00b33ab94cc0b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c736ea17e30420191bf5cc9001027f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e425bfb2654649fbb103101c278ba4ba","IPY_MODEL_0b9098e5643d4ec1880c5c3e1417f513","IPY_MODEL_275eb6df3b82480bbf0dc5081d48ef4d"],"layout":"IPY_MODEL_f121af0b91eb484a91258770bb062429"}},"e425bfb2654649fbb103101c278ba4ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a3656ac8f840bab314470c7d837d6f","placeholder":"â€‹","style":"IPY_MODEL_7eb773efaa834b9ca5e8d55ffee7f9f5","value":"Generating train split: 100%"}},"0b9098e5643d4ec1880c5c3e1417f513":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7216ffbcbe09452c87974fcdcb4605b8","max":14041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42c0a3e930a7435a90d1e1193ab228c9","value":14041}},"275eb6df3b82480bbf0dc5081d48ef4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81c37e9e90248928d7bde069d148140","placeholder":"â€‹","style":"IPY_MODEL_ed3fbc8ab76f4130872996864ea3a483","value":" 14041/14041 [00:03&lt;00:00, 4400.99 examples/s]"}},"f121af0b91eb484a91258770bb062429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a3656ac8f840bab314470c7d837d6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb773efaa834b9ca5e8d55ffee7f9f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7216ffbcbe09452c87974fcdcb4605b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c0a3e930a7435a90d1e1193ab228c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a81c37e9e90248928d7bde069d148140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed3fbc8ab76f4130872996864ea3a483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3bd409fe2f24974916f5da96078950e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17cb839e1efe475f99a3000ac11188ec","IPY_MODEL_1f889187a0ed46beb1f972c598958155","IPY_MODEL_3e50cc60da0c4f6bbf8a04ca92f7993e"],"layout":"IPY_MODEL_95a983a4978b4add822eb42c2cc1005f"}},"17cb839e1efe475f99a3000ac11188ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3dc2933a5144c4aa623e31fd40032b","placeholder":"â€‹","style":"IPY_MODEL_2af3acfc9c8b443aa101544b01dfdb6a","value":"Generating validation split: 100%"}},"1f889187a0ed46beb1f972c598958155":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75af02eb79e84a41a95e67cc46893b8e","max":3250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_807fcaf8da9f443794f3fb3f9c5e9f7b","value":3250}},"3e50cc60da0c4f6bbf8a04ca92f7993e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a5e4e5ba76e4aefa22fa072e6ebb1a3","placeholder":"â€‹","style":"IPY_MODEL_64d93dfd0c2741728faa0986873ea04d","value":" 3250/3250 [00:00&lt;00:00, 4427.67 examples/s]"}},"95a983a4978b4add822eb42c2cc1005f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c3dc2933a5144c4aa623e31fd40032b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af3acfc9c8b443aa101544b01dfdb6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75af02eb79e84a41a95e67cc46893b8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807fcaf8da9f443794f3fb3f9c5e9f7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a5e4e5ba76e4aefa22fa072e6ebb1a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d93dfd0c2741728faa0986873ea04d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe8841175a1f4563b2e87cd6d88e98ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fe7325c7f6a4beb993c8dab1063d47c","IPY_MODEL_08b44b132b4b4a6f8d8d2b591f45be8d","IPY_MODEL_285caa3f66834686b53c244aab23b003"],"layout":"IPY_MODEL_904273a7d71f4830af0cde87674f2c54"}},"1fe7325c7f6a4beb993c8dab1063d47c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0613327f65074b4a9170348713e60230","placeholder":"â€‹","style":"IPY_MODEL_0509e68b0b644c47a127b51531084abe","value":"Generating test split: 100%"}},"08b44b132b4b4a6f8d8d2b591f45be8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b618281831eb46c28e8b6c0bd8cbfd52","max":3453,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebdbe28631d341bd8d4eed6cd1109984","value":3453}},"285caa3f66834686b53c244aab23b003":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1874872c24da4b5780d009bbc6250fcf","placeholder":"â€‹","style":"IPY_MODEL_369351e045de4a3abf1c9bb8557b8f82","value":" 3453/3453 [00:00&lt;00:00, 5116.63 examples/s]"}},"904273a7d71f4830af0cde87674f2c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0613327f65074b4a9170348713e60230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0509e68b0b644c47a127b51531084abe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b618281831eb46c28e8b6c0bd8cbfd52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebdbe28631d341bd8d4eed6cd1109984":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1874872c24da4b5780d009bbc6250fcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"369351e045de4a3abf1c9bb8557b8f82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}